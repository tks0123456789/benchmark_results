python mnist_mlp.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
60000 train samples
10000 test samples
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
dense_1 (Dense)                    (None, 512)         401920      dense_input_1[0][0]              
____________________________________________________________________________________________________
activation_1 (Activation)          (None, 512)         0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)                (None, 512)         0           activation_1[0][0]               
____________________________________________________________________________________________________
dense_2 (Dense)                    (None, 512)         262656      dropout_1[0][0]                  
____________________________________________________________________________________________________
activation_2 (Activation)          (None, 512)         0           dense_2[0][0]                    
____________________________________________________________________________________________________
dropout_2 (Dropout)                (None, 512)         0           activation_2[0][0]               
____________________________________________________________________________________________________
dense_3 (Dense)                    (None, 10)          5130        dropout_2[0][0]                  
____________________________________________________________________________________________________
activation_3 (Activation)          (None, 10)          0           dense_3[0][0]                    
====================================================================================================
Total params: 669706
____________________________________________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
60000/60000 [==============================] - 2s - loss: 0.2752 - acc: 0.9166 - val_loss: 0.1164 - val_acc: 0.9643
Epoch 2/20
60000/60000 [==============================] - 2s - loss: 0.1136 - acc: 0.9655 - val_loss: 0.0837 - val_acc: 0.9754
Epoch 3/20
60000/60000 [==============================] - 2s - loss: 0.0809 - acc: 0.9747 - val_loss: 0.0699 - val_acc: 0.9779
Epoch 4/20
60000/60000 [==============================] - 2s - loss: 0.0606 - acc: 0.9808 - val_loss: 0.0718 - val_acc: 0.9765
Epoch 5/20
60000/60000 [==============================] - 2s - loss: 0.0503 - acc: 0.9838 - val_loss: 0.0652 - val_acc: 0.9787
Epoch 6/20
60000/60000 [==============================] - 2s - loss: 0.0425 - acc: 0.9866 - val_loss: 0.0535 - val_acc: 0.9835
Epoch 7/20
60000/60000 [==============================] - 2s - loss: 0.0344 - acc: 0.9889 - val_loss: 0.0609 - val_acc: 0.9814
Epoch 8/20
60000/60000 [==============================] - 2s - loss: 0.0293 - acc: 0.9901 - val_loss: 0.0637 - val_acc: 0.9830
Epoch 9/20
60000/60000 [==============================] - 2s - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0584 - val_acc: 0.9845
Epoch 10/20
60000/60000 [==============================] - 2s - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0609 - val_acc: 0.9830
Epoch 11/20
60000/60000 [==============================] - 2s - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0594 - val_acc: 0.9836
Epoch 12/20
60000/60000 [==============================] - 2s - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0634 - val_acc: 0.9847
Epoch 13/20
60000/60000 [==============================] - 2s - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0616 - val_acc: 0.9847
Epoch 14/20
60000/60000 [==============================] - 2s - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0652 - val_acc: 0.9845
Epoch 15/20
60000/60000 [==============================] - 2s - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0670 - val_acc: 0.9844
Epoch 16/20
60000/60000 [==============================] - 2s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0824 - val_acc: 0.9822
Epoch 17/20
60000/60000 [==============================] - 2s - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0630 - val_acc: 0.9857
Epoch 18/20
60000/60000 [==============================] - 2s - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0671 - val_acc: 0.9849
Epoch 19/20
60000/60000 [==============================] - 2s - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0703 - val_acc: 0.9844
Epoch 20/20
60000/60000 [==============================] - 2s - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0644 - val_acc: 0.9844
Test score: 0.0643513638924
Test accuracy: 0.9844


python mnist_cnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/12
60000/60000 [==============================] - 26s - loss: 0.2572 - acc: 0.9216 - val_loss: 0.0571 - val_acc: 0.9825
Epoch 2/12
60000/60000 [==============================] - 26s - loss: 0.0951 - acc: 0.9711 - val_loss: 0.0399 - val_acc: 0.9864
Epoch 3/12
60000/60000 [==============================] - 26s - loss: 0.0713 - acc: 0.9786 - val_loss: 0.0363 - val_acc: 0.9884
Epoch 4/12
60000/60000 [==============================] - 26s - loss: 0.0578 - acc: 0.9829 - val_loss: 0.0307 - val_acc: 0.9890
Epoch 5/12
60000/60000 [==============================] - 26s - loss: 0.0488 - acc: 0.9848 - val_loss: 0.0296 - val_acc: 0.9901
Epoch 6/12
60000/60000 [==============================] - 26s - loss: 0.0416 - acc: 0.9867 - val_loss: 0.0304 - val_acc: 0.9907
Epoch 7/12
60000/60000 [==============================] - 26s - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0317 - val_acc: 0.9892
Epoch 8/12
60000/60000 [==============================] - 26s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0284 - val_acc: 0.9917
Epoch 9/12
60000/60000 [==============================] - 26s - loss: 0.0312 - acc: 0.9907 - val_loss: 0.0270 - val_acc: 0.9919
Epoch 10/12
60000/60000 [==============================] - 26s - loss: 0.0296 - acc: 0.9907 - val_loss: 0.0280 - val_acc: 0.9922
Epoch 11/12
60000/60000 [==============================] - 26s - loss: 0.0276 - acc: 0.9909 - val_loss: 0.0277 - val_acc: 0.9917
Epoch 12/12
60000/60000 [==============================] - 26s - loss: 0.0252 - acc: 0.9919 - val_loss: 0.0282 - val_acc: 0.9920
Test score: 0.0282181292013
Test accuracy: 0.992


python mnist_sklearn_wrapper.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.6127 - acc: 0.7937     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.3219 - acc: 0.8992     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2608 - acc: 0.9189     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.5918 - acc: 0.7985     
Epoch 2/3
40000/40000 [==============================] - 10s - loss: 0.3134 - acc: 0.9005    
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2680 - acc: 0.9175     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.5986 - acc: 0.8000     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.3143 - acc: 0.8985     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2551 - acc: 0.9210     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 10s - loss: 0.5079 - acc: 0.8317    
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2924 - acc: 0.9073     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2523 - acc: 0.9194     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2363 - acc: 0.9264     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2175 - acc: 0.9322     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2058 - acc: 0.9362     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.5848 - acc: 0.8031     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.3129 - acc: 0.8999     
Epoch 3/6
40000/40000 [==============================] - 10s - loss: 0.2596 - acc: 0.9197    
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2436 - acc: 0.9256     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2330 - acc: 0.9287     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2298 - acc: 0.9301     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 10s - loss: 0.4908 - acc: 0.8408    
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2745 - acc: 0.9161     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2334 - acc: 0.9295     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2164 - acc: 0.9348     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2091 - acc: 0.9387     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1998 - acc: 0.9403     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3452 - acc: 0.8931     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1583 - acc: 0.9535     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1333 - acc: 0.9614     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3824 - acc: 0.8812     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1816 - acc: 0.9466     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1409 - acc: 0.9586     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3366 - acc: 0.8945     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1656 - acc: 0.9506     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1372 - acc: 0.9590     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3563 - acc: 0.8890     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1720 - acc: 0.9497     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1422 - acc: 0.9585     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1268 - acc: 0.9645     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1187 - acc: 0.9657     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1088 - acc: 0.9683     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3489 - acc: 0.8937     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1736 - acc: 0.9505     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1447 - acc: 0.9577     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1317 - acc: 0.9615     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1204 - acc: 0.9660     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1091 - acc: 0.9692     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3427 - acc: 0.8950     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1659 - acc: 0.9525     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1379 - acc: 0.9602     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1212 - acc: 0.9645     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1158 - acc: 0.9667     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1071 - acc: 0.9694     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.4662 - acc: 0.8535     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.2737 - acc: 0.9175     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2354 - acc: 0.9302     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.4313 - acc: 0.8608     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.2572 - acc: 0.9190     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2317 - acc: 0.9276     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.5119 - acc: 0.8339     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.2912 - acc: 0.9084     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2502 - acc: 0.9243     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.4504 - acc: 0.8545     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2578 - acc: 0.9206     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2313 - acc: 0.9274     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2150 - acc: 0.9318     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2103 - acc: 0.9337     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2059 - acc: 0.9362     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.4825 - acc: 0.8444     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2730 - acc: 0.9168     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2408 - acc: 0.9288     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2135 - acc: 0.9340     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2065 - acc: 0.9378     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1996 - acc: 0.9395     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.4800 - acc: 0.8467     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2735 - acc: 0.9144     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2472 - acc: 0.9216     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2267 - acc: 0.9299     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2190 - acc: 0.9324     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2094 - acc: 0.9362     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3215 - acc: 0.9029     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1662 - acc: 0.9520     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1396 - acc: 0.9601     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3494 - acc: 0.8946     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1709 - acc: 0.9509     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1480 - acc: 0.9578     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3360 - acc: 0.8978     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1628 - acc: 0.9530     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1436 - acc: 0.9600     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3252 - acc: 0.9015     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1671 - acc: 0.9515     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1406 - acc: 0.9598     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1290 - acc: 0.9632     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1210 - acc: 0.9653     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1095 - acc: 0.9685     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3284 - acc: 0.9001     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1702 - acc: 0.9526     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1399 - acc: 0.9612     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1287 - acc: 0.9638     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1284 - acc: 0.9650     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1158 - acc: 0.9670     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3295 - acc: 0.9007     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1705 - acc: 0.9512     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1480 - acc: 0.9568     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1321 - acc: 0.9626     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1219 - acc: 0.9654     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1185 - acc: 0.9667     
20000/20000 [==============================] - 1s     
Epoch 1/6
60000/60000 [==============================] - 14s - loss: 0.3071 - acc: 0.9065    
Epoch 2/6
60000/60000 [==============================] - 14s - loss: 0.1478 - acc: 0.9567    
Epoch 3/6
60000/60000 [==============================] - 14s - loss: 0.1229 - acc: 0.9650    
Epoch 4/6
60000/60000 [==============================] - 14s - loss: 0.1137 - acc: 0.9675    
Epoch 5/6
60000/60000 [==============================] - 14s - loss: 0.1074 - acc: 0.9697    
Epoch 6/6
60000/60000 [==============================] - 14s - loss: 0.1015 - acc: 0.9708    
The parameters of the best model are: 
{'dense_layer_sizes': [64], 'nb_conv': 3, 'nb_pool': 2, 'nb_epoch': 6, 'nb_filters': 8}
10000/10000 [==============================] - 0s     
loss :  0.0453512147586
acc :  0.986


python mnist_siamese_graph.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Train on 108400 samples, validate on 17820 samples
Epoch 1/20
108400/108400 [==============================] - 4s - loss: 0.1068 - val_loss: 0.0506
Epoch 2/20
108400/108400 [==============================] - 4s - loss: 0.0510 - val_loss: 0.0369
Epoch 3/20
108400/108400 [==============================] - 4s - loss: 0.0369 - val_loss: 0.0310
Epoch 4/20
108400/108400 [==============================] - 4s - loss: 0.0301 - val_loss: 0.0271
Epoch 5/20
108400/108400 [==============================] - 4s - loss: 0.0256 - val_loss: 0.0268
Epoch 6/20
108400/108400 [==============================] - 4s - loss: 0.0230 - val_loss: 0.0257
Epoch 7/20
108400/108400 [==============================] - 4s - loss: 0.0208 - val_loss: 0.0252
Epoch 8/20
108400/108400 [==============================] - 4s - loss: 0.0190 - val_loss: 0.0237
Epoch 9/20
108400/108400 [==============================] - 4s - loss: 0.0175 - val_loss: 0.0240
Epoch 10/20
108400/108400 [==============================] - 4s - loss: 0.0165 - val_loss: 0.0246
Epoch 11/20
108400/108400 [==============================] - 4s - loss: 0.0157 - val_loss: 0.0245
Epoch 12/20
108400/108400 [==============================] - 4s - loss: 0.0147 - val_loss: 0.0240
Epoch 13/20
108400/108400 [==============================] - 4s - loss: 0.0138 - val_loss: 0.0239
Epoch 14/20
108400/108400 [==============================] - 4s - loss: 0.0133 - val_loss: 0.0253
Epoch 15/20
108400/108400 [==============================] - 4s - loss: 0.0124 - val_loss: 0.0246
Epoch 16/20
108400/108400 [==============================] - 4s - loss: 0.0117 - val_loss: 0.0245
Epoch 17/20
108400/108400 [==============================] - 4s - loss: 0.0115 - val_loss: 0.0242
Epoch 18/20
108400/108400 [==============================] - 4s - loss: 0.0111 - val_loss: 0.0247
Epoch 19/20
108400/108400 [==============================] - 4s - loss: 0.0108 - val_loss: 0.0258
Epoch 20/20
108400/108400 [==============================] - 4s - loss: 0.0104 - val_loss: 0.0251
* Accuracy on training set: 99.93%
* Accuracy on test set: 99.40%


python imdb_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
Downloading data from https://s3.amazonaws.com/text-datasets/imdb.pkl
33218560/33213513 [==============================] - 52s    
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 80)
X_test shape: (5000, 80)
Build model...
Train...
(20000, 80)
(20000,)
Train on 20000 samples, validate on 5000 samples
Epoch 1/15
20000/20000 [==============================] - 49s - loss: 0.5870 - acc: 0.6847 - val_loss: 0.4479 - val_acc: 0.7950
Epoch 2/15
20000/20000 [==============================] - 49s - loss: 0.4335 - acc: 0.8075 - val_loss: 0.4030 - val_acc: 0.8196
Epoch 3/15
20000/20000 [==============================] - 49s - loss: 0.3523 - acc: 0.8526 - val_loss: 0.3983 - val_acc: 0.8200
Epoch 4/15
20000/20000 [==============================] - 49s - loss: 0.2849 - acc: 0.8842 - val_loss: 0.3985 - val_acc: 0.8272
Epoch 5/15
20000/20000 [==============================] - 49s - loss: 0.2434 - acc: 0.9039 - val_loss: 0.4642 - val_acc: 0.8206
Epoch 6/15
20000/20000 [==============================] - 49s - loss: 0.2057 - acc: 0.9181 - val_loss: 0.4650 - val_acc: 0.8264
Epoch 7/15
20000/20000 [==============================] - 49s - loss: 0.1764 - acc: 0.9334 - val_loss: 0.4680 - val_acc: 0.8136
Epoch 8/15
20000/20000 [==============================] - 49s - loss: 0.1483 - acc: 0.9427 - val_loss: 0.5340 - val_acc: 0.8202
Epoch 9/15
20000/20000 [==============================] - 49s - loss: 0.1352 - acc: 0.9474 - val_loss: 0.4883 - val_acc: 0.8132
Epoch 10/15
20000/20000 [==============================] - 49s - loss: 0.1139 - acc: 0.9580 - val_loss: 0.5827 - val_acc: 0.8104
Epoch 11/15
20000/20000 [==============================] - 49s - loss: 0.1011 - acc: 0.9632 - val_loss: 0.5834 - val_acc: 0.8118
Epoch 12/15
20000/20000 [==============================] - 49s - loss: 0.0910 - acc: 0.9661 - val_loss: 0.7059 - val_acc: 0.8088
Epoch 13/15
20000/20000 [==============================] - 49s - loss: 0.0857 - acc: 0.9677 - val_loss: 0.6236 - val_acc: 0.8120
Epoch 14/15
20000/20000 [==============================] - 49s - loss: 0.0756 - acc: 0.9724 - val_loss: 0.7265 - val_acc: 0.8100
Epoch 15/15
20000/20000 [==============================] - 49s - loss: 0.0738 - acc: 0.9728 - val_loss: 0.6517 - val_acc: 0.8090
5000/5000 [==============================] - 4s     
Test score: 0.651677638912
Test accuracy: 0.809


python imdb_cnn.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 400)
X_test shape: (5000, 400)
Build model...
Train on 20000 samples, validate on 5000 samples
Epoch 1/2
20000/20000 [==============================] - 15s - loss: 0.4581 - acc: 0.7640 - val_loss: 0.3172 - val_acc: 0.8656
Epoch 2/2
20000/20000 [==============================] - 15s - loss: 0.2944 - acc: 0.8758 - val_loss: 0.2811 - val_acc: 0.8826


python imdb_cnn_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 100)
X_test shape: (5000, 100)
Build model...
Train...
Train on 20000 samples, validate on 5000 samples
Epoch 1/2
20000/20000 [==============================] - 34s - loss: 0.4312 - acc: 0.7894 - val_loss: 0.3465 - val_acc: 0.8448
Epoch 2/2
20000/20000 [==============================] - 34s - loss: 0.2265 - acc: 0.9110 - val_loss: 0.3540 - val_acc: 0.8490
5000/5000 [==============================] - 3s     
Test score: 0.354021408424
Test accuracy: 0.848999991179


python reuters_mlp.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
Downloading data from https://s3.amazonaws.com/text-datasets/reuters.pkl
9216000/9211982 [==============================] - 17s    
8982 train sequences
2246 test sequences
46 classes
Vectorizing sequence data...
X_train shape: (8982, 1000)
X_test shape: (2246, 1000)
Convert class vector to binary class matrix (for use with categorical_crossentropy)
Y_train shape: (8982, 46)
Y_test shape: (2246, 46)
Building model...
Train on 8083 samples, validate on 899 samples
Epoch 1/5
8083/8083 [==============================] - 0s - loss: 1.4164 - acc: 0.6851 - val_loss: 1.0786 - val_acc: 0.7631
Epoch 2/5
8083/8083 [==============================] - 0s - loss: 0.7705 - acc: 0.8185 - val_loss: 0.9107 - val_acc: 0.7987
Epoch 3/5
8083/8083 [==============================] - 0s - loss: 0.5516 - acc: 0.8661 - val_loss: 0.8658 - val_acc: 0.8009
Epoch 4/5
8083/8083 [==============================] - 0s - loss: 0.4095 - acc: 0.8992 - val_loss: 0.8906 - val_acc: 0.8098
Epoch 5/5
8083/8083 [==============================] - 0s - loss: 0.3282 - acc: 0.9164 - val_loss: 0.8824 - val_acc: 0.8131
2246/2246 [==============================] - 0s     
Test score: 0.875797399748
Test accuracy: 0.793410507569


python antirectifier.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/40
60000/60000 [==============================] - 2s - loss: 0.8016 - acc: 0.8857 - val_loss: 0.2561 - val_acc: 0.9458
Epoch 2/40
60000/60000 [==============================] - 2s - loss: 0.1942 - acc: 0.9561 - val_loss: 0.1243 - val_acc: 0.9692
Epoch 3/40
60000/60000 [==============================] - 2s - loss: 0.1185 - acc: 0.9715 - val_loss: 0.0957 - val_acc: 0.9734
Epoch 4/40
60000/60000 [==============================] - 2s - loss: 0.0874 - acc: 0.9783 - val_loss: 0.0797 - val_acc: 0.9770
Epoch 5/40
60000/60000 [==============================] - 2s - loss: 0.0704 - acc: 0.9824 - val_loss: 0.0808 - val_acc: 0.9772
Epoch 6/40
60000/60000 [==============================] - 2s - loss: 0.0596 - acc: 0.9852 - val_loss: 0.0671 - val_acc: 0.9806
Epoch 7/40
60000/60000 [==============================] - 2s - loss: 0.0494 - acc: 0.9881 - val_loss: 0.0642 - val_acc: 0.9804
Epoch 8/40
60000/60000 [==============================] - 2s - loss: 0.0431 - acc: 0.9897 - val_loss: 0.0689 - val_acc: 0.9803
Epoch 9/40
60000/60000 [==============================] - 2s - loss: 0.0369 - acc: 0.9912 - val_loss: 0.0617 - val_acc: 0.9818
Epoch 10/40
60000/60000 [==============================] - 2s - loss: 0.0329 - acc: 0.9922 - val_loss: 0.0603 - val_acc: 0.9815
Epoch 11/40
60000/60000 [==============================] - 2s - loss: 0.0283 - acc: 0.9938 - val_loss: 0.0613 - val_acc: 0.9809
Epoch 12/40
60000/60000 [==============================] - 2s - loss: 0.0256 - acc: 0.9944 - val_loss: 0.0598 - val_acc: 0.9822
Epoch 13/40
60000/60000 [==============================] - 2s - loss: 0.0242 - acc: 0.9943 - val_loss: 0.0560 - val_acc: 0.9841
Epoch 14/40
60000/60000 [==============================] - 2s - loss: 0.0205 - acc: 0.9959 - val_loss: 0.0599 - val_acc: 0.9822
Epoch 15/40
60000/60000 [==============================] - 2s - loss: 0.0185 - acc: 0.9964 - val_loss: 0.0575 - val_acc: 0.9824
Epoch 16/40
60000/60000 [==============================] - 2s - loss: 0.0179 - acc: 0.9963 - val_loss: 0.0564 - val_acc: 0.9823
Epoch 17/40
60000/60000 [==============================] - 2s - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0547 - val_acc: 0.9835
Epoch 18/40
60000/60000 [==============================] - 2s - loss: 0.0149 - acc: 0.9973 - val_loss: 0.0596 - val_acc: 0.9823
Epoch 19/40
60000/60000 [==============================] - 2s - loss: 0.0132 - acc: 0.9975 - val_loss: 0.0538 - val_acc: 0.9839
Epoch 20/40
60000/60000 [==============================] - 2s - loss: 0.0128 - acc: 0.9977 - val_loss: 0.0567 - val_acc: 0.9836
Epoch 21/40
60000/60000 [==============================] - 2s - loss: 0.0122 - acc: 0.9976 - val_loss: 0.0551 - val_acc: 0.9837
Epoch 22/40
60000/60000 [==============================] - 2s - loss: 0.0110 - acc: 0.9981 - val_loss: 0.0557 - val_acc: 0.9826
Epoch 23/40
60000/60000 [==============================] - 2s - loss: 0.0101 - acc: 0.9982 - val_loss: 0.0543 - val_acc: 0.9843
Epoch 24/40
60000/60000 [==============================] - 2s - loss: 0.0093 - acc: 0.9985 - val_loss: 0.0570 - val_acc: 0.9833
Epoch 25/40
60000/60000 [==============================] - 2s - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0621 - val_acc: 0.9811
Epoch 26/40
60000/60000 [==============================] - 2s - loss: 0.0086 - acc: 0.9986 - val_loss: 0.0580 - val_acc: 0.9831
Epoch 27/40
60000/60000 [==============================] - 2s - loss: 0.0083 - acc: 0.9986 - val_loss: 0.0589 - val_acc: 0.9831
Epoch 28/40
60000/60000 [==============================] - 2s - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0595 - val_acc: 0.9818
Epoch 29/40
60000/60000 [==============================] - 2s - loss: 0.0071 - acc: 0.9990 - val_loss: 0.0523 - val_acc: 0.9838
Epoch 30/40
60000/60000 [==============================] - 2s - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0563 - val_acc: 0.9839
Epoch 31/40
60000/60000 [==============================] - 2s - loss: 0.0065 - acc: 0.9992 - val_loss: 0.0537 - val_acc: 0.9853
Epoch 32/40
60000/60000 [==============================] - 2s - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0569 - val_acc: 0.9841
Epoch 33/40
60000/60000 [==============================] - 2s - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0564 - val_acc: 0.9835
Epoch 34/40
60000/60000 [==============================] - 2s - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0530 - val_acc: 0.9844
Epoch 35/40
60000/60000 [==============================] - 2s - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0552 - val_acc: 0.9840
Epoch 36/40
60000/60000 [==============================] - 2s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0549 - val_acc: 0.9837
Epoch 37/40
60000/60000 [==============================] - 2s - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0545 - val_acc: 0.9845
Epoch 38/40
60000/60000 [==============================] - 2s - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0538 - val_acc: 0.9846
Epoch 39/40
60000/60000 [==============================] - 2s - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0541 - val_acc: 0.9848
Epoch 40/40
60000/60000 [==============================] - 2s - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0550 - val_acc: 0.9848


python imdb_bidirectional_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 100)
X_test shape: (5000, 100)
Train...
Train on 20000 samples, validate on 5000 samples
Epoch 1/4
20000/20000 [==============================] - 89s - loss: 0.4595 - acc: 0.7763 - val_loss: 0.3695 - val_acc: 0.8282
Epoch 2/4
20000/20000 [==============================] - 90s - loss: 0.2459 - acc: 0.9023 - val_loss: 0.3844 - val_acc: 0.8362
Epoch 3/4
20000/20000 [==============================] - 90s - loss: 0.1291 - acc: 0.9539 - val_loss: 0.4482 - val_acc: 0.8210
Epoch 4/4
20000/20000 [==============================] - 90s - loss: 0.0540 - acc: 0.9825 - val_loss: 0.6642 - val_acc: 0.8314


python cifar10_cnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
X_train shape: (50000, 3, 32, 32)
50000 train samples
10000 test samples
Using real-time data augmentation.
Epoch 1/200
50000/50000 [==============================] - 78s - loss: 1.7040 - acc: 0.3689 - val_loss: 1.2726 - val_acc: 0.5381
Epoch 2/200
50000/50000 [==============================] - 76s - loss: 1.3625 - acc: 0.5064 - val_loss: 1.1567 - val_acc: 0.5847
Epoch 3/200
50000/50000 [==============================] - 76s - loss: 1.2196 - acc: 0.5633 - val_loss: 1.1163 - val_acc: 0.5981
Epoch 4/200
50000/50000 [==============================] - 76s - loss: 1.1302 - acc: 0.5994 - val_loss: 0.8949 - val_acc: 0.6824
Epoch 5/200
50000/50000 [==============================] - 76s - loss: 1.0609 - acc: 0.6241 - val_loss: 0.8628 - val_acc: 0.6985
Epoch 6/200
50000/50000 [==============================] - 76s - loss: 1.0165 - acc: 0.6419 - val_loss: 0.7944 - val_acc: 0.7250
Epoch 7/200
50000/50000 [==============================] - 76s - loss: 0.9857 - acc: 0.6526 - val_loss: 0.8412 - val_acc: 0.7054
Epoch 8/200
50000/50000 [==============================] - 76s - loss: 0.9624 - acc: 0.6623 - val_loss: 0.7865 - val_acc: 0.7244
Epoch 9/200
50000/50000 [==============================] - 76s - loss: 0.9432 - acc: 0.6711 - val_loss: 0.7452 - val_acc: 0.7424
Epoch 10/200
50000/50000 [==============================] - 76s - loss: 0.9267 - acc: 0.6754 - val_loss: 0.7334 - val_acc: 0.7463
Epoch 11/200
50000/50000 [==============================] - 76s - loss: 0.9153 - acc: 0.6809 - val_loss: 0.7626 - val_acc: 0.7352
Epoch 12/200
50000/50000 [==============================] - 76s - loss: 0.9031 - acc: 0.6848 - val_loss: 0.7727 - val_acc: 0.7362
Epoch 13/200
50000/50000 [==============================] - 76s - loss: 0.8954 - acc: 0.6877 - val_loss: 0.7433 - val_acc: 0.7402
Epoch 14/200
50000/50000 [==============================] - 76s - loss: 0.8818 - acc: 0.6941 - val_loss: 0.7151 - val_acc: 0.7534
Epoch 15/200
50000/50000 [==============================] - 76s - loss: 0.8756 - acc: 0.6943 - val_loss: 0.7009 - val_acc: 0.7540
Epoch 16/200
50000/50000 [==============================] - 76s - loss: 0.8755 - acc: 0.6944 - val_loss: 0.7202 - val_acc: 0.7495
Epoch 17/200
50000/50000 [==============================] - 76s - loss: 0.8717 - acc: 0.6968 - val_loss: 0.6794 - val_acc: 0.7654
Epoch 18/200
50000/50000 [==============================] - 76s - loss: 0.8651 - acc: 0.7011 - val_loss: 0.7028 - val_acc: 0.7580
Epoch 19/200
50000/50000 [==============================] - 76s - loss: 0.8603 - acc: 0.7026 - val_loss: 0.7396 - val_acc: 0.7426
Epoch 20/200
50000/50000 [==============================] - 76s - loss: 0.8523 - acc: 0.7047 - val_loss: 0.6953 - val_acc: 0.7598
Epoch 21/200
50000/50000 [==============================] - 76s - loss: 0.8490 - acc: 0.7059 - val_loss: 0.6797 - val_acc: 0.7635
Epoch 22/200
50000/50000 [==============================] - 76s - loss: 0.8448 - acc: 0.7065 - val_loss: 0.6894 - val_acc: 0.7648
Epoch 23/200
50000/50000 [==============================] - 76s - loss: 0.8373 - acc: 0.7124 - val_loss: 0.6752 - val_acc: 0.7647
Epoch 24/200
50000/50000 [==============================] - 76s - loss: 0.8451 - acc: 0.7092 - val_loss: 0.6945 - val_acc: 0.7605
Epoch 25/200
50000/50000 [==============================] - 76s - loss: 0.8335 - acc: 0.7106 - val_loss: 0.7181 - val_acc: 0.7528
Epoch 26/200
50000/50000 [==============================] - 76s - loss: 0.8359 - acc: 0.7131 - val_loss: 0.6745 - val_acc: 0.7624
Epoch 27/200
50000/50000 [==============================] - 76s - loss: 0.8404 - acc: 0.7092 - val_loss: 0.7088 - val_acc: 0.7553
Epoch 28/200
50000/50000 [==============================] - 76s - loss: 0.8318 - acc: 0.7095 - val_loss: 0.6572 - val_acc: 0.7731
Epoch 29/200
50000/50000 [==============================] - 76s - loss: 0.8210 - acc: 0.7189 - val_loss: 0.7459 - val_acc: 0.7423
Epoch 30/200
50000/50000 [==============================] - 76s - loss: 0.8249 - acc: 0.7167 - val_loss: 0.6984 - val_acc: 0.7639
Epoch 31/200
50000/50000 [==============================] - 76s - loss: 0.8311 - acc: 0.7136 - val_loss: 0.6745 - val_acc: 0.7661
Epoch 32/200
50000/50000 [==============================] - 76s - loss: 0.8247 - acc: 0.7146 - val_loss: 0.7449 - val_acc: 0.7486
Epoch 33/200
50000/50000 [==============================] - 76s - loss: 0.8186 - acc: 0.7171 - val_loss: 0.6705 - val_acc: 0.7727
Epoch 34/200
50000/50000 [==============================] - 76s - loss: 0.8217 - acc: 0.7171 - val_loss: 0.7189 - val_acc: 0.7553
Epoch 35/200
50000/50000 [==============================] - 76s - loss: 0.8236 - acc: 0.7178 - val_loss: 0.6611 - val_acc: 0.7778
Epoch 36/200
50000/50000 [==============================] - 76s - loss: 0.8132 - acc: 0.7218 - val_loss: 0.6329 - val_acc: 0.7902
Epoch 37/200
50000/50000 [==============================] - 76s - loss: 0.8106 - acc: 0.7223 - val_loss: 0.7402 - val_acc: 0.7477
Epoch 38/200
50000/50000 [==============================] - 76s - loss: 0.8054 - acc: 0.7251 - val_loss: 0.6639 - val_acc: 0.7755
Epoch 39/200
50000/50000 [==============================] - 76s - loss: 0.8079 - acc: 0.7231 - val_loss: 0.6402 - val_acc: 0.7812
Epoch 40/200
50000/50000 [==============================] - 76s - loss: 0.8063 - acc: 0.7243 - val_loss: 0.6592 - val_acc: 0.7753
Epoch 41/200
50000/50000 [==============================] - 76s - loss: 0.8000 - acc: 0.7258 - val_loss: 0.6294 - val_acc: 0.7849
Epoch 42/200
50000/50000 [==============================] - 76s - loss: 0.7969 - acc: 0.7268 - val_loss: 0.6941 - val_acc: 0.7680
Epoch 43/200
50000/50000 [==============================] - 76s - loss: 0.7951 - acc: 0.7266 - val_loss: 0.6367 - val_acc: 0.7832
Epoch 44/200
50000/50000 [==============================] - 76s - loss: 0.7996 - acc: 0.7284 - val_loss: 0.6169 - val_acc: 0.7920
Epoch 45/200
50000/50000 [==============================] - 76s - loss: 0.7871 - acc: 0.7311 - val_loss: 0.6402 - val_acc: 0.7825
Epoch 46/200
50000/50000 [==============================] - 76s - loss: 0.8032 - acc: 0.7254 - val_loss: 0.6181 - val_acc: 0.7935
Epoch 47/200
50000/50000 [==============================] - 76s - loss: 0.7846 - acc: 0.7322 - val_loss: 0.6305 - val_acc: 0.7874
Epoch 48/200
50000/50000 [==============================] - 76s - loss: 0.7868 - acc: 0.7304 - val_loss: 0.6436 - val_acc: 0.7807
Epoch 49/200
50000/50000 [==============================] - 76s - loss: 0.7888 - acc: 0.7306 - val_loss: 0.6809 - val_acc: 0.7696
Epoch 50/200
50000/50000 [==============================] - 76s - loss: 0.7940 - acc: 0.7280 - val_loss: 0.6533 - val_acc: 0.7773
Epoch 51/200
50000/50000 [==============================] - 76s - loss: 0.7941 - acc: 0.7301 - val_loss: 0.6434 - val_acc: 0.7810
Epoch 52/200
50000/50000 [==============================] - 76s - loss: 0.7901 - acc: 0.7310 - val_loss: 0.6261 - val_acc: 0.7888
Epoch 53/200
50000/50000 [==============================] - 76s - loss: 0.7765 - acc: 0.7390 - val_loss: 0.6634 - val_acc: 0.7734
Epoch 54/200
50000/50000 [==============================] - 76s - loss: 0.7756 - acc: 0.7364 - val_loss: 0.5995 - val_acc: 0.7975
Epoch 55/200
50000/50000 [==============================] - 76s - loss: 0.7827 - acc: 0.7343 - val_loss: 0.6601 - val_acc: 0.7790
Epoch 56/200
50000/50000 [==============================] - 76s - loss: 0.7874 - acc: 0.7304 - val_loss: 0.6625 - val_acc: 0.7778
Epoch 57/200
50000/50000 [==============================] - 76s - loss: 0.7774 - acc: 0.7342 - val_loss: 0.6231 - val_acc: 0.7911
Epoch 58/200
50000/50000 [==============================] - 76s - loss: 0.7860 - acc: 0.7345 - val_loss: 0.6105 - val_acc: 0.7919
Epoch 59/200
50000/50000 [==============================] - 76s - loss: 0.7811 - acc: 0.7351 - val_loss: 0.6368 - val_acc: 0.7878
Epoch 60/200
50000/50000 [==============================] - 76s - loss: 0.7789 - acc: 0.7348 - val_loss: 0.6162 - val_acc: 0.7921
Epoch 61/200
50000/50000 [==============================] - 76s - loss: 0.7691 - acc: 0.7381 - val_loss: 0.6361 - val_acc: 0.7871
Epoch 62/200
50000/50000 [==============================] - 76s - loss: 0.7702 - acc: 0.7387 - val_loss: 0.6054 - val_acc: 0.7973
Epoch 63/200
50000/50000 [==============================] - 76s - loss: 0.7648 - acc: 0.7397 - val_loss: 0.6482 - val_acc: 0.7834
Epoch 64/200
50000/50000 [==============================] - 76s - loss: 0.7740 - acc: 0.7377 - val_loss: 0.6198 - val_acc: 0.7928
Epoch 65/200
50000/50000 [==============================] - 76s - loss: 0.7740 - acc: 0.7365 - val_loss: 0.6422 - val_acc: 0.7905
Epoch 66/200
50000/50000 [==============================] - 76s - loss: 0.7761 - acc: 0.7359 - val_loss: 0.6330 - val_acc: 0.7930
Epoch 67/200
50000/50000 [==============================] - 76s - loss: 0.7794 - acc: 0.7355 - val_loss: 0.6669 - val_acc: 0.7791
Epoch 68/200
50000/50000 [==============================] - 76s - loss: 0.7669 - acc: 0.7397 - val_loss: 0.6447 - val_acc: 0.7833
Epoch 69/200
50000/50000 [==============================] - 76s - loss: 0.7710 - acc: 0.7383 - val_loss: 0.6148 - val_acc: 0.7909
Epoch 70/200
50000/50000 [==============================] - 76s - loss: 0.7747 - acc: 0.7386 - val_loss: 0.5887 - val_acc: 0.8049
Epoch 71/200
50000/50000 [==============================] - 76s - loss: 0.7647 - acc: 0.7419 - val_loss: 0.6251 - val_acc: 0.7881
Epoch 72/200
50000/50000 [==============================] - 76s - loss: 0.7553 - acc: 0.7441 - val_loss: 0.6539 - val_acc: 0.7817
Epoch 73/200
50000/50000 [==============================] - 76s - loss: 0.7621 - acc: 0.7403 - val_loss: 0.5972 - val_acc: 0.8002
Epoch 74/200
50000/50000 [==============================] - 76s - loss: 0.7616 - acc: 0.7431 - val_loss: 0.6404 - val_acc: 0.7866
Epoch 75/200
50000/50000 [==============================] - 76s - loss: 0.7592 - acc: 0.7431 - val_loss: 0.6202 - val_acc: 0.7933
Epoch 76/200
50000/50000 [==============================] - 76s - loss: 0.7681 - acc: 0.7390 - val_loss: 0.6046 - val_acc: 0.7981
Epoch 77/200
50000/50000 [==============================] - 76s - loss: 0.7731 - acc: 0.7384 - val_loss: 0.6021 - val_acc: 0.7999
Epoch 78/200
50000/50000 [==============================] - 76s - loss: 0.7774 - acc: 0.7387 - val_loss: 0.6239 - val_acc: 0.7917
Epoch 79/200
50000/50000 [==============================] - 76s - loss: 0.7631 - acc: 0.7447 - val_loss: 0.6359 - val_acc: 0.7900
Epoch 80/200
50000/50000 [==============================] - 76s - loss: 0.7575 - acc: 0.7453 - val_loss: 0.6017 - val_acc: 0.7990
Epoch 81/200
50000/50000 [==============================] - 76s - loss: 0.7690 - acc: 0.7404 - val_loss: 0.6458 - val_acc: 0.7867
Epoch 82/200
50000/50000 [==============================] - 76s - loss: 0.7695 - acc: 0.7385 - val_loss: 0.6348 - val_acc: 0.7865
Epoch 83/200
50000/50000 [==============================] - 76s - loss: 0.7638 - acc: 0.7407 - val_loss: 0.6066 - val_acc: 0.7944
Epoch 84/200
50000/50000 [==============================] - 76s - loss: 0.7626 - acc: 0.7423 - val_loss: 0.6236 - val_acc: 0.7945
Epoch 85/200
50000/50000 [==============================] - 76s - loss: 0.7546 - acc: 0.7465 - val_loss: 0.6414 - val_acc: 0.7852
Epoch 86/200
50000/50000 [==============================] - 76s - loss: 0.7510 - acc: 0.7487 - val_loss: 0.6109 - val_acc: 0.7995
Epoch 87/200
50000/50000 [==============================] - 76s - loss: 0.7498 - acc: 0.7469 - val_loss: 0.6685 - val_acc: 0.7741
Epoch 88/200
50000/50000 [==============================] - 76s - loss: 0.7585 - acc: 0.7441 - val_loss: 0.6080 - val_acc: 0.7967
Epoch 89/200
50000/50000 [==============================] - 76s - loss: 0.7554 - acc: 0.7463 - val_loss: 0.6430 - val_acc: 0.7870
Epoch 90/200
50000/50000 [==============================] - 76s - loss: 0.7624 - acc: 0.7452 - val_loss: 0.5973 - val_acc: 0.7988
Epoch 91/200
50000/50000 [==============================] - 76s - loss: 0.7602 - acc: 0.7448 - val_loss: 0.6068 - val_acc: 0.7984
Epoch 92/200
50000/50000 [==============================] - 76s - loss: 0.7668 - acc: 0.7421 - val_loss: 0.6461 - val_acc: 0.7817
Epoch 93/200
50000/50000 [==============================] - 76s - loss: 0.7599 - acc: 0.7453 - val_loss: 0.6302 - val_acc: 0.7904
Epoch 94/200
50000/50000 [==============================] - 76s - loss: 0.7564 - acc: 0.7462 - val_loss: 0.6124 - val_acc: 0.7990
Epoch 95/200
50000/50000 [==============================] - 76s - loss: 0.7528 - acc: 0.7464 - val_loss: 0.6377 - val_acc: 0.7873
Epoch 96/200
50000/50000 [==============================] - 76s - loss: 0.7519 - acc: 0.7464 - val_loss: 0.5868 - val_acc: 0.8048
Epoch 97/200
50000/50000 [==============================] - 76s - loss: 0.7520 - acc: 0.7477 - val_loss: 0.6192 - val_acc: 0.7941
Epoch 98/200
50000/50000 [==============================] - 76s - loss: 0.7599 - acc: 0.7443 - val_loss: 0.6191 - val_acc: 0.7915
Epoch 99/200
50000/50000 [==============================] - 76s - loss: 0.7587 - acc: 0.7438 - val_loss: 0.5945 - val_acc: 0.8023
Epoch 100/200
50000/50000 [==============================] - 76s - loss: 0.7470 - acc: 0.7476 - val_loss: 0.6114 - val_acc: 0.7952
Epoch 101/200
50000/50000 [==============================] - 76s - loss: 0.7474 - acc: 0.7470 - val_loss: 0.6055 - val_acc: 0.8006
Epoch 102/200
50000/50000 [==============================] - 76s - loss: 0.7563 - acc: 0.7454 - val_loss: 0.6149 - val_acc: 0.7951
Epoch 103/200
50000/50000 [==============================] - 76s - loss: 0.7413 - acc: 0.7497 - val_loss: 0.6068 - val_acc: 0.7968
Epoch 104/200
50000/50000 [==============================] - 76s - loss: 0.7511 - acc: 0.7476 - val_loss: 0.6027 - val_acc: 0.7974
Epoch 105/200
50000/50000 [==============================] - 76s - loss: 0.7431 - acc: 0.7507 - val_loss: 0.6190 - val_acc: 0.7923
Epoch 106/200
50000/50000 [==============================] - 76s - loss: 0.7384 - acc: 0.7508 - val_loss: 0.6523 - val_acc: 0.7861
Epoch 107/200
50000/50000 [==============================] - 76s - loss: 0.7476 - acc: 0.7481 - val_loss: 0.5939 - val_acc: 0.7994
Epoch 108/200
50000/50000 [==============================] - 76s - loss: 0.7350 - acc: 0.7524 - val_loss: 0.5933 - val_acc: 0.7977
Epoch 109/200
50000/50000 [==============================] - 76s - loss: 0.7392 - acc: 0.7497 - val_loss: 0.6073 - val_acc: 0.7924
Epoch 110/200
50000/50000 [==============================] - 76s - loss: 0.7387 - acc: 0.7527 - val_loss: 0.5676 - val_acc: 0.8094
Epoch 111/200
50000/50000 [==============================] - 76s - loss: 0.7437 - acc: 0.7505 - val_loss: 0.6051 - val_acc: 0.7988
Epoch 112/200
50000/50000 [==============================] - 76s - loss: 0.7405 - acc: 0.7532 - val_loss: 0.5682 - val_acc: 0.8095
Epoch 113/200
50000/50000 [==============================] - 76s - loss: 0.7385 - acc: 0.7524 - val_loss: 0.5759 - val_acc: 0.8035
Epoch 114/200
50000/50000 [==============================] - 76s - loss: 0.7296 - acc: 0.7543 - val_loss: 0.5756 - val_acc: 0.8052
Epoch 115/200
50000/50000 [==============================] - 76s - loss: 0.7369 - acc: 0.7538 - val_loss: 0.5877 - val_acc: 0.8047
Epoch 116/200
50000/50000 [==============================] - 76s - loss: 0.7392 - acc: 0.7508 - val_loss: 0.6160 - val_acc: 0.7924
Epoch 117/200
50000/50000 [==============================] - 76s - loss: 0.7298 - acc: 0.7520 - val_loss: 0.5999 - val_acc: 0.8032
Epoch 118/200
50000/50000 [==============================] - 76s - loss: 0.7387 - acc: 0.7522 - val_loss: 0.5664 - val_acc: 0.8118
Epoch 119/200
50000/50000 [==============================] - 76s - loss: 0.7453 - acc: 0.7509 - val_loss: 0.6278 - val_acc: 0.7931
Epoch 120/200
50000/50000 [==============================] - 76s - loss: 0.7248 - acc: 0.7559 - val_loss: 0.6112 - val_acc: 0.7983
Epoch 121/200
50000/50000 [==============================] - 76s - loss: 0.7312 - acc: 0.7556 - val_loss: 0.5775 - val_acc: 0.8083
Epoch 122/200
50000/50000 [==============================] - 76s - loss: 0.7328 - acc: 0.7554 - val_loss: 0.5893 - val_acc: 0.8053
Epoch 123/200
50000/50000 [==============================] - 76s - loss: 0.7261 - acc: 0.7542 - val_loss: 0.5827 - val_acc: 0.8025
Epoch 124/200
50000/50000 [==============================] - 76s - loss: 0.7279 - acc: 0.7565 - val_loss: 0.6075 - val_acc: 0.7965
Epoch 125/200
50000/50000 [==============================] - 76s - loss: 0.7365 - acc: 0.7528 - val_loss: 0.6252 - val_acc: 0.7951
Epoch 126/200
50000/50000 [==============================] - 76s - loss: 0.7283 - acc: 0.7568 - val_loss: 0.5970 - val_acc: 0.8019
Epoch 127/200
50000/50000 [==============================] - 76s - loss: 0.7363 - acc: 0.7535 - val_loss: 0.5758 - val_acc: 0.8119
Epoch 128/200
50000/50000 [==============================] - 76s - loss: 0.7315 - acc: 0.7549 - val_loss: 0.5887 - val_acc: 0.8061
Epoch 129/200
50000/50000 [==============================] - 76s - loss: 0.7307 - acc: 0.7556 - val_loss: 0.5978 - val_acc: 0.8021
Epoch 130/200
50000/50000 [==============================] - 76s - loss: 0.7293 - acc: 0.7559 - val_loss: 0.6001 - val_acc: 0.8020
Epoch 131/200
50000/50000 [==============================] - 76s - loss: 0.7322 - acc: 0.7529 - val_loss: 0.5939 - val_acc: 0.8029
Epoch 132/200
50000/50000 [==============================] - 76s - loss: 0.7301 - acc: 0.7570 - val_loss: 0.6338 - val_acc: 0.7894
Epoch 133/200
50000/50000 [==============================] - 76s - loss: 0.7263 - acc: 0.7559 - val_loss: 0.5825 - val_acc: 0.8084
Epoch 134/200
50000/50000 [==============================] - 76s - loss: 0.7332 - acc: 0.7528 - val_loss: 0.6118 - val_acc: 0.7957
Epoch 135/200
50000/50000 [==============================] - 76s - loss: 0.7296 - acc: 0.7526 - val_loss: 0.5887 - val_acc: 0.8032
Epoch 136/200
50000/50000 [==============================] - 76s - loss: 0.7275 - acc: 0.7548 - val_loss: 0.5969 - val_acc: 0.8013
Epoch 137/200
50000/50000 [==============================] - 76s - loss: 0.7276 - acc: 0.7571 - val_loss: 0.6161 - val_acc: 0.7978
Epoch 138/200
50000/50000 [==============================] - 76s - loss: 0.7257 - acc: 0.7563 - val_loss: 0.6023 - val_acc: 0.7996
Epoch 139/200
50000/50000 [==============================] - 76s - loss: 0.7164 - acc: 0.7609 - val_loss: 0.5737 - val_acc: 0.8136
Epoch 140/200
50000/50000 [==============================] - 76s - loss: 0.7202 - acc: 0.7594 - val_loss: 0.6093 - val_acc: 0.7986
Epoch 141/200
50000/50000 [==============================] - 76s - loss: 0.7259 - acc: 0.7553 - val_loss: 0.5765 - val_acc: 0.8109
Epoch 142/200
50000/50000 [==============================] - 76s - loss: 0.7169 - acc: 0.7580 - val_loss: 0.6152 - val_acc: 0.7950
Epoch 143/200
50000/50000 [==============================] - 76s - loss: 0.7190 - acc: 0.7579 - val_loss: 0.5963 - val_acc: 0.8045
Epoch 144/200
50000/50000 [==============================] - 76s - loss: 0.7144 - acc: 0.7611 - val_loss: 0.5938 - val_acc: 0.8055
Epoch 145/200
50000/50000 [==============================] - 76s - loss: 0.7295 - acc: 0.7582 - val_loss: 0.5690 - val_acc: 0.8109
Epoch 146/200
50000/50000 [==============================] - 76s - loss: 0.7194 - acc: 0.7596 - val_loss: 0.5589 - val_acc: 0.8170
Epoch 147/200
50000/50000 [==============================] - 76s - loss: 0.7152 - acc: 0.7607 - val_loss: 0.5825 - val_acc: 0.8132
Epoch 148/200
50000/50000 [==============================] - 76s - loss: 0.7184 - acc: 0.7575 - val_loss: 0.5864 - val_acc: 0.8087
Epoch 149/200
50000/50000 [==============================] - 76s - loss: 0.7226 - acc: 0.7589 - val_loss: 0.5720 - val_acc: 0.8105
Epoch 150/200
50000/50000 [==============================] - 76s - loss: 0.7039 - acc: 0.7639 - val_loss: 0.6120 - val_acc: 0.7999
Epoch 151/200
50000/50000 [==============================] - 76s - loss: 0.7093 - acc: 0.7616 - val_loss: 0.5781 - val_acc: 0.8074
Epoch 152/200
50000/50000 [==============================] - 76s - loss: 0.7188 - acc: 0.7580 - val_loss: 0.5809 - val_acc: 0.8072
Epoch 153/200
50000/50000 [==============================] - 76s - loss: 0.7039 - acc: 0.7645 - val_loss: 0.5686 - val_acc: 0.8101
Epoch 154/200
50000/50000 [==============================] - 76s - loss: 0.7031 - acc: 0.7631 - val_loss: 0.5633 - val_acc: 0.8188
Epoch 155/200
50000/50000 [==============================] - 76s - loss: 0.7164 - acc: 0.7616 - val_loss: 0.5946 - val_acc: 0.8037
Epoch 156/200
50000/50000 [==============================] - 76s - loss: 0.7172 - acc: 0.7603 - val_loss: 0.6074 - val_acc: 0.7958
Epoch 157/200
50000/50000 [==============================] - 76s - loss: 0.7156 - acc: 0.7605 - val_loss: 0.5792 - val_acc: 0.8122
Epoch 158/200
50000/50000 [==============================] - 76s - loss: 0.7089 - acc: 0.7625 - val_loss: 0.5674 - val_acc: 0.8121
Epoch 159/200
50000/50000 [==============================] - 76s - loss: 0.7148 - acc: 0.7626 - val_loss: 0.5708 - val_acc: 0.8125
Epoch 160/200
50000/50000 [==============================] - 76s - loss: 0.7158 - acc: 0.7607 - val_loss: 0.5711 - val_acc: 0.8133
Epoch 161/200
50000/50000 [==============================] - 76s - loss: 0.7164 - acc: 0.7597 - val_loss: 0.5829 - val_acc: 0.8084
Epoch 162/200
50000/50000 [==============================] - 76s - loss: 0.7058 - acc: 0.7637 - val_loss: 0.6212 - val_acc: 0.7972
Epoch 163/200
50000/50000 [==============================] - 76s - loss: 0.7068 - acc: 0.7642 - val_loss: 0.5546 - val_acc: 0.8163
Epoch 164/200
50000/50000 [==============================] - 76s - loss: 0.7141 - acc: 0.7611 - val_loss: 0.5739 - val_acc: 0.8075
Epoch 165/200
50000/50000 [==============================] - 76s - loss: 0.7082 - acc: 0.7644 - val_loss: 0.6128 - val_acc: 0.7973
Epoch 166/200
50000/50000 [==============================] - 76s - loss: 0.7053 - acc: 0.7644 - val_loss: 0.5710 - val_acc: 0.8124
Epoch 167/200
50000/50000 [==============================] - 76s - loss: 0.7212 - acc: 0.7582 - val_loss: 0.6079 - val_acc: 0.8005
Epoch 168/200
50000/50000 [==============================] - 76s - loss: 0.7109 - acc: 0.7606 - val_loss: 0.5686 - val_acc: 0.8114
Epoch 169/200
50000/50000 [==============================] - 76s - loss: 0.7084 - acc: 0.7618 - val_loss: 0.5450 - val_acc: 0.8177
Epoch 170/200
50000/50000 [==============================] - 76s - loss: 0.6988 - acc: 0.7673 - val_loss: 0.5380 - val_acc: 0.8234
Epoch 171/200
50000/50000 [==============================] - 76s - loss: 0.7067 - acc: 0.7636 - val_loss: 0.5669 - val_acc: 0.8122
Epoch 172/200
50000/50000 [==============================] - 76s - loss: 0.7114 - acc: 0.7621 - val_loss: 0.5969 - val_acc: 0.8018
Epoch 173/200
50000/50000 [==============================] - 76s - loss: 0.7129 - acc: 0.7612 - val_loss: 0.6048 - val_acc: 0.7977
Epoch 174/200
50000/50000 [==============================] - 76s - loss: 0.7102 - acc: 0.7620 - val_loss: 0.5934 - val_acc: 0.8059
Epoch 175/200
50000/50000 [==============================] - 76s - loss: 0.7037 - acc: 0.7647 - val_loss: 0.5651 - val_acc: 0.8145
Epoch 176/200
50000/50000 [==============================] - 76s - loss: 0.7007 - acc: 0.7675 - val_loss: 0.6244 - val_acc: 0.7921
Epoch 177/200
50000/50000 [==============================] - 76s - loss: 0.6965 - acc: 0.7671 - val_loss: 0.6227 - val_acc: 0.7928
Epoch 178/200
50000/50000 [==============================] - 76s - loss: 0.7074 - acc: 0.7642 - val_loss: 0.5712 - val_acc: 0.8093
Epoch 179/200
50000/50000 [==============================] - 76s - loss: 0.6923 - acc: 0.7697 - val_loss: 0.5644 - val_acc: 0.8142
Epoch 180/200
50000/50000 [==============================] - 76s - loss: 0.7036 - acc: 0.7661 - val_loss: 0.5758 - val_acc: 0.8126
Epoch 181/200
50000/50000 [==============================] - 76s - loss: 0.6989 - acc: 0.7658 - val_loss: 0.5553 - val_acc: 0.8160
Epoch 182/200
50000/50000 [==============================] - 76s - loss: 0.6995 - acc: 0.7659 - val_loss: 0.5605 - val_acc: 0.8146
Epoch 183/200
50000/50000 [==============================] - 76s - loss: 0.7007 - acc: 0.7649 - val_loss: 0.5660 - val_acc: 0.8102
Epoch 184/200
50000/50000 [==============================] - 76s - loss: 0.6972 - acc: 0.7675 - val_loss: 0.6031 - val_acc: 0.7981
Epoch 185/200
50000/50000 [==============================] - 76s - loss: 0.7101 - acc: 0.7612 - val_loss: 0.5707 - val_acc: 0.8050
Epoch 186/200
50000/50000 [==============================] - 76s - loss: 0.6900 - acc: 0.7681 - val_loss: 0.5437 - val_acc: 0.8223
Epoch 187/200
50000/50000 [==============================] - 76s - loss: 0.6989 - acc: 0.7663 - val_loss: 0.5826 - val_acc: 0.8072
Epoch 188/200
50000/50000 [==============================] - 76s - loss: 0.6892 - acc: 0.7699 - val_loss: 0.5498 - val_acc: 0.8202
Epoch 189/200
50000/50000 [==============================] - 76s - loss: 0.7000 - acc: 0.7678 - val_loss: 0.5809 - val_acc: 0.8090
Epoch 190/200
50000/50000 [==============================] - 76s - loss: 0.6834 - acc: 0.7712 - val_loss: 0.5624 - val_acc: 0.8173
Epoch 191/200
50000/50000 [==============================] - 76s - loss: 0.6854 - acc: 0.7706 - val_loss: 0.5764 - val_acc: 0.8124
Epoch 192/200
50000/50000 [==============================] - 76s - loss: 0.6951 - acc: 0.7665 - val_loss: 0.5545 - val_acc: 0.8145
Epoch 193/200
50000/50000 [==============================] - 76s - loss: 0.6849 - acc: 0.7694 - val_loss: 0.5607 - val_acc: 0.8166
Epoch 194/200
50000/50000 [==============================] - 76s - loss: 0.7010 - acc: 0.7661 - val_loss: 0.5554 - val_acc: 0.8209
Epoch 195/200
50000/50000 [==============================] - 76s - loss: 0.6956 - acc: 0.7693 - val_loss: 0.5482 - val_acc: 0.8198
Epoch 196/200
50000/50000 [==============================] - 76s - loss: 0.6918 - acc: 0.7677 - val_loss: 0.5510 - val_acc: 0.8191
Epoch 197/200
50000/50000 [==============================] - 76s - loss: 0.6879 - acc: 0.7691 - val_loss: 0.5459 - val_acc: 0.8196
Epoch 198/200
50000/50000 [==============================] - 76s - loss: 0.6904 - acc: 0.7689 - val_loss: 0.5865 - val_acc: 0.8061
Epoch 199/200
50000/50000 [==============================] - 76s - loss: 0.6916 - acc: 0.7691 - val_loss: 0.5646 - val_acc: 0.8109
Epoch 200/200
50000/50000 [==============================] - 76s - loss: 0.6865 - acc: 0.7694 - val_loss: 0.6151 - val_acc: 0.7979


python stateful_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Generating Data
Input shape: (50000, 1, 1)
Output shape
(50000, 1)
Creating Model
Training
Epoch 0 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 347.6594    
Epoch 1 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 155.6363    
Epoch 2 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 81.5722    
Epoch 3 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 48.3305    
Epoch 4 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 30.9629    
Epoch 5 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 21.0955    
Epoch 6 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 15.2851    
Epoch 7 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 11.8137    
Epoch 8 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 9.7596    
Epoch 9 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 8.6144    
Epoch 10 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 6.8574    
Epoch 11 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 5.4063    
Epoch 12 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.7967    
Epoch 13 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.3603    
Epoch 14 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.9979    
Epoch 15 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.6330    
Epoch 16 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.5952    
Epoch 17 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.3124    
Epoch 18 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.0268    
Epoch 19 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.0712    
Epoch 20 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.7632    
Epoch 21 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.1311    
Epoch 22 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.3231    
Epoch 23 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.4092    
Epoch 24 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.0051    
Predicting
Ploting Results


python babi_rnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 50, 100, 100
vocab = [u'.', u'?', u'Daniel', u'John', u'Mary', u'Sandra', u'Where', u'apple', u'back', u'bathroom', u'bedroom', u'discarded', u'down', u'dropped', u'football', u'garden', u'got', u'grabbed', u'hallway', u'is', u'journeyed', u'kitchen', u'left', u'milk', u'moved', u'office', u'picked', u'put', u'the', u'there', u'to', u'took', u'travelled', u'up', u'went']
X.shape = (1000, 552)
Xq.shape = (1000, 5)
Y.shape = (1000, 36)
story_maxlen, query_maxlen = 552, 5
Build model...
Training
Train on 950 samples, validate on 50 samples
Epoch 1/40
950/950 [==============================] - 9s - loss: 3.0771 - acc: 0.1895 - val_loss: 2.6338 - val_acc: 0.0600
Epoch 2/40
950/950 [==============================] - 9s - loss: 2.1378 - acc: 0.1884 - val_loss: 1.9316 - val_acc: 0.0600
Epoch 3/40
950/950 [==============================] - 9s - loss: 1.9409 - acc: 0.1916 - val_loss: 1.8471 - val_acc: 0.0600
Epoch 4/40
950/950 [==============================] - 9s - loss: 1.9016 - acc: 0.1947 - val_loss: 1.8591 - val_acc: 0.0600
Epoch 5/40
950/950 [==============================] - 9s - loss: 1.8757 - acc: 0.1937 - val_loss: 1.8523 - val_acc: 0.0600
Epoch 6/40
950/950 [==============================] - 9s - loss: 1.8856 - acc: 0.1958 - val_loss: 1.8721 - val_acc: 0.0600
Epoch 7/40
950/950 [==============================] - 9s - loss: 1.8953 - acc: 0.1705 - val_loss: 1.8137 - val_acc: 0.1400
Epoch 8/40
950/950 [==============================] - 9s - loss: 1.8641 - acc: 0.1874 - val_loss: 1.8301 - val_acc: 0.0600
Epoch 9/40
950/950 [==============================] - 9s - loss: 1.8720 - acc: 0.1811 - val_loss: 1.8262 - val_acc: 0.0600
Epoch 10/40
950/950 [==============================] - 9s - loss: 1.8619 - acc: 0.1895 - val_loss: 1.8139 - val_acc: 0.0600
Epoch 11/40
950/950 [==============================] - 9s - loss: 1.8443 - acc: 0.1916 - val_loss: 1.8612 - val_acc: 0.0600
Epoch 12/40
950/950 [==============================] - 9s - loss: 1.8156 - acc: 0.1937 - val_loss: 1.8204 - val_acc: 0.0600
Epoch 13/40
950/950 [==============================] - 9s - loss: 1.8356 - acc: 0.1863 - val_loss: 1.7687 - val_acc: 0.3000
Epoch 14/40
950/950 [==============================] - 9s - loss: 1.8339 - acc: 0.1768 - val_loss: 1.7887 - val_acc: 0.1400
Epoch 15/40
950/950 [==============================] - 9s - loss: 1.8161 - acc: 0.1979 - val_loss: 1.8206 - val_acc: 0.0600
Epoch 16/40
950/950 [==============================] - 9s - loss: 1.8239 - acc: 0.2232 - val_loss: 1.7962 - val_acc: 0.1600
Epoch 17/40
950/950 [==============================] - 9s - loss: 1.7992 - acc: 0.2200 - val_loss: 1.7704 - val_acc: 0.2400
Epoch 18/40
950/950 [==============================] - 9s - loss: 1.8092 - acc: 0.2105 - val_loss: 1.7604 - val_acc: 0.2600
Epoch 19/40
950/950 [==============================] - 9s - loss: 1.7945 - acc: 0.2326 - val_loss: 1.8006 - val_acc: 0.1600
Epoch 20/40
950/950 [==============================] - 9s - loss: 1.7948 - acc: 0.2284 - val_loss: 1.8224 - val_acc: 0.1600
Epoch 21/40
950/950 [==============================] - 9s - loss: 1.7885 - acc: 0.2295 - val_loss: 1.7620 - val_acc: 0.2400
Epoch 22/40
950/950 [==============================] - 9s - loss: 1.7695 - acc: 0.2474 - val_loss: 1.7608 - val_acc: 0.2000
Epoch 23/40
950/950 [==============================] - 9s - loss: 1.7567 - acc: 0.2526 - val_loss: 1.6990 - val_acc: 0.3200
Epoch 24/40
950/950 [==============================] - 9s - loss: 1.7521 - acc: 0.2621 - val_loss: 1.7765 - val_acc: 0.2200
Epoch 25/40
950/950 [==============================] - 9s - loss: 1.7814 - acc: 0.2516 - val_loss: 1.6995 - val_acc: 0.3400
Epoch 26/40
950/950 [==============================] - 9s - loss: 1.7519 - acc: 0.2495 - val_loss: 1.7735 - val_acc: 0.2000
Epoch 27/40
950/950 [==============================] - 9s - loss: 1.7379 - acc: 0.3000 - val_loss: 1.7080 - val_acc: 0.3600
Epoch 28/40
950/950 [==============================] - 9s - loss: 1.7266 - acc: 0.2832 - val_loss: 1.8205 - val_acc: 0.1800
Epoch 29/40
950/950 [==============================] - 9s - loss: 1.7199 - acc: 0.2937 - val_loss: 1.6843 - val_acc: 0.3600
Epoch 30/40
950/950 [==============================] - 9s - loss: 1.7142 - acc: 0.2947 - val_loss: 1.6985 - val_acc: 0.3400
Epoch 31/40
950/950 [==============================] - 9s - loss: 1.7070 - acc: 0.3147 - val_loss: 1.7812 - val_acc: 0.2000
Epoch 32/40
950/950 [==============================] - 9s - loss: 1.7164 - acc: 0.2947 - val_loss: 1.6878 - val_acc: 0.3600
Epoch 33/40
950/950 [==============================] - 9s - loss: 1.7086 - acc: 0.3063 - val_loss: 1.7184 - val_acc: 0.3000
Epoch 34/40
950/950 [==============================] - 9s - loss: 1.6891 - acc: 0.3253 - val_loss: 1.8076 - val_acc: 0.3000
Epoch 35/40
950/950 [==============================] - 9s - loss: 1.7639 - acc: 0.2947 - val_loss: 1.7174 - val_acc: 0.3400
Epoch 36/40
950/950 [==============================] - 9s - loss: 1.7231 - acc: 0.2937 - val_loss: 1.7030 - val_acc: 0.3400
Epoch 37/40
950/950 [==============================] - 9s - loss: 1.6799 - acc: 0.3337 - val_loss: 1.6776 - val_acc: 0.3000
Epoch 38/40
950/950 [==============================] - 9s - loss: 1.6726 - acc: 0.3368 - val_loss: 1.7101 - val_acc: 0.3000
Epoch 39/40
950/950 [==============================] - 9s - loss: 1.6822 - acc: 0.3211 - val_loss: 1.6596 - val_acc: 0.3400
Epoch 40/40
950/950 [==============================] - 9s - loss: 1.7062 - acc: 0.3253 - val_loss: 1.6936 - val_acc: 0.3000
1000/1000 [==============================] - 4s     
Test loss / test accuracy = 1.7147 / 0.2820


python babi_memnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Extracting stories for the challenge: single_supporting_fact_10k
-
Vocab size: 22 unique words
Story max length: 68 words
Query max length: 4 words
Number of training stories: 10000
Number of test stories: 1000
-
Here's what a "story" tuple looks like (input, query, answer):
([u'Mary', u'moved', u'to', u'the', u'bathroom', u'.', u'John', u'went', u'to', u'the', u'hallway', u'.'], [u'Where', u'is', u'Mary', u'?'], u'bathroom')
-
Vectorizing the word sequences...
-
inputs: integer tensor of shape (samples, max_length)
inputs_train shape: (10000, 68)
inputs_test shape: (1000, 68)
-
queries: integer tensor of shape (samples, max_length)
queries_train shape: (10000, 4)
queries_test shape: (1000, 4)
-
answers: binary (1 or 0) tensor of shape (samples, vocab_size)
answers_train shape: (10000, 22)
answers_test shape: (1000, 22)
-
Compiling...
Train on 10000 samples, validate on 1000 samples
Epoch 1/120
10000/10000 [==============================] - 2s - loss: 2.0684 - acc: 0.1614 - val_loss: 1.8024 - val_acc: 0.1910
Epoch 2/120
10000/10000 [==============================] - 2s - loss: 1.8320 - acc: 0.1687 - val_loss: 1.7971 - val_acc: 0.1830
Epoch 3/120
10000/10000 [==============================] - 2s - loss: 1.8149 - acc: 0.1700 - val_loss: 1.7831 - val_acc: 0.2340
Epoch 4/120
10000/10000 [==============================] - 2s - loss: 1.7436 - acc: 0.2401 - val_loss: 1.6922 - val_acc: 0.2660
Epoch 5/120
10000/10000 [==============================] - 2s - loss: 1.6658 - acc: 0.3098 - val_loss: 1.6491 - val_acc: 0.3380
Epoch 6/120
10000/10000 [==============================] - 2s - loss: 1.6266 - acc: 0.3495 - val_loss: 1.5923 - val_acc: 0.3820
Epoch 7/120
10000/10000 [==============================] - 2s - loss: 1.5655 - acc: 0.3923 - val_loss: 1.5462 - val_acc: 0.4120
Epoch 8/120
10000/10000 [==============================] - 2s - loss: 1.5236 - acc: 0.4057 - val_loss: 1.5058 - val_acc: 0.4260
Epoch 9/120
10000/10000 [==============================] - 2s - loss: 1.5016 - acc: 0.4228 - val_loss: 1.4919 - val_acc: 0.4410
Epoch 10/120
10000/10000 [==============================] - 2s - loss: 1.4930 - acc: 0.4346 - val_loss: 1.4726 - val_acc: 0.4360
Epoch 11/120
10000/10000 [==============================] - 2s - loss: 1.4723 - acc: 0.4467 - val_loss: 1.4373 - val_acc: 0.4560
Epoch 12/120
10000/10000 [==============================] - 2s - loss: 1.4295 - acc: 0.4667 - val_loss: 1.3905 - val_acc: 0.4710
Epoch 13/120
10000/10000 [==============================] - 2s - loss: 1.4027 - acc: 0.4683 - val_loss: 1.3723 - val_acc: 0.4800
Epoch 14/120
10000/10000 [==============================] - 2s - loss: 1.3901 - acc: 0.4763 - val_loss: 1.3644 - val_acc: 0.4820
Epoch 15/120
10000/10000 [==============================] - 2s - loss: 1.3719 - acc: 0.4819 - val_loss: 1.3797 - val_acc: 0.4820
Epoch 16/120
10000/10000 [==============================] - 2s - loss: 1.3710 - acc: 0.4807 - val_loss: 1.3497 - val_acc: 0.4940
Epoch 17/120
10000/10000 [==============================] - 2s - loss: 1.3716 - acc: 0.4787 - val_loss: 1.3433 - val_acc: 0.5040
Epoch 18/120
10000/10000 [==============================] - 2s - loss: 1.3657 - acc: 0.4836 - val_loss: 1.3385 - val_acc: 0.5080
Epoch 19/120
10000/10000 [==============================] - 2s - loss: 1.3575 - acc: 0.4859 - val_loss: 1.3291 - val_acc: 0.5120
Epoch 20/120
10000/10000 [==============================] - 2s - loss: 1.3514 - acc: 0.4920 - val_loss: 1.3421 - val_acc: 0.5030
Epoch 21/120
10000/10000 [==============================] - 2s - loss: 1.3395 - acc: 0.4992 - val_loss: 1.3391 - val_acc: 0.5010
Epoch 22/120
10000/10000 [==============================] - 2s - loss: 1.3555 - acc: 0.4843 - val_loss: 1.3272 - val_acc: 0.4940
Epoch 23/120
10000/10000 [==============================] - 2s - loss: 1.3452 - acc: 0.4928 - val_loss: 1.3166 - val_acc: 0.5160
Epoch 24/120
10000/10000 [==============================] - 2s - loss: 1.3396 - acc: 0.4939 - val_loss: 1.3166 - val_acc: 0.5240
Epoch 25/120
10000/10000 [==============================] - 2s - loss: 1.3374 - acc: 0.4962 - val_loss: 1.3190 - val_acc: 0.5140
Epoch 26/120
10000/10000 [==============================] - 2s - loss: 1.3275 - acc: 0.5017 - val_loss: 1.3016 - val_acc: 0.5260
Epoch 27/120
10000/10000 [==============================] - 2s - loss: 1.3168 - acc: 0.4994 - val_loss: 1.3031 - val_acc: 0.5230
Epoch 28/120
10000/10000 [==============================] - 2s - loss: 1.3075 - acc: 0.5065 - val_loss: 1.2768 - val_acc: 0.5340
Epoch 29/120
10000/10000 [==============================] - 2s - loss: 1.2929 - acc: 0.5134 - val_loss: 1.2645 - val_acc: 0.5240
Epoch 30/120
10000/10000 [==============================] - 2s - loss: 1.2774 - acc: 0.5111 - val_loss: 1.2328 - val_acc: 0.5340
Epoch 31/120
10000/10000 [==============================] - 2s - loss: 1.2598 - acc: 0.5112 - val_loss: 1.2129 - val_acc: 0.5340
Epoch 32/120
10000/10000 [==============================] - 2s - loss: 1.2564 - acc: 0.5101 - val_loss: 1.2069 - val_acc: 0.5290
Epoch 33/120
10000/10000 [==============================] - 2s - loss: 1.2544 - acc: 0.5163 - val_loss: 1.2129 - val_acc: 0.5240
Epoch 34/120
10000/10000 [==============================] - 2s - loss: 1.2536 - acc: 0.5125 - val_loss: 1.2122 - val_acc: 0.5340
Epoch 35/120
10000/10000 [==============================] - 2s - loss: 1.2309 - acc: 0.5224 - val_loss: 1.2086 - val_acc: 0.5290
Epoch 36/120
10000/10000 [==============================] - 2s - loss: 1.2328 - acc: 0.5244 - val_loss: 1.2028 - val_acc: 0.5250
Epoch 37/120
10000/10000 [==============================] - 2s - loss: 1.2279 - acc: 0.5234 - val_loss: 1.1873 - val_acc: 0.5250
Epoch 38/120
10000/10000 [==============================] - 2s - loss: 1.2292 - acc: 0.5200 - val_loss: 1.1921 - val_acc: 0.5220
Epoch 39/120
10000/10000 [==============================] - 2s - loss: 1.2157 - acc: 0.5239 - val_loss: 1.1803 - val_acc: 0.5310
Epoch 40/120
10000/10000 [==============================] - 2s - loss: 1.2154 - acc: 0.5225 - val_loss: 1.1868 - val_acc: 0.5360
Epoch 41/120
10000/10000 [==============================] - 2s - loss: 1.2029 - acc: 0.5326 - val_loss: 1.1595 - val_acc: 0.5350
Epoch 42/120
10000/10000 [==============================] - 2s - loss: 1.1928 - acc: 0.5325 - val_loss: 1.1399 - val_acc: 0.5420
Epoch 43/120
10000/10000 [==============================] - 2s - loss: 1.1680 - acc: 0.5400 - val_loss: 1.0980 - val_acc: 0.5510
Epoch 44/120
10000/10000 [==============================] - 2s - loss: 1.1261 - acc: 0.5565 - val_loss: 1.0249 - val_acc: 0.5660
Epoch 45/120
10000/10000 [==============================] - 2s - loss: 1.0717 - acc: 0.5863 - val_loss: 0.9660 - val_acc: 0.6150
Epoch 46/120
10000/10000 [==============================] - 2s - loss: 1.0060 - acc: 0.6164 - val_loss: 0.8830 - val_acc: 0.6610
Epoch 47/120
10000/10000 [==============================] - 2s - loss: 0.9485 - acc: 0.6438 - val_loss: 0.8458 - val_acc: 0.6840
Epoch 48/120
10000/10000 [==============================] - 2s - loss: 0.9100 - acc: 0.6621 - val_loss: 0.7885 - val_acc: 0.7060
Epoch 49/120
10000/10000 [==============================] - 2s - loss: 0.8696 - acc: 0.6837 - val_loss: 0.7571 - val_acc: 0.7210
Epoch 50/120
10000/10000 [==============================] - 2s - loss: 0.8328 - acc: 0.6947 - val_loss: 0.7357 - val_acc: 0.7330
Epoch 51/120
10000/10000 [==============================] - 2s - loss: 0.8157 - acc: 0.7094 - val_loss: 0.7151 - val_acc: 0.7400
Epoch 52/120
10000/10000 [==============================] - 2s - loss: 0.7821 - acc: 0.7213 - val_loss: 0.7079 - val_acc: 0.7410
Epoch 53/120
10000/10000 [==============================] - 2s - loss: 0.7701 - acc: 0.7267 - val_loss: 0.6937 - val_acc: 0.7450
Epoch 54/120
10000/10000 [==============================] - 2s - loss: 0.7550 - acc: 0.7294 - val_loss: 0.6726 - val_acc: 0.7480
Epoch 55/120
10000/10000 [==============================] - 2s - loss: 0.7442 - acc: 0.7335 - val_loss: 0.6579 - val_acc: 0.7480
Epoch 56/120
10000/10000 [==============================] - 2s - loss: 0.7177 - acc: 0.7420 - val_loss: 0.6560 - val_acc: 0.7460
Epoch 57/120
10000/10000 [==============================] - 2s - loss: 0.7126 - acc: 0.7411 - val_loss: 0.6373 - val_acc: 0.7480
Epoch 58/120
10000/10000 [==============================] - 2s - loss: 0.7026 - acc: 0.7427 - val_loss: 0.6363 - val_acc: 0.7470
Epoch 59/120
10000/10000 [==============================] - 2s - loss: 0.6832 - acc: 0.7533 - val_loss: 0.6168 - val_acc: 0.7550
Epoch 60/120
10000/10000 [==============================] - 2s - loss: 0.6719 - acc: 0.7514 - val_loss: 0.6142 - val_acc: 0.7530
Epoch 61/120
10000/10000 [==============================] - 2s - loss: 0.6594 - acc: 0.7580 - val_loss: 0.5949 - val_acc: 0.7530
Epoch 62/120
10000/10000 [==============================] - 2s - loss: 0.6415 - acc: 0.7626 - val_loss: 0.5775 - val_acc: 0.7540
Epoch 63/120
10000/10000 [==============================] - 2s - loss: 0.6265 - acc: 0.7668 - val_loss: 0.5656 - val_acc: 0.7610
Epoch 64/120
10000/10000 [==============================] - 2s - loss: 0.6155 - acc: 0.7735 - val_loss: 0.5516 - val_acc: 0.7600
Epoch 65/120
10000/10000 [==============================] - 2s - loss: 0.5980 - acc: 0.7741 - val_loss: 0.5402 - val_acc: 0.7720
Epoch 66/120
10000/10000 [==============================] - 2s - loss: 0.5843 - acc: 0.7814 - val_loss: 0.5325 - val_acc: 0.7640
Epoch 67/120
10000/10000 [==============================] - 2s - loss: 0.5734 - acc: 0.7859 - val_loss: 0.5219 - val_acc: 0.7840
Epoch 68/120
10000/10000 [==============================] - 2s - loss: 0.5581 - acc: 0.7857 - val_loss: 0.5135 - val_acc: 0.7960
Epoch 69/120
10000/10000 [==============================] - 2s - loss: 0.5467 - acc: 0.7934 - val_loss: 0.4978 - val_acc: 0.7930
Epoch 70/120
10000/10000 [==============================] - 2s - loss: 0.5431 - acc: 0.7978 - val_loss: 0.4823 - val_acc: 0.8020
Epoch 71/120
10000/10000 [==============================] - 2s - loss: 0.5323 - acc: 0.7991 - val_loss: 0.4828 - val_acc: 0.8060
Epoch 72/120
10000/10000 [==============================] - 2s - loss: 0.5182 - acc: 0.8043 - val_loss: 0.4611 - val_acc: 0.8170
Epoch 73/120
10000/10000 [==============================] - 2s - loss: 0.5097 - acc: 0.8105 - val_loss: 0.4601 - val_acc: 0.8240
Epoch 74/120
10000/10000 [==============================] - 2s - loss: 0.5000 - acc: 0.8131 - val_loss: 0.4462 - val_acc: 0.8370
Epoch 75/120
10000/10000 [==============================] - 2s - loss: 0.4916 - acc: 0.8149 - val_loss: 0.4338 - val_acc: 0.8360
Epoch 76/120
10000/10000 [==============================] - 2s - loss: 0.4878 - acc: 0.8186 - val_loss: 0.4327 - val_acc: 0.8470
Epoch 77/120
10000/10000 [==============================] - 2s - loss: 0.4680 - acc: 0.8262 - val_loss: 0.4181 - val_acc: 0.8530
Epoch 78/120
10000/10000 [==============================] - 2s - loss: 0.4563 - acc: 0.8259 - val_loss: 0.4050 - val_acc: 0.8660
Epoch 79/120
10000/10000 [==============================] - 2s - loss: 0.4545 - acc: 0.8347 - val_loss: 0.4088 - val_acc: 0.8550
Epoch 80/120
10000/10000 [==============================] - 2s - loss: 0.4546 - acc: 0.8311 - val_loss: 0.4006 - val_acc: 0.8580
Epoch 81/120
10000/10000 [==============================] - 2s - loss: 0.4563 - acc: 0.8314 - val_loss: 0.3986 - val_acc: 0.8640
Epoch 82/120
10000/10000 [==============================] - 2s - loss: 0.4382 - acc: 0.8380 - val_loss: 0.3796 - val_acc: 0.8730
Epoch 83/120
10000/10000 [==============================] - 2s - loss: 0.4473 - acc: 0.8359 - val_loss: 0.3782 - val_acc: 0.8700
Epoch 84/120
10000/10000 [==============================] - 2s - loss: 0.4322 - acc: 0.8430 - val_loss: 0.3769 - val_acc: 0.8720
Epoch 85/120
10000/10000 [==============================] - 2s - loss: 0.4345 - acc: 0.8373 - val_loss: 0.3690 - val_acc: 0.8710
Epoch 86/120
10000/10000 [==============================] - 2s - loss: 0.4175 - acc: 0.8431 - val_loss: 0.3708 - val_acc: 0.8690
Epoch 87/120
10000/10000 [==============================] - 2s - loss: 0.4241 - acc: 0.8450 - val_loss: 0.3625 - val_acc: 0.8770
Epoch 88/120
10000/10000 [==============================] - 2s - loss: 0.4169 - acc: 0.8484 - val_loss: 0.3711 - val_acc: 0.8640
Epoch 89/120
10000/10000 [==============================] - 2s - loss: 0.4106 - acc: 0.8453 - val_loss: 0.3666 - val_acc: 0.8700
Epoch 90/120
10000/10000 [==============================] - 2s - loss: 0.4051 - acc: 0.8528 - val_loss: 0.3593 - val_acc: 0.8680
Epoch 91/120
10000/10000 [==============================] - 2s - loss: 0.4064 - acc: 0.8512 - val_loss: 0.3532 - val_acc: 0.8760
Epoch 92/120
10000/10000 [==============================] - 2s - loss: 0.4062 - acc: 0.8484 - val_loss: 0.3555 - val_acc: 0.8740
Epoch 93/120
10000/10000 [==============================] - 2s - loss: 0.4096 - acc: 0.8480 - val_loss: 0.3467 - val_acc: 0.8770
Epoch 94/120
10000/10000 [==============================] - 2s - loss: 0.4018 - acc: 0.8529 - val_loss: 0.3471 - val_acc: 0.8740
Epoch 95/120
10000/10000 [==============================] - 2s - loss: 0.3854 - acc: 0.8581 - val_loss: 0.3443 - val_acc: 0.8710
Epoch 96/120
10000/10000 [==============================] - 2s - loss: 0.3947 - acc: 0.8558 - val_loss: 0.3462 - val_acc: 0.8820
Epoch 97/120
10000/10000 [==============================] - 2s - loss: 0.3934 - acc: 0.8585 - val_loss: 0.3384 - val_acc: 0.8730
Epoch 98/120
10000/10000 [==============================] - 2s - loss: 0.3914 - acc: 0.8554 - val_loss: 0.3524 - val_acc: 0.8720
Epoch 99/120
10000/10000 [==============================] - 2s - loss: 0.3820 - acc: 0.8577 - val_loss: 0.3432 - val_acc: 0.8760
Epoch 100/120
10000/10000 [==============================] - 2s - loss: 0.3816 - acc: 0.8603 - val_loss: 0.3439 - val_acc: 0.8760
Epoch 101/120
10000/10000 [==============================] - 2s - loss: 0.3921 - acc: 0.8552 - val_loss: 0.3405 - val_acc: 0.8820
Epoch 102/120
10000/10000 [==============================] - 2s - loss: 0.3810 - acc: 0.8591 - val_loss: 0.3298 - val_acc: 0.8800
Epoch 103/120
10000/10000 [==============================] - 2s - loss: 0.3803 - acc: 0.8627 - val_loss: 0.3271 - val_acc: 0.8790
Epoch 104/120
10000/10000 [==============================] - 2s - loss: 0.3797 - acc: 0.8618 - val_loss: 0.3356 - val_acc: 0.8780
Epoch 105/120
10000/10000 [==============================] - 2s - loss: 0.3793 - acc: 0.8601 - val_loss: 0.3326 - val_acc: 0.8770
Epoch 106/120
10000/10000 [==============================] - 2s - loss: 0.3749 - acc: 0.8629 - val_loss: 0.3242 - val_acc: 0.8800
Epoch 107/120
10000/10000 [==============================] - 2s - loss: 0.3840 - acc: 0.8613 - val_loss: 0.3255 - val_acc: 0.8810
Epoch 108/120
10000/10000 [==============================] - 2s - loss: 0.3641 - acc: 0.8634 - val_loss: 0.3209 - val_acc: 0.8790
Epoch 109/120
10000/10000 [==============================] - 2s - loss: 0.3695 - acc: 0.8661 - val_loss: 0.3226 - val_acc: 0.8820
Epoch 110/120
10000/10000 [==============================] - 2s - loss: 0.3648 - acc: 0.8659 - val_loss: 0.3318 - val_acc: 0.8820
Epoch 111/120
10000/10000 [==============================] - 2s - loss: 0.3642 - acc: 0.8695 - val_loss: 0.3146 - val_acc: 0.8850
Epoch 112/120
10000/10000 [==============================] - 2s - loss: 0.3690 - acc: 0.8639 - val_loss: 0.3130 - val_acc: 0.8840
Epoch 113/120
10000/10000 [==============================] - 2s - loss: 0.3627 - acc: 0.8669 - val_loss: 0.3098 - val_acc: 0.8880
Epoch 114/120
10000/10000 [==============================] - 2s - loss: 0.3561 - acc: 0.8702 - val_loss: 0.3033 - val_acc: 0.8850
Epoch 115/120
10000/10000 [==============================] - 2s - loss: 0.3552 - acc: 0.8675 - val_loss: 0.3057 - val_acc: 0.8880
Epoch 116/120
10000/10000 [==============================] - 2s - loss: 0.3456 - acc: 0.8700 - val_loss: 0.2989 - val_acc: 0.8850
Epoch 117/120
10000/10000 [==============================] - 2s - loss: 0.3456 - acc: 0.8743 - val_loss: 0.2920 - val_acc: 0.8890
Epoch 118/120
10000/10000 [==============================] - 2s - loss: 0.3528 - acc: 0.8716 - val_loss: 0.2909 - val_acc: 0.8860
Epoch 119/120
10000/10000 [==============================] - 2s - loss: 0.3388 - acc: 0.8775 - val_loss: 0.2842 - val_acc: 0.8920
Epoch 120/120
10000/10000 [==============================] - 2s - loss: 0.3504 - acc: 0.8742 - val_loss: 0.2837 - val_acc: 0.8900


python addition_rnn.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Generating data...
Total addition questions: 50000
Vectorization...
(45000, 7, 12)
(45000, 4, 12)
Build model...
/usr/local/lib/python2.7/dist-packages/keras/layers/core.py:992: UserWarning: TimeDistributedDense is deprecated, please use TimeDistributed(Dense(...)) instead.
  warnings.warn('TimeDistributedDense is deprecated, '

--------------------------------------------------
Iteration 1
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.8490 - acc: 0.3331 - val_loss: 1.7107 - val_acc: 0.3696
Q 367+14 
T 381 
 774 
---
Q 19+102 
T 121 
 211 
---
Q 550+528
T 1078
 105 
---
Q 308+83 
T 391 
 304 
---
Q 63+353 
T 416 
 433 
---
Q 726+716
T 1442
 1114
---
Q 427+4  
T 431 
 21  
---
Q 16+16  
T 32  
 11  
---
Q 644+65 
T 709 
 555 
---
Q 556+56 
T 612 
 605 
---

--------------------------------------------------
Iteration 2
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.6152 - acc: 0.3998 - val_loss: 1.5130 - val_acc: 0.4370
Q 41+13  
T 54  
 11  
---
Q 54+110 
T 164 
 251 
---
Q 96+535 
T 631 
 604 
---
Q 935+442
T 1377
 1482
---
Q 67+104 
T 171 
 110 
---
Q 894+78 
T 972 
 904 
---
Q 492+548
T 1040
 104 
---
Q 899+82 
T 981 
 904 
---
Q 26+548 
T 574 
 514 
---
Q 853+535
T 1388
 1382
---

--------------------------------------------------
Iteration 3
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.4064 - acc: 0.4757 - val_loss: 1.3121 - val_acc: 0.5162
Q 85+76  
T 161 
 152 
---
Q 423+10 
T 433 
 444 
---
Q 639+593
T 1232
 1202
---
Q 1+520  
T 521 
 555 
---
Q 646+54 
T 700 
 680 
---
Q 88+437 
T 525 
 422 
---
Q 67+669 
T 736 
 724 
---
Q 822+206
T 1028
 103 
---
Q 70+643 
T 713 
 700 
---
Q 460+50 
T 510 
 500 
---

--------------------------------------------------
Iteration 4
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.2329 - acc: 0.5437 - val_loss: 1.1789 - val_acc: 0.5581
Q 11+177 
T 188 
 188 
---
Q 53+49  
T 102 
 11  
---
Q 63+239 
T 302 
 301 
---
Q 284+79 
T 363 
 346 
---
Q 308+83 
T 391 
 301 
---
Q 25+250 
T 275 
 279 
---
Q 65+319 
T 384 
 391 
---
Q 844+55 
T 899 
 890 
---
Q 89+201 
T 290 
 201 
---
Q 5+913  
T 918 
 910 
---

--------------------------------------------------
Iteration 5
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.0805 - acc: 0.6029 - val_loss: 0.9956 - val_acc: 0.6377
Q 5+17   
T 22  
 18  
---
Q 761+98 
T 859 
 858 
---
Q 835+19 
T 854 
 851 
---
Q 310+807
T 1117
 1147
---
Q 24+429 
T 453 
 452 
---
Q 996+16 
T 1012
 1011
---
Q 419+92 
T 511 
 511 
---
Q 2+280  
T 282 
 282 
---
Q 672+549
T 1221
 1222
---
Q 246+904
T 1150
 1145
---

--------------------------------------------------
Iteration 6
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.8528 - acc: 0.6902 - val_loss: 0.7184 - val_acc: 0.7436
Q 83+885 
T 968 
 958 
---
Q 24+615 
T 639 
 669 
---
Q 547+69 
T 616 
 614 
---
Q 323+39 
T 362 
 371 
---
Q 676+7  
T 683 
 683 
---
Q 601+959
T 1560
 1579
---
Q 715+180
T 895 
 896 
---
Q 637+30 
T 667 
 667 
---
Q 585+62 
T 647 
 647 
---
Q 470+435
T 905 
 906 
---

--------------------------------------------------
Iteration 7
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.5872 - acc: 0.8077 - val_loss: 0.4997 - val_acc: 0.8504
Q 2+360  
T 362 
 361 
---
Q 995+586
T 1581
 1571
---
Q 19+843 
T 862 
 862 
---
Q 20+160 
T 180 
 282 
---
Q 557+22 
T 579 
 579 
---
Q 522+16 
T 538 
 538 
---
Q 896+86 
T 982 
 973 
---
Q 543+590
T 1133
 1143
---
Q 227+170
T 397 
 398 
---
Q 294+470
T 764 
 765 
---

--------------------------------------------------
Iteration 8
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.4228 - acc: 0.8828 - val_loss: 0.3830 - val_acc: 0.8923
Q 492+994
T 1486
 1577
---
Q 4+525  
T 529 
 529 
---
Q 50+725 
T 775 
 765 
---
Q 260+32 
T 292 
 292 
---
Q 117+639
T 756 
 766 
---
Q 492+548
T 1040
 1040
---
Q 206+94 
T 300 
 290 
---
Q 36+121 
T 157 
 157 
---
Q 623+6  
T 629 
 629 
---
Q 681+267
T 948 
 948 
---

--------------------------------------------------
Iteration 9
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.3194 - acc: 0.9226 - val_loss: 0.3082 - val_acc: 0.9113
Q 94+447 
T 541 
 541 
---
Q 898+908
T 1806
 1706
---
Q 226+53 
T 279 
 279 
---
Q 240+99 
T 339 
 339 
---
Q 38+17  
T 55  
 55  
---
Q 53+195 
T 248 
 248 
---
Q 651+27 
T 678 
 678 
---
Q 16+273 
T 289 
 289 
---
Q 2+945  
T 947 
 947 
---
Q 174+508
T 682 
 692 
---

--------------------------------------------------
Iteration 10
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.2489 - acc: 0.9444 - val_loss: 0.2326 - val_acc: 0.9430
Q 95+828 
T 923 
 923 
---
Q 155+320
T 475 
 475 
---
Q 450+50 
T 500 
 400 
---
Q 238+28 
T 266 
 266 
---
Q 691+733
T 1424
 1424
---
Q 27+358 
T 385 
 385 
---
Q 3+799  
T 802 
 702 
---
Q 54+976 
T 1030
 1030
---
Q 602+30 
T 632 
 632 
---
Q 161+91 
T 252 
 252 
---

--------------------------------------------------
Iteration 11
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.1948 - acc: 0.9603 - val_loss: 0.1732 - val_acc: 0.9670
Q 21+633 
T 654 
 654 
---
Q 281+87 
T 368 
 368 
---
Q 916+613
T 1529
 1529
---
Q 716+7  
T 723 
 723 
---
Q 2+870  
T 872 
 872 
---
Q 464+4  
T 468 
 468 
---
Q 20+590 
T 610 
 611 
---
Q 47+602 
T 649 
 649 
---
Q 75+7   
T 82  
 82  
---
Q 316+807
T 1123
 1123
---

--------------------------------------------------
Iteration 12
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.1534 - acc: 0.9709 - val_loss: 0.1737 - val_acc: 0.9516
Q 497+65 
T 562 
 562 
---
Q 71+729 
T 800 
 700 
---
Q 103+782
T 885 
 885 
---
Q 775+12 
T 787 
 787 
---
Q 16+974 
T 990 
 990 
---
Q 543+590
T 1133
 1133
---
Q 504+534
T 1038
 1048
---
Q 953+119
T 1072
 1072
---
Q 693+72 
T 765 
 765 
---
Q 751+849
T 1600
 1500
---

--------------------------------------------------
Iteration 13
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.1245 - acc: 0.9779 - val_loss: 0.1246 - val_acc: 0.9734
Q 65+139 
T 204 
 204 
---
Q 64+76  
T 140 
 140 
---
Q 976+225
T 1201
 1201
---
Q 328+2  
T 330 
 330 
---
Q 622+99 
T 721 
 721 
---
Q 81+481 
T 562 
 562 
---
Q 953+119
T 1072
 1072
---
Q 740+48 
T 788 
 788 
---
Q 945+162
T 1107
 1107
---
Q 539+411
T 950 
 950 
---

--------------------------------------------------
Iteration 14
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.1273 - acc: 0.9710 - val_loss: 0.1146 - val_acc: 0.9737
Q 879+387
T 1266
 1266
---
Q 680+36 
T 716 
 716 
---
Q 77+32  
T 109 
 109 
---
Q 452+3  
T 455 
 455 
---
Q 360+78 
T 438 
 438 
---
Q 91+784 
T 875 
 875 
---
Q 87+322 
T 409 
 409 
---
Q 27+916 
T 943 
 943 
---
Q 661+23 
T 684 
 684 
---
Q 395+60 
T 455 
 455 
---

--------------------------------------------------
Iteration 15
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0835 - acc: 0.9874 - val_loss: 0.0864 - val_acc: 0.9826
Q 217+658
T 875 
 875 
---
Q 28+321 
T 349 
 349 
---
Q 683+365
T 1048
 1048
---
Q 98+440 
T 538 
 538 
---
Q 105+4  
T 109 
 109 
---
Q 24+76  
T 100 
 100 
---
Q 515+310
T 825 
 825 
---
Q 698+88 
T 786 
 776 
---
Q 243+399
T 642 
 642 
---
Q 567+1  
T 568 
 568 
---

--------------------------------------------------
Iteration 16
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0673 - acc: 0.9908 - val_loss: 0.0756 - val_acc: 0.9842
Q 62+129 
T 191 
 191 
---
Q 17+475 
T 492 
 492 
---
Q 38+538 
T 576 
 576 
---
Q 57+376 
T 433 
 433 
---
Q 3+573  
T 576 
 576 
---
Q 214+69 
T 283 
 283 
---
Q 6+673  
T 679 
 679 
---
Q 1+461  
T 462 
 462 
---
Q 368+343
T 711 
 711 
---
Q 51+350 
T 401 
 401 
---

--------------------------------------------------
Iteration 17
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0888 - acc: 0.9786 - val_loss: 0.0905 - val_acc: 0.9751
Q 818+9  
T 827 
 827 
---
Q 464+30 
T 494 
 494 
---
Q 4+885  
T 889 
 889 
---
Q 953+119
T 1072
 1062
---
Q 23+60  
T 83  
 73  
---
Q 457+50 
T 507 
 507 
---
Q 67+73  
T 140 
 130 
---
Q 607+540
T 1147
 1147
---
Q 230+322
T 552 
 552 
---
Q 19+640 
T 659 
 659 
---

--------------------------------------------------
Iteration 18
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0495 - acc: 0.9937 - val_loss: 0.0514 - val_acc: 0.9907
Q 72+82  
T 154 
 154 
---
Q 32+86  
T 118 
 118 
---
Q 3+558  
T 561 
 561 
---
Q 955+1  
T 956 
 956 
---
Q 33+385 
T 418 
 418 
---
Q 38+607 
T 645 
 645 
---
Q 808+13 
T 821 
 821 
---
Q 45+64  
T 109 
 109 
---
Q 689+4  
T 693 
 693 
---
Q 43+385 
T 428 
 428 
---

--------------------------------------------------
Iteration 19
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0421 - acc: 0.9947 - val_loss: 0.0488 - val_acc: 0.9902
Q 989+131
T 1120
 1120
---
Q 69+429 
T 498 
 498 
---
Q 10+651 
T 661 
 661 
---
Q 18+26  
T 44  
 44  
---
Q 76+736 
T 812 
 812 
---
Q 771+13 
T 784 
 784 
---
Q 3+846  
T 849 
 849 
---
Q 578+666
T 1244
 1244
---
Q 825+324
T 1149
 1149
---
Q 375+4  
T 379 
 379 
---

--------------------------------------------------
Iteration 20
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0534 - acc: 0.9890 - val_loss: 0.7863 - val_acc: 0.8174
Q 293+640
T 933 
 843 
---
Q 19+752 
T 771 
 770 
---
Q 932+76 
T 1008
 1008
---
Q 254+41 
T 295 
 294 
---
Q 758+64 
T 822 
 822 
---
Q 42+848 
T 890 
 890 
---
Q 31+547 
T 578 
 577 
---
Q 869+6  
T 875 
 874 
---
Q 97+89  
T 186 
 186 
---
Q 99+264 
T 363 
 363 
---

--------------------------------------------------
Iteration 21
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0625 - acc: 0.9870 - val_loss: 0.0463 - val_acc: 0.9893
Q 116+732
T 848 
 848 
---
Q 320+878
T 1198
 1198
---
Q 728+99 
T 827 
 827 
---
Q 198+5  
T 203 
 203 
---
Q 172+10 
T 182 
 182 
---
Q 47+707 
T 754 
 754 
---
Q 45+4   
T 49  
 49  
---
Q 4+752  
T 756 
 756 
---
Q 916+89 
T 1005
 1005
---
Q 786+534
T 1320
 1320
---

--------------------------------------------------
Iteration 22
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0270 - acc: 0.9972 - val_loss: 0.0297 - val_acc: 0.9950
Q 862+9  
T 871 
 871 
---
Q 978+375
T 1353
 1353
---
Q 830+41 
T 871 
 871 
---
Q 759+97 
T 856 
 856 
---
Q 643+284
T 927 
 927 
---
Q 822+6  
T 828 
 828 
---
Q 693+72 
T 765 
 765 
---
Q 49+72  
T 121 
 121 
---
Q 81+96  
T 177 
 177 
---
Q 308+915
T 1223
 1223
---

--------------------------------------------------
Iteration 23
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0236 - acc: 0.9977 - val_loss: 0.0298 - val_acc: 0.9938
Q 293+84 
T 377 
 377 
---
Q 79+998 
T 1077
 1077
---
Q 610+902
T 1512
 1512
---
Q 92+469 
T 561 
 561 
---
Q 698+88 
T 786 
 786 
---
Q 212+14 
T 226 
 226 
---
Q 72+878 
T 950 
 950 
---
Q 4+820  
T 824 
 824 
---
Q 599+3  
T 602 
 602 
---
Q 7+554  
T 561 
 561 
---

--------------------------------------------------
Iteration 24
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0490 - acc: 0.9874 - val_loss: 0.0464 - val_acc: 0.9876
Q 38+345 
T 383 
 383 
---
Q 421+477
T 898 
 898 
---
Q 703+8  
T 711 
 711 
---
Q 754+97 
T 851 
 851 
---
Q 20+101 
T 121 
 111 
---
Q 55+350 
T 405 
 405 
---
Q 0+971  
T 971 
 971 
---
Q 92+3   
T 95  
 95  
---
Q 51+839 
T 890 
 890 
---
Q 442+763
T 1205
 1205
---

--------------------------------------------------
Iteration 25
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0206 - acc: 0.9977 - val_loss: 0.0236 - val_acc: 0.9957
Q 517+3  
T 520 
 520 
---
Q 139+33 
T 172 
 172 
---
Q 6+6    
T 12  
 12  
---
Q 708+5  
T 713 
 713 
---
Q 9+426  
T 435 
 435 
---
Q 80+643 
T 723 
 723 
---
Q 163+73 
T 236 
 236 
---
Q 21+35  
T 56  
 56  
---
Q 696+652
T 1348
 1348
---
Q 58+17  
T 75  
 75  
---

--------------------------------------------------
Iteration 26
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0170 - acc: 0.9984 - val_loss: 0.0241 - val_acc: 0.9950
Q 37+588 
T 625 
 625 
---
Q 668+534
T 1202
 1202
---
Q 448+7  
T 455 
 455 
---
Q 3+149  
T 152 
 152 
---
Q 2+164  
T 166 
 166 
---
Q 364+589
T 953 
 953 
---
Q 525+40 
T 565 
 565 
---
Q 230+0  
T 230 
 230 
---
Q 428+6  
T 434 
 434 
---
Q 5+17   
T 22  
 22  
---

--------------------------------------------------
Iteration 27
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0341 - acc: 0.9916 - val_loss: 0.0279 - val_acc: 0.9937
Q 51+332 
T 383 
 383 
---
Q 279+10 
T 289 
 289 
---
Q 41+546 
T 587 
 587 
---
Q 38+454 
T 492 
 592 
---
Q 585+6  
T 591 
 591 
---
Q 827+79 
T 906 
 906 
---
Q 754+730
T 1484
 1484
---
Q 14+3   
T 17  
 17  
---
Q 19+677 
T 696 
 696 
---
Q 889+2  
T 891 
 891 
---

--------------------------------------------------
Iteration 28
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0372 - acc: 0.9912 - val_loss: 0.1458 - val_acc: 0.9434
Q 615+788
T 1403
 1303
---
Q 162+911
T 1073
 1073
---
Q 226+274
T 500 
 500 
---
Q 5+17   
T 22  
 22  
---
Q 78+558 
T 636 
 636 
---
Q 590+971
T 1561
 1562
---
Q 26+915 
T 941 
 941 
---
Q 656+71 
T 727 
 727 
---
Q 717+494
T 1211
 1212
---
Q 907+990
T 1897
 1897
---

--------------------------------------------------
Iteration 29
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0348 - acc: 0.9912 - val_loss: 0.0168 - val_acc: 0.9970
Q 83+416 
T 499 
 499 
---
Q 546+3  
T 549 
 549 
---
Q 15+665 
T 680 
 680 
---
Q 384+7  
T 391 
 391 
---
Q 4+984  
T 988 
 988 
---
Q 843+43 
T 886 
 886 
---
Q 534+96 
T 630 
 630 
---
Q 692+599
T 1291
 1291
---
Q 59+560 
T 619 
 619 
---
Q 308+132
T 440 
 440 
---

--------------------------------------------------
Iteration 30
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0103 - acc: 0.9994 - val_loss: 0.0151 - val_acc: 0.9974
Q 642+72 
T 714 
 714 
---
Q 253+797
T 1050
 1050
---
Q 75+442 
T 517 
 517 
---
Q 4+968  
T 972 
 972 
---
Q 49+72  
T 121 
 121 
---
Q 26+754 
T 780 
 780 
---
Q 643+284
T 927 
 927 
---
Q 64+685 
T 749 
 749 
---
Q 245+2  
T 247 
 247 
---
Q 684+1  
T 685 
 685 
---

--------------------------------------------------
Iteration 31
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0091 - acc: 0.9995 - val_loss: 0.0141 - val_acc: 0.9978
Q 931+14 
T 945 
 945 
---
Q 849+159
T 1008
 1008
---
Q 341+98 
T 439 
 439 
---
Q 81+96  
T 177 
 177 
---
Q 27+370 
T 397 
 397 
---
Q 61+219 
T 280 
 280 
---
Q 53+81  
T 134 
 134 
---
Q 15+98  
T 113 
 113 
---
Q 378+892
T 1270
 1270
---
Q 624+22 
T 646 
 646 
---

--------------------------------------------------
Iteration 32
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0090 - acc: 0.9992 - val_loss: 0.0185 - val_acc: 0.9957
Q 223+542
T 765 
 765 
---
Q 900+267
T 1167
 1167
---
Q 3+248  
T 251 
 251 
---
Q 518+772
T 1290
 1290
---
Q 995+21 
T 1016
 1016
---
Q 1+473  
T 474 
 474 
---
Q 408+14 
T 422 
 422 
---
Q 390+66 
T 456 
 456 
---
Q 76+725 
T 801 
 801 
---
Q 43+90  
T 133 
 133 
---

--------------------------------------------------
Iteration 33
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0551 - acc: 0.9832 - val_loss: 0.0260 - val_acc: 0.9929
Q 56+95  
T 151 
 151 
---
Q 976+225
T 1201
 1201
---
Q 368+59 
T 427 
 427 
---
Q 526+1  
T 527 
 527 
---
Q 403+804
T 1207
 1107
---
Q 373+3  
T 376 
 376 
---
Q 970+645
T 1615
 1615
---
Q 43+385 
T 428 
 428 
---
Q 240+99 
T 339 
 339 
---
Q 27+716 
T 743 
 743 
---

--------------------------------------------------
Iteration 34
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0109 - acc: 0.9986 - val_loss: 0.0126 - val_acc: 0.9979
Q 771+0  
T 771 
 771 
---
Q 450+54 
T 504 
 504 
---
Q 98+189 
T 287 
 286 
---
Q 513+250
T 763 
 763 
---
Q 461+4  
T 465 
 465 
---
Q 898+9  
T 907 
 907 
---
Q 3+99   
T 102 
 102 
---
Q 382+98 
T 480 
 480 
---
Q 69+598 
T 667 
 667 
---
Q 56+810 
T 866 
 866 
---

--------------------------------------------------
Iteration 35
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0069 - acc: 0.9996 - val_loss: 0.0106 - val_acc: 0.9980
Q 39+473 
T 512 
 512 
---
Q 293+4  
T 297 
 297 
---
Q 21+71  
T 92  
 92  
---
Q 62+516 
T 578 
 578 
---
Q 10+543 
T 553 
 553 
---
Q 257+45 
T 302 
 302 
---
Q 57+968 
T 1025
 1025
---
Q 1+718  
T 719 
 719 
---
Q 5+795  
T 800 
 800 
---
Q 614+80 
T 694 
 694 
---

--------------------------------------------------
Iteration 36
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0077 - acc: 0.9991 - val_loss: 0.0227 - val_acc: 0.9937
Q 915+46 
T 961 
 961 
---
Q 826+60 
T 886 
 886 
---
Q 80+17  
T 97  
 97  
---
Q 291+17 
T 308 
 308 
---
Q 19+5   
T 24  
 24  
---
Q 41+421 
T 462 
 462 
---
Q 391+134
T 525 
 525 
---
Q 61+663 
T 724 
 724 
---
Q 365+325
T 690 
 690 
---
Q 151+180
T 331 
 331 
---

--------------------------------------------------
Iteration 37
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0395 - acc: 0.9888 - val_loss: 0.0115 - val_acc: 0.9978
Q 42+848 
T 890 
 890 
---
Q 27+517 
T 544 
 544 
---
Q 41+883 
T 924 
 924 
---
Q 235+236
T 471 
 471 
---
Q 680+907
T 1587
 1587
---
Q 12+37  
T 49  
 49  
---
Q 140+91 
T 231 
 231 
---
Q 539+44 
T 583 
 583 
---
Q 28+22  
T 50  
 40  
---
Q 615+972
T 1587
 1587
---

--------------------------------------------------
Iteration 38
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0057 - acc: 0.9998 - val_loss: 0.0102 - val_acc: 0.9982
Q 452+3  
T 455 
 455 
---
Q 64+536 
T 600 
 600 
---
Q 98+184 
T 282 
 282 
---
Q 510+838
T 1348
 1348
---
Q 62+449 
T 511 
 511 
---
Q 14+603 
T 617 
 617 
---
Q 71+28  
T 99  
 99  
---
Q 66+564 
T 630 
 630 
---
Q 10+493 
T 503 
 503 
---
Q 37+544 
T 581 
 581 
---

--------------------------------------------------
Iteration 39
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0053 - acc: 0.9996 - val_loss: 0.0103 - val_acc: 0.9979
Q 592+59 
T 651 
 651 
---
Q 995+856
T 1851
 1851
---
Q 3+404  
T 407 
 407 
---
Q 41+13  
T 54  
 54  
---
Q 987+563
T 1550
 1550
---
Q 41+243 
T 284 
 284 
---
Q 60+320 
T 380 
 380 
---
Q 3+42   
T 45  
 45  
---
Q 607+8  
T 615 
 615 
---
Q 345+548
T 893 
 893 
---

--------------------------------------------------
Iteration 40
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0458 - acc: 0.9859 - val_loss: 0.0174 - val_acc: 0.9960
Q 61+325 
T 386 
 386 
---
Q 758+64 
T 822 
 822 
---
Q 543+603
T 1146
 1146
---
Q 740+368
T 1108
 1108
---
Q 57+58  
T 115 
 115 
---
Q 573+0  
T 573 
 573 
---
Q 882+256
T 1138
 1138
---
Q 836+525
T 1361
 1361
---
Q 535+716
T 1251
 1251
---
Q 707+39 
T 746 
 746 
---

--------------------------------------------------
Iteration 41
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0138 - acc: 0.9972 - val_loss: 0.0144 - val_acc: 0.9964
Q 61+80  
T 141 
 141 
---
Q 749+720
T 1469
 1469
---
Q 3+705  
T 708 
 708 
---
Q 540+489
T 1029
 1029
---
Q 498+797
T 1295
 1295
---
Q 549+89 
T 638 
 638 
---
Q 961+27 
T 988 
 988 
---
Q 75+939 
T 1014
 1014
---
Q 34+541 
T 575 
 575 
---
Q 37+391 
T 428 
 428 
---

--------------------------------------------------
Iteration 42
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0054 - acc: 0.9996 - val_loss: 0.0081 - val_acc: 0.9987
Q 7+554  
T 561 
 561 
---
Q 924+492
T 1416
 1416
---
Q 0+615  
T 615 
 615 
---
Q 59+661 
T 720 
 720 
---
Q 6+8    
T 14  
 14  
---
Q 95+533 
T 628 
 628 
---
Q 726+249
T 975 
 975 
---
Q 87+621 
T 708 
 708 
---
Q 8+526  
T 534 
 534 
---
Q 990+322
T 1312
 1312
---

--------------------------------------------------
Iteration 43
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0041 - acc: 0.9998 - val_loss: 0.0071 - val_acc: 0.9989
Q 651+27 
T 678 
 678 
---
Q 67+104 
T 171 
 171 
---
Q 421+49 
T 470 
 470 
---
Q 0+780  
T 780 
 780 
---
Q 83+235 
T 318 
 318 
---
Q 187+2  
T 189 
 189 
---
Q 750+6  
T 756 
 756 
---
Q 208+511
T 719 
 719 
---
Q 773+71 
T 844 
 844 
---
Q 1+235  
T 236 
 236 
---

--------------------------------------------------
Iteration 44
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0088 - val_acc: 0.9979
Q 374+0  
T 374 
 374 
---
Q 470+38 
T 508 
 508 
---
Q 16+898 
T 914 
 914 
---
Q 247+39 
T 286 
 286 
---
Q 10+493 
T 503 
 503 
---
Q 252+46 
T 298 
 298 
---
Q 238+813
T 1051
 1051
---
Q 808+13 
T 821 
 821 
---
Q 864+17 
T 881 
 881 
---
Q 8+617  
T 625 
 625 
---

--------------------------------------------------
Iteration 45
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0470 - acc: 0.9863 - val_loss: 0.0105 - val_acc: 0.9979
Q 366+580
T 946 
 946 
---
Q 37+544 
T 581 
 581 
---
Q 911+501
T 1412
 1412
---
Q 6+291  
T 297 
 297 
---
Q 660+50 
T 710 
 710 
---
Q 50+679 
T 729 
 729 
---
Q 7+663  
T 670 
 670 
---
Q 139+29 
T 168 
 168 
---
Q 27+517 
T 544 
 544 
---
Q 18+258 
T 276 
 276 
---

--------------------------------------------------
Iteration 46
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0044 - acc: 0.9998 - val_loss: 0.0072 - val_acc: 0.9986
Q 3+117  
T 120 
 120 
---
Q 93+681 
T 774 
 774 
---
Q 277+497
T 774 
 774 
---
Q 334+0  
T 334 
 334 
---
Q 19+292 
T 311 
 311 
---
Q 24+327 
T 351 
 351 
---
Q 373+176
T 549 
 549 
---
Q 933+9  
T 942 
 942 
---
Q 3+365  
T 368 
 368 
---
Q 5+870  
T 875 
 875 
---

--------------------------------------------------
Iteration 47
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0036 - acc: 0.9999 - val_loss: 0.0074 - val_acc: 0.9984
Q 4+184  
T 188 
 188 
---
Q 7+782  
T 789 
 789 
---
Q 41+67  
T 108 
 108 
---
Q 507+4  
T 511 
 511 
---
Q 879+46 
T 925 
 925 
---
Q 252+46 
T 298 
 298 
---
Q 358+573
T 931 
 931 
---
Q 50+941 
T 991 
 991 
---
Q 788+88 
T 876 
 876 
---
Q 233+84 
T 317 
 317 
---

--------------------------------------------------
Iteration 48
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0035 - acc: 0.9998 - val_loss: 0.0065 - val_acc: 0.9987
Q 710+8  
T 718 
 718 
---
Q 65+69  
T 134 
 134 
---
Q 52+363 
T 415 
 415 
---
Q 698+93 
T 791 
 791 
---
Q 11+65  
T 76  
 76  
---
Q 545+74 
T 619 
 619 
---
Q 567+2  
T 569 
 569 
---
Q 421+452
T 873 
 873 
---
Q 647+834
T 1481
 1481
---
Q 55+920 
T 975 
 975 
---

--------------------------------------------------
Iteration 49
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0034 - acc: 0.9996 - val_loss: 0.0067 - val_acc: 0.9987
Q 757+685
T 1442
 1442
---
Q 32+474 
T 506 
 506 
---
Q 52+94  
T 146 
 146 
---
Q 0+765  
T 765 
 765 
---
Q 689+241
T 930 
 930 
---
Q 305+41 
T 346 
 346 
---
Q 912+596
T 1508
 1508
---
Q 152+16 
T 168 
 168 
---
Q 36+21  
T 57  
 57  
---
Q 0+199  
T 199 
 199 
---

--------------------------------------------------
Iteration 50
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0559 - acc: 0.9837 - val_loss: 0.0524 - val_acc: 0.9822
Q 86+125 
T 211 
 211 
---
Q 124+375
T 499 
 499 
---
Q 72+27  
T 99  
 10  
---
Q 55+947 
T 1002
 1002
---
Q 516+732
T 1248
 1248
---
Q 353+919
T 1272
 1272
---
Q 92+469 
T 561 
 561 
---
Q 132+934
T 1066
 1066
---
Q 339+4  
T 343 
 343 
---
Q 818+51 
T 869 
 869 
---

--------------------------------------------------
Iteration 51
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0110 - acc: 0.9977 - val_loss: 0.0069 - val_acc: 0.9990
Q 823+4  
T 827 
 827 
---
Q 83+416 
T 499 
 499 
---
Q 224+461
T 685 
 685 
---
Q 677+64 
T 741 
 741 
---
Q 990+322
T 1312
 1312
---
Q 394+954
T 1348
 1348
---
Q 351+76 
T 427 
 427 
---
Q 844+55 
T 899 
 899 
---
Q 85+991 
T 1076
 1076
---
Q 767+89 
T 856 
 856 
---

--------------------------------------------------
Iteration 52
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0032 - acc: 0.9999 - val_loss: 0.0059 - val_acc: 0.9990
Q 83+434 
T 517 
 517 
---
Q 953+24 
T 977 
 977 
---
Q 675+296
T 971 
 971 
---
Q 336+10 
T 346 
 346 
---
Q 49+625 
T 674 
 674 
---
Q 373+176
T 549 
 549 
---
Q 8+115  
T 123 
 123 
---
Q 264+18 
T 282 
 282 
---
Q 368+343
T 711 
 711 
---
Q 95+828 
T 923 
 923 
---

--------------------------------------------------
Iteration 53
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0049 - val_acc: 0.9994
Q 362+71 
T 433 
 433 
---
Q 959+75 
T 1034
 1034
---
Q 16+452 
T 468 
 468 
---
Q 817+81 
T 898 
 898 
---
Q 17+909 
T 926 
 926 
---
Q 519+76 
T 595 
 595 
---
Q 69+22  
T 91  
 91  
---
Q 4+930  
T 934 
 934 
---
Q 206+96 
T 302 
 302 
---
Q 3+682  
T 685 
 685 
---

--------------------------------------------------
Iteration 54
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0026 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9985
Q 417+987
T 1404
 1404
---
Q 6+502  
T 508 
 508 
---
Q 392+28 
T 420 
 420 
---
Q 603+88 
T 691 
 691 
---
Q 7+324  
T 331 
 331 
---
Q 604+54 
T 658 
 658 
---
Q 266+77 
T 343 
 343 
---
Q 28+649 
T 677 
 677 
---
Q 89+42  
T 131 
 131 
---
Q 431+69 
T 500 
 500 
---

--------------------------------------------------
Iteration 55
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0352 - acc: 0.9903 - val_loss: 0.0534 - val_acc: 0.9816
Q 669+76 
T 745 
 745 
---
Q 748+32 
T 780 
 780 
---
Q 985+3  
T 988 
 988 
---
Q 642+72 
T 714 
 714 
---
Q 326+784
T 1110
 1110
---
Q 756+20 
T 776 
 776 
---
Q 603+864
T 1467
 1467
---
Q 963+37 
T 1000
 1000
---
Q 284+79 
T 363 
 363 
---
Q 895+746
T 1641
 1641
---

--------------------------------------------------
Iteration 56
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0180 - acc: 0.9952 - val_loss: 0.0069 - val_acc: 0.9987
Q 781+95 
T 876 
 876 
---
Q 7+79   
T 86  
 86  
---
Q 432+8  
T 440 
 440 
---
Q 291+852
T 1143
 1143
---
Q 85+991 
T 1076
 1076
---
Q 5+815  
T 820 
 820 
---
Q 334+4  
T 338 
 338 
---
Q 616+543
T 1159
 1159
---
Q 63+353 
T 416 
 416 
---
Q 123+82 
T 205 
 205 
---

--------------------------------------------------
Iteration 57
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0027 - acc: 0.9999 - val_loss: 0.0052 - val_acc: 0.9992
Q 3+506  
T 509 
 509 
---
Q 439+42 
T 481 
 481 
---
Q 237+903
T 1140
 1140
---
Q 511+75 
T 586 
 586 
---
Q 375+31 
T 406 
 406 
---
Q 86+488 
T 574 
 574 
---
Q 56+23  
T 79  
 79  
---
Q 86+769 
T 855 
 855 
---
Q 745+70 
T 815 
 815 
---
Q 322+83 
T 405 
 405 
---

--------------------------------------------------
Iteration 58
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9994
Q 78+679 
T 757 
 757 
---
Q 748+724
T 1472
 1472
---
Q 29+790 
T 819 
 819 
---
Q 34+162 
T 196 
 196 
---
Q 390+7  
T 397 
 397 
---
Q 8+837  
T 845 
 845 
---
Q 31+367 
T 398 
 398 
---
Q 53+190 
T 243 
 243 
---
Q 30+736 
T 766 
 766 
---
Q 172+45 
T 217 
 217 
---

--------------------------------------------------
Iteration 59
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0020 - acc: 0.9999 - val_loss: 0.0054 - val_acc: 0.9987
Q 680+30 
T 710 
 710 
---
Q 24+839 
T 863 
 863 
---
Q 43+35  
T 78  
 78  
---
Q 462+174
T 636 
 636 
---
Q 20+587 
T 607 
 607 
---
Q 427+480
T 907 
 907 
---
Q 263+378
T 641 
 641 
---
Q 857+82 
T 939 
 939 
---
Q 350+735
T 1085
 1085
---
Q 75+695 
T 770 
 770 
---

--------------------------------------------------
Iteration 60
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0296 - acc: 0.9910 - val_loss: 0.0869 - val_acc: 0.9727
Q 223+542
T 765 
 765 
---
Q 729+60 
T 789 
 789 
---
Q 939+914
T 1853
 1852
---
Q 3+598  
T 601 
 601 
---
Q 7+554  
T 561 
 561 
---
Q 31+939 
T 970 
 970 
---
Q 80+948 
T 1028
 1028
---
Q 646+0  
T 646 
 646 
---
Q 307+407
T 714 
 714 
---
Q 5+577  
T 582 
 582 
---

--------------------------------------------------
Iteration 61
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0206 - acc: 0.9939 - val_loss: 0.0076 - val_acc: 0.9983
Q 828+61 
T 889 
 889 
---
Q 330+92 
T 422 
 422 
---
Q 452+98 
T 550 
 550 
---
Q 359+6  
T 365 
 365 
---
Q 319+38 
T 357 
 357 
---
Q 303+4  
T 307 
 307 
---
Q 779+852
T 1631
 1631
---
Q 62+62  
T 124 
 124 
---
Q 15+404 
T 419 
 419 
---
Q 769+172
T 941 
 941 
---

--------------------------------------------------
Iteration 62
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9993
Q 4+138  
T 142 
 142 
---
Q 60+77  
T 137 
 137 
---
Q 44+910 
T 954 
 954 
---
Q 84+366 
T 450 
 450 
---
Q 588+454
T 1042
 1042
---
Q 59+65  
T 124 
 124 
---
Q 71+659 
T 730 
 730 
---
Q 31+939 
T 970 
 970 
---
Q 82+563 
T 645 
 645 
---
Q 37+537 
T 574 
 574 
---

--------------------------------------------------
Iteration 63
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0021 - acc: 0.9999 - val_loss: 0.0045 - val_acc: 0.9990
Q 450+54 
T 504 
 504 
---
Q 7+171  
T 178 
 178 
---
Q 261+143
T 404 
 404 
---
Q 216+190
T 406 
 406 
---
Q 578+632
T 1210
 1210
---
Q 7+366  
T 373 
 373 
---
Q 19+843 
T 862 
 862 
---
Q 42+59  
T 101 
 101 
---
Q 38+96  
T 134 
 134 
---
Q 484+990
T 1474
 1474
---

--------------------------------------------------
Iteration 64
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9989
Q 42+848 
T 890 
 890 
---
Q 266+77 
T 343 
 343 
---
Q 1+750  
T 751 
 751 
---
Q 795+384
T 1179
 1179
---
Q 268+5  
T 273 
 273 
---
Q 20+587 
T 607 
 607 
---
Q 10+929 
T 939 
 939 
---
Q 17+419 
T 436 
 436 
---
Q 26+267 
T 293 
 293 
---
Q 447+600
T 1047
 1047
---

--------------------------------------------------
Iteration 65
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0327 - acc: 0.9900 - val_loss: 0.0782 - val_acc: 0.9740
Q 197+1  
T 198 
 198 
---
Q 415+274
T 689 
 689 
---
Q 241+774
T 1015
 1015
---
Q 447+523
T 970 
 970 
---
Q 440+3  
T 443 
 443 
---
Q 758+712
T 1470
 1470
---
Q 6+708  
T 714 
 714 
---
Q 586+61 
T 647 
 647 
---
Q 630+170
T 800 
 800 
---
Q 789+17 
T 806 
 806 
---

--------------------------------------------------
Iteration 66
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0097 - acc: 0.9976 - val_loss: 0.0059 - val_acc: 0.9986
Q 889+2  
T 891 
 891 
---
Q 910+244
T 1154
 1154
---
Q 852+332
T 1184
 1184
---
Q 153+67 
T 220 
 220 
---
Q 6+203  
T 209 
 209 
---
Q 88+212 
T 300 
 200 
---
Q 33+621 
T 654 
 654 
---
Q 945+7  
T 952 
 952 
---
Q 34+96  
T 130 
 130 
---
Q 260+430
T 690 
 690 
---

--------------------------------------------------
Iteration 67
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9992
Q 333+28 
T 361 
 361 
---
Q 931+49 
T 980 
 980 
---
Q 34+101 
T 135 
 135 
---
Q 83+1   
T 84  
 84  
---
Q 99+277 
T 376 
 376 
---
Q 9+855  
T 864 
 864 
---
Q 69+423 
T 492 
 492 
---
Q 2+637  
T 639 
 639 
---
Q 5+238  
T 243 
 243 
---
Q 508+492
T 1000
 1000
---

--------------------------------------------------
Iteration 68
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0065 - val_acc: 0.9983
Q 658+5  
T 663 
 663 
---
Q 37+413 
T 450 
 450 
---
Q 19+717 
T 736 
 736 
---
Q 303+15 
T 318 
 318 
---
Q 947+82 
T 1029
 1029
---
Q 392+359
T 751 
 751 
---
Q 718+788
T 1506
 1506
---
Q 417+987
T 1404
 1404
---
Q 920+31 
T 951 
 951 
---
Q 8+709  
T 717 
 717 
---

--------------------------------------------------
Iteration 69
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0045 - val_acc: 0.9986
Q 35+55  
T 90  
 90  
---
Q 605+5  
T 610 
 610 
---
Q 18+258 
T 276 
 276 
---
Q 647+8  
T 655 
 655 
---
Q 862+9  
T 871 
 871 
---
Q 933+9  
T 942 
 942 
---
Q 143+61 
T 204 
 204 
---
Q 5+82   
T 87  
 87  
---
Q 627+14 
T 641 
 641 
---
Q 569+7  
T 576 
 576 
---

--------------------------------------------------
Iteration 70
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9982
Q 19+102 
T 121 
 121 
---
Q 23+824 
T 847 
 847 
---
Q 68+78  
T 146 
 146 
---
Q 3+895  
T 898 
 898 
---
Q 48+369 
T 417 
 417 
---
Q 246+743
T 989 
 989 
---
Q 544+176
T 720 
 720 
---
Q 623+37 
T 660 
 660 
---
Q 0+238  
T 238 
 238 
---
Q 811+79 
T 890 
 890 
---

--------------------------------------------------
Iteration 71
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0547 - acc: 0.9851 - val_loss: 0.0060 - val_acc: 0.9986
Q 87+717 
T 804 
 804 
---
Q 10+493 
T 503 
 503 
---
Q 2+200  
T 202 
 202 
---
Q 508+6  
T 514 
 514 
---
Q 912+782
T 1694
 1694
---
Q 995+21 
T 1016
 1016
---
Q 96+114 
T 210 
 210 
---
Q 669+614
T 1283
 1283
---
Q 1+201  
T 202 
 202 
---
Q 175+215
T 390 
 390 
---

--------------------------------------------------
Iteration 72
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0024 - acc: 0.9999 - val_loss: 0.0048 - val_acc: 0.9991
Q 789+658
T 1447
 1447
---
Q 56+796 
T 852 
 852 
---
Q 281+15 
T 296 
 296 
---
Q 28+163 
T 191 
 191 
---
Q 34+87  
T 121 
 121 
---
Q 8+43   
T 51  
 51  
---
Q 71+853 
T 924 
 924 
---
Q 13+1   
T 14  
 14  
---
Q 66+262 
T 328 
 328 
---
Q 4+325  
T 329 
 329 
---

--------------------------------------------------
Iteration 73
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9993
Q 985+36 
T 1021
 1021
---
Q 786+534
T 1320
 1320
---
Q 62+961 
T 1023
 1023
---
Q 322+0  
T 322 
 322 
---
Q 959+602
T 1561
 1561
---
Q 272+927
T 1199
 1199
---
Q 325+97 
T 422 
 422 
---
Q 68+163 
T 231 
 231 
---
Q 41+883 
T 924 
 924 
---
Q 150+65 
T 215 
 215 
---

--------------------------------------------------
Iteration 74
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 0.9990
Q 4+381  
T 385 
 385 
---
Q 914+99 
T 1013
 1013
---
Q 5+5    
T 10  
 10  
---
Q 70+600 
T 670 
 670 
---
Q 102+80 
T 182 
 182 
---
Q 724+72 
T 796 
 796 
---
Q 329+489
T 818 
 818 
---
Q 658+5  
T 663 
 663 
---
Q 35+83  
T 118 
 118 
---
Q 65+319 
T 384 
 384 
---

--------------------------------------------------
Iteration 75
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0044 - val_acc: 0.9990
Q 103+733
T 836 
 836 
---
Q 16+87  
T 103 
 103 
---
Q 826+436
T 1262
 1262
---
Q 240+99 
T 339 
 339 
---
Q 483+423
T 906 
 906 
---
Q 1+867  
T 868 
 868 
---
Q 1+718  
T 719 
 719 
---
Q 937+926
T 1863
 1863
---
Q 10+439 
T 449 
 449 
---
Q 15+897 
T 912 
 912 
---

--------------------------------------------------
Iteration 76
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0034 - val_acc: 0.9992
Q 27+916 
T 943 
 943 
---
Q 3+449  
T 452 
 452 
---
Q 499+579
T 1078
 1078
---
Q 912+782
T 1694
 1694
---
Q 382+22 
T 404 
 404 
---
Q 121+0  
T 121 
 121 
---
Q 389+1  
T 390 
 390 
---
Q 50+32  
T 82  
 82  
---
Q 6+210  
T 216 
 216 
---
Q 691+5  
T 696 
 696 
---

--------------------------------------------------
Iteration 77
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0374 - acc: 0.9884 - val_loss: 0.0510 - val_acc: 0.9830
Q 50+397 
T 447 
 447 
---
Q 824+939
T 1763
 1763
---
Q 65+104 
T 169 
 169 
---
Q 24+176 
T 200 
 200 
---
Q 136+274
T 410 
 410 
---
Q 3+931  
T 934 
 934 
---
Q 84+213 
T 297 
 297 
---
Q 208+30 
T 238 
 238 
---
Q 105+4  
T 109 
 109 
---
Q 708+753
T 1461
 1461
---

--------------------------------------------------
Iteration 78
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0070 - acc: 0.9983 - val_loss: 0.0046 - val_acc: 0.9992
Q 66+873 
T 939 
 939 
---
Q 6+210  
T 216 
 216 
---
Q 245+2  
T 247 
 247 
---
Q 492+675
T 1167
 1167
---
Q 19+338 
T 357 
 357 
---
Q 53+713 
T 766 
 766 
---
Q 237+903
T 1140
 1140
---
Q 747+463
T 1210
 1210
---
Q 41+941 
T 982 
 982 
---
Q 897+98 
T 995 
 995 
---

--------------------------------------------------
Iteration 79
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9996
Q 79+624 
T 703 
 703 
---
Q 269+42 
T 311 
 311 
---
Q 330+12 
T 342 
 342 
---
Q 880+631
T 1511
 1511
---
Q 132+934
T 1066
 1066
---
Q 532+54 
T 586 
 586 
---
Q 3+931  
T 934 
 934 
---
Q 44+622 
T 666 
 666 
---
Q 43+35  
T 78  
 78  
---
Q 1+595  
T 596 
 596 
---

--------------------------------------------------
Iteration 80
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9996
Q 672+549
T 1221
 1221
---
Q 159+63 
T 222 
 222 
---
Q 808+6  
T 814 
 814 
---
Q 1+673  
T 674 
 674 
---
Q 385+70 
T 455 
 455 
---
Q 43+296 
T 339 
 339 
---
Q 29+808 
T 837 
 837 
---
Q 482+156
T 638 
 638 
---
Q 472+79 
T 551 
 551 
---
Q 143+21 
T 164 
 164 
---

--------------------------------------------------
Iteration 81
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9995
Q 658+38 
T 696 
 696 
---
Q 26+249 
T 275 
 275 
---
Q 785+34 
T 819 
 819 
---
Q 49+396 
T 445 
 445 
---
Q 630+184
T 814 
 814 
---
Q 57+282 
T 339 
 339 
---
Q 0+146  
T 146 
 146 
---
Q 715+180
T 895 
 895 
---
Q 63+47  
T 110 
 110 
---
Q 447+35 
T 482 
 482 
---

--------------------------------------------------
Iteration 82
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0399 - acc: 0.9881 - val_loss: 0.0498 - val_acc: 0.9832
Q 267+269
T 536 
 536 
---
Q 83+657 
T 740 
 740 
---
Q 17+15  
T 32  
 32  
---
Q 172+10 
T 182 
 182 
---
Q 173+50 
T 223 
 223 
---
Q 56+796 
T 852 
 852 
---
Q 813+479
T 1292
 1292
---
Q 246+73 
T 319 
 319 
---
Q 48+212 
T 260 
 260 
---
Q 720+703
T 1423
 1423
---

--------------------------------------------------
Iteration 83
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0047 - val_acc: 0.9990
Q 2+908  
T 910 
 910 
---
Q 308+132
T 440 
 440 
---
Q 32+474 
T 506 
 506 
---
Q 61+6   
T 67  
 67  
---
Q 9+855  
T 864 
 864 
---
Q 364+88 
T 452 
 452 
---
Q 943+331
T 1274
 1274
---
Q 71+671 
T 742 
 742 
---
Q 487+242
T 729 
 729 
---
Q 967+43 
T 1010
 1010
---

--------------------------------------------------
Iteration 84
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9993
Q 70+45  
T 115 
 115 
---
Q 78+426 
T 504 
 504 
---
Q 601+959
T 1560
 1560
---
Q 631+551
T 1182
 1182
---
Q 69+306 
T 375 
 375 
---
Q 790+98 
T 888 
 888 
---
Q 32+964 
T 996 
 996 
---
Q 898+657
T 1555
 1555
---
Q 25+200 
T 225 
 225 
---
Q 675+642
T 1317
 1317
---

--------------------------------------------------
Iteration 85
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9992
Q 363+13 
T 376 
 376 
---
Q 111+11 
T 122 
 122 
---
Q 728+8  
T 736 
 736 
---
Q 7+329  
T 336 
 336 
---
Q 37+573 
T 610 
 610 
---
Q 17+92  
T 109 
 109 
---
Q 375+4  
T 379 
 379 
---
Q 1+883  
T 884 
 884 
---
Q 5+406  
T 411 
 411 
---
Q 623+37 
T 660 
 660 
---

--------------------------------------------------
Iteration 86
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9993
Q 47+896 
T 943 
 943 
---
Q 70+969 
T 1039
 1039
---
Q 612+688
T 1300
 1300
---
Q 696+23 
T 719 
 719 
---
Q 675+320
T 995 
 995 
---
Q 878+88 
T 966 
 966 
---
Q 7+652  
T 659 
 659 
---
Q 200+748
T 948 
 948 
---
Q 27+845 
T 872 
 872 
---
Q 10+561 
T 571 
 571 
---

--------------------------------------------------
Iteration 87
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9993
Q 897+98 
T 995 
 995 
---
Q 995+97 
T 1092
 1092
---
Q 492+675
T 1167
 1167
---
Q 323+39 
T 362 
 362 
---
Q 27+847 
T 874 
 874 
---
Q 511+75 
T 586 
 586 
---
Q 131+79 
T 210 
 210 
---
Q 244+556
T 800 
 800 
---
Q 621+92 
T 713 
 713 
---
Q 518+772
T 1290
 1290
---

--------------------------------------------------
Iteration 88
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0304 - acc: 0.9904 - val_loss: 0.0357 - val_acc: 0.9883
Q 82+361 
T 443 
 443 
---
Q 31+378 
T 409 
 409 
---
Q 828+30 
T 858 
 858 
---
Q 68+27  
T 95  
 95  
---
Q 24+595 
T 619 
 619 
---
Q 761+394
T 1155
 1155
---
Q 57+67  
T 124 
 124 
---
Q 397+952
T 1349
 1349
---
Q 841+375
T 1216
 1216
---
Q 252+38 
T 290 
 290 
---

--------------------------------------------------
Iteration 89
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0063 - acc: 0.9986 - val_loss: 0.0126 - val_acc: 0.9964
Q 311+731
T 1042
 1042
---
Q 723+54 
T 777 
 777 
---
Q 0+370  
T 370 
 370 
---
Q 560+62 
T 622 
 622 
---
Q 5+370  
T 375 
 375 
---
Q 467+1  
T 468 
 468 
---
Q 379+952
T 1331
 1331
---
Q 95+545 
T 640 
 640 
---
Q 202+75 
T 277 
 277 
---
Q 706+3  
T 709 
 709 
---

--------------------------------------------------
Iteration 90
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0021 - acc: 0.9998 - val_loss: 0.0032 - val_acc: 0.9993
Q 932+912
T 1844
 1844
---
Q 119+606
T 725 
 725 
---
Q 26+320 
T 346 
 346 
---
Q 937+912
T 1849
 1849
---
Q 915+9  
T 924 
 924 
---
Q 13+62  
T 75  
 75  
---
Q 60+598 
T 658 
 658 
---
Q 17+179 
T 196 
 196 
---
Q 567+1  
T 568 
 568 
---
Q 979+6  
T 985 
 985 
---

--------------------------------------------------
Iteration 91
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 9.8340e-04 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9994
Q 962+93 
T 1055
 1055
---
Q 436+284
T 720 
 720 
---
Q 869+9  
T 878 
 878 
---
Q 868+898
T 1766
 1766
---
Q 957+82 
T 1039
 1039
---
Q 212+14 
T 226 
 226 
---
Q 467+911
T 1378
 1378
---
Q 70+969 
T 1039
 1039
---
Q 686+5  
T 691 
 691 
---
Q 39+47  
T 86  
 86  
---

--------------------------------------------------
Iteration 92
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 8.5705e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9994
Q 55+920 
T 975 
 975 
---
Q 83+21  
T 104 
 104 
---
Q 698+36 
T 734 
 734 
---
Q 43+90  
T 133 
 133 
---
Q 44+277 
T 321 
 321 
---
Q 488+94 
T 582 
 582 
---
Q 688+93 
T 781 
 781 
---
Q 298+49 
T 347 
 347 
---
Q 32+46  
T 78  
 78  
---
Q 201+63 
T 264 
 264 
---

--------------------------------------------------
Iteration 93
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0010 - acc: 0.9999 - val_loss: 0.0033 - val_acc: 0.9991
Q 365+81 
T 446 
 446 
---
Q 64+661 
T 725 
 725 
---
Q 685+10 
T 695 
 695 
---
Q 586+3  
T 589 
 589 
---
Q 57+376 
T 433 
 433 
---
Q 673+222
T 895 
 895 
---
Q 964+1  
T 965 
 965 
---
Q 836+997
T 1833
 1833
---
Q 59+65  
T 124 
 124 
---
Q 65+69  
T 134 
 134 
---

--------------------------------------------------
Iteration 94
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0402 - acc: 0.9879 - val_loss: 0.0257 - val_acc: 0.9925
Q 64+537 
T 601 
 601 
---
Q 55+265 
T 320 
 320 
---
Q 123+67 
T 190 
 190 
---
Q 83+880 
T 963 
 963 
---
Q 34+811 
T 845 
 845 
---
Q 7+700  
T 707 
 707 
---
Q 389+333
T 722 
 722 
---
Q 693+435
T 1128
 1128
---
Q 31+92  
T 123 
 123 
---
Q 987+5  
T 992 
 992 
---

--------------------------------------------------
Iteration 95
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0040 - acc: 0.9993 - val_loss: 0.0045 - val_acc: 0.9990
Q 97+307 
T 404 
 404 
---
Q 100+6  
T 106 
 106 
---
Q 928+190
T 1118
 1118
---
Q 63+52  
T 115 
 115 
---
Q 16+452 
T 468 
 468 
---
Q 791+3  
T 794 
 794 
---
Q 835+56 
T 891 
 891 
---
Q 33+466 
T 499 
 499 
---
Q 18+12  
T 30  
 30  
---
Q 330+206
T 536 
 536 
---

--------------------------------------------------
Iteration 96
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 0.9987
Q 289+80 
T 369 
 369 
---
Q 86+769 
T 855 
 855 
---
Q 85+76  
T 161 
 161 
---
Q 750+304
T 1054
 1054
---
Q 47+790 
T 837 
 837 
---
Q 825+815
T 1640
 1640
---
Q 886+362
T 1248
 1248
---
Q 703+20 
T 723 
 723 
---
Q 85+858 
T 943 
 943 
---
Q 74+64  
T 138 
 138 
---

--------------------------------------------------
Iteration 97
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 9.2016e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9992
Q 678+61 
T 739 
 739 
---
Q 402+28 
T 430 
 430 
---
Q 3+867  
T 870 
 870 
---
Q 417+29 
T 446 
 446 
---
Q 308+83 
T 391 
 391 
---
Q 592+253
T 845 
 845 
---
Q 84+965 
T 1049
 1049
---
Q 24+396 
T 420 
 420 
---
Q 581+986
T 1567
 1567
---
Q 50+397 
T 447 
 447 
---

--------------------------------------------------
Iteration 98
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 9.6975e-04 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9993
Q 98+440 
T 538 
 538 
---
Q 8+925  
T 933 
 933 
---
Q 749+6  
T 755 
 755 
---
Q 231+144
T 375 
 375 
---
Q 458+136
T 594 
 594 
---
Q 59+570 
T 629 
 629 
---
Q 252+942
T 1194
 1194
---
Q 2+627  
T 629 
 629 
---
Q 44+277 
T 321 
 321 
---
Q 895+43 
T 938 
 938 
---

--------------------------------------------------
Iteration 99
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.2628e-04 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 0.9993
Q 59+65  
T 124 
 124 
---
Q 390+518
T 908 
 908 
---
Q 60+202 
T 262 
 262 
---
Q 384+7  
T 391 
 391 
---
Q 86+507 
T 593 
 593 
---
Q 517+604
T 1121
 1121
---
Q 305+41 
T 346 
 346 
---
Q 509+42 
T 551 
 551 
---
Q 233+84 
T 317 
 317 
---
Q 542+46 
T 588 
 588 
---

--------------------------------------------------
Iteration 100
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 8.2039e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9991
Q 631+489
T 1120
 1120
---
Q 35+169 
T 204 
 204 
---
Q 66+873 
T 939 
 939 
---
Q 287+98 
T 385 
 385 
---
Q 277+6  
T 283 
 283 
---
Q 664+61 
T 725 
 725 
---
Q 6+833  
T 839 
 839 
---
Q 17+6   
T 23  
 23  
---
Q 162+32 
T 194 
 194 
---
Q 3+104  
T 107 
 107 
---

--------------------------------------------------
Iteration 101
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0264 - acc: 0.9931 - val_loss: 0.1528 - val_acc: 0.9535
Q 6+282  
T 288 
 288 
---
Q 43+679 
T 722 
 722 
---
Q 970+559
T 1529
 1529
---
Q 575+119
T 694 
 694 
---
Q 26+466 
T 492 
 492 
---
Q 791+3  
T 794 
 794 
---
Q 298+49 
T 347 
 348 
---
Q 560+33 
T 593 
 593 
---
Q 446+32 
T 478 
 478 
---
Q 32+4   
T 36  
 36  
---

--------------------------------------------------
Iteration 102
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0237 - acc: 0.9931 - val_loss: 0.0043 - val_acc: 0.9991
Q 300+70 
T 370 
 370 
---
Q 7+35   
T 42  
 42  
---
Q 799+745
T 1544
 1544
---
Q 430+76 
T 506 
 506 
---
Q 59+65  
T 124 
 124 
---
Q 4+285  
T 289 
 289 
---
Q 4+984  
T 988 
 988 
---
Q 350+374
T 724 
 724 
---
Q 628+32 
T 660 
 660 
---
Q 995+89 
T 1084
 1084
---

--------------------------------------------------
Iteration 103
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9992
Q 246+73 
T 319 
 319 
---
Q 919+656
T 1575
 1575
---
Q 876+414
T 1290
 1290
---
Q 730+678
T 1408
 1408
---
Q 26+249 
T 275 
 275 
---
Q 63+453 
T 516 
 516 
---
Q 0+940  
T 940 
 940 
---
Q 615+576
T 1191
 1191
---
Q 689+717
T 1406
 1406
---
Q 233+84 
T 317 
 317 
---

--------------------------------------------------
Iteration 104
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 9.1570e-04 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 0.9993
Q 621+608
T 1229
 1229
---
Q 9+500  
T 509 
 509 
---
Q 4+820  
T 824 
 824 
---
Q 22+907 
T 929 
 929 
---
Q 718+12 
T 730 
 730 
---
Q 170+359
T 529 
 529 
---
Q 784+792
T 1576
 1576
---
Q 604+54 
T 658 
 658 
---
Q 556+56 
T 612 
 612 
---
Q 36+121 
T 157 
 157 
---

--------------------------------------------------
Iteration 105
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.7731e-04 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 0.9993
Q 395+60 
T 455 
 455 
---
Q 987+92 
T 1079
 1079
---
Q 184+70 
T 254 
 254 
---
Q 883+338
T 1221
 1221
---
Q 9+426  
T 435 
 435 
---
Q 859+4  
T 863 
 863 
---
Q 910+72 
T 982 
 982 
---
Q 63+47  
T 110 
 110 
---
Q 4+325  
T 329 
 329 
---
Q 92+469 
T 561 
 561 
---

--------------------------------------------------
Iteration 106
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.2790e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9992
Q 138+66 
T 204 
 204 
---
Q 80+918 
T 998 
 998 
---
Q 902+83 
T 985 
 985 
---
Q 675+320
T 995 
 995 
---
Q 830+378
T 1208
 1208
---
Q 42+178 
T 220 
 220 
---
Q 6+6    
T 12  
 12  
---
Q 19+18  
T 37  
 37  
---
Q 5+148  
T 153 
 153 
---
Q 442+2  
T 444 
 444 
---

--------------------------------------------------
Iteration 107
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.1420e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9995
Q 400+275
T 675 
 675 
---
Q 417+84 
T 501 
 501 
---
Q 63+47  
T 110 
 110 
---
Q 2+51   
T 53  
 53  
---
Q 49+229 
T 278 
 278 
---
Q 428+43 
T 471 
 471 
---
Q 366+20 
T 386 
 386 
---
Q 4+543  
T 547 
 547 
---
Q 36+284 
T 320 
 320 
---
Q 816+816
T 1632
 1632
---

--------------------------------------------------
Iteration 108
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0263 - acc: 0.9922 - val_loss: 0.0096 - val_acc: 0.9970
Q 904+50 
T 954 
 954 
---
Q 392+47 
T 439 
 439 
---
Q 143+24 
T 167 
 167 
---
Q 473+43 
T 516 
 516 
---
Q 639+57 
T 696 
 696 
---
Q 105+38 
T 143 
 143 
---
Q 19+63  
T 82  
 82  
---
Q 68+195 
T 263 
 263 
---
Q 271+31 
T 302 
 302 
---
Q 93+492 
T 585 
 585 
---

--------------------------------------------------
Iteration 109
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0056 - acc: 0.9987 - val_loss: 0.0033 - val_acc: 0.9994
Q 236+89 
T 325 
 325 
---
Q 25+327 
T 352 
 352 
---
Q 9+205  
T 214 
 214 
---
Q 82+563 
T 645 
 645 
---
Q 996+4  
T 1000
 1000
---
Q 893+94 
T 987 
 987 
---
Q 45+663 
T 708 
 708 
---
Q 77+821 
T 898 
 898 
---
Q 8+658  
T 666 
 666 
---
Q 532+2  
T 534 
 534 
---

--------------------------------------------------
Iteration 110
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 8.6682e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9996
Q 600+12 
T 612 
 612 
---
Q 324+374
T 698 
 698 
---
Q 31+99  
T 130 
 130 
---
Q 2+172  
T 174 
 174 
---
Q 537+4  
T 541 
 541 
---
Q 12+681 
T 693 
 693 
---
Q 30+647 
T 677 
 677 
---
Q 24+76  
T 100 
 100 
---
Q 36+993 
T 1029
 1029
---
Q 375+213
T 588 
 588 
---

--------------------------------------------------
Iteration 111
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.7344e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9994
Q 17+733 
T 750 
 750 
---
Q 12+115 
T 127 
 127 
---
Q 285+93 
T 378 
 378 
---
Q 757+685
T 1442
 1442
---
Q 8+659  
T 667 
 667 
---
Q 3+561  
T 564 
 564 
---
Q 428+6  
T 434 
 434 
---
Q 516+8  
T 524 
 524 
---
Q 214+817
T 1031
 1031
---
Q 352+37 
T 389 
 389 
---

--------------------------------------------------
Iteration 112
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.9256e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9995
Q 504+69 
T 573 
 573 
---
Q 293+504
T 797 
 797 
---
Q 70+868 
T 938 
 938 
---
Q 4+463  
T 467 
 467 
---
Q 648+90 
T 738 
 738 
---
Q 894+62 
T 956 
 956 
---
Q 14+120 
T 134 
 134 
---
Q 91+77  
T 168 
 168 
---
Q 3+895  
T 898 
 898 
---
Q 6+555  
T 561 
 561 
---

--------------------------------------------------
Iteration 113
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.5867e-04 - acc: 0.9999 - val_loss: 0.0029 - val_acc: 0.9991
Q 394+433
T 827 
 827 
---
Q 719+64 
T 783 
 783 
---
Q 2+584  
T 586 
 586 
---
Q 880+756
T 1636
 1636
---
Q 711+133
T 844 
 844 
---
Q 553+803
T 1356
 1356
---
Q 822+648
T 1470
 1470
---
Q 204+17 
T 221 
 221 
---
Q 508+6  
T 514 
 514 
---
Q 168+1  
T 169 
 169 
---

--------------------------------------------------
Iteration 114
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0354 - acc: 0.9896 - val_loss: 0.0043 - val_acc: 0.9991
Q 501+446
T 947 
 947 
---
Q 218+70 
T 288 
 288 
---
Q 17+179 
T 196 
 196 
---
Q 96+114 
T 210 
 210 
---
Q 170+359
T 529 
 529 
---
Q 373+3  
T 376 
 376 
---
Q 6+241  
T 247 
 247 
---
Q 445+73 
T 518 
 518 
---
Q 51+435 
T 486 
 486 
---
Q 18+258 
T 276 
 276 
---

--------------------------------------------------
Iteration 115
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0016 - acc: 0.9999 - val_loss: 0.0030 - val_acc: 0.9993
Q 89+364 
T 453 
 453 
---
Q 77+74  
T 151 
 151 
---
Q 524+3  
T 527 
 527 
---
Q 765+52 
T 817 
 817 
---
Q 271+1  
T 272 
 272 
---
Q 916+30 
T 946 
 946 
---
Q 155+320
T 475 
 475 
---
Q 970+559
T 1529
 1529
---
Q 90+859 
T 949 
 949 
---
Q 79+32  
T 111 
 111 
---

--------------------------------------------------
Iteration 116
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.6375e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9994
Q 484+990
T 1474
 1474
---
Q 912+596
T 1508
 1508
---
Q 7+188  
T 195 
 195 
---
Q 144+20 
T 164 
 164 
---
Q 4+411  
T 415 
 415 
---
Q 423+660
T 1083
 1083
---
Q 323+487
T 810 
 810 
---
Q 740+708
T 1448
 1448
---
Q 103+478
T 581 
 581 
---
Q 759+63 
T 822 
 822 
---

--------------------------------------------------
Iteration 117
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.1588e-04 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 0.9994
Q 37+537 
T 574 
 574 
---
Q 713+438
T 1151
 1151
---
Q 911+5  
T 916 
 916 
---
Q 59+317 
T 376 
 376 
---
Q 6+588  
T 594 
 594 
---
Q 745+70 
T 815 
 815 
---
Q 4+925  
T 929 
 929 
---
Q 299+55 
T 354 
 354 
---
Q 89+95  
T 184 
 184 
---
Q 492+95 
T 587 
 587 
---

--------------------------------------------------
Iteration 118
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.5382e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9995
Q 676+7  
T 683 
 683 
---
Q 644+544
T 1188
 1188
---
Q 3+858  
T 861 
 861 
---
Q 539+71 
T 610 
 610 
---
Q 959+602
T 1561
 1561
---
Q 523+6  
T 529 
 529 
---
Q 72+34  
T 106 
 106 
---
Q 41+674 
T 715 
 715 
---
Q 995+586
T 1581
 1581
---
Q 1+950  
T 951 
 951 
---

--------------------------------------------------
Iteration 119
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.0879e-04 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 0.9993
Q 8+66   
T 74  
 74  
---
Q 53+120 
T 173 
 173 
---
Q 133+885
T 1018
 1018
---
Q 414+590
T 1004
 1004
---
Q 5+148  
T 153 
 153 
---
Q 41+961 
T 1002
 1002
---
Q 64+839 
T 903 
 903 
---
Q 57+29  
T 86  
 86  
---
Q 56+93  
T 149 
 149 
---
Q 27+374 
T 401 
 401 
---

--------------------------------------------------
Iteration 120
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0288 - acc: 0.9914 - val_loss: 0.0510 - val_acc: 0.9835
Q 564+72 
T 636 
 636 
---
Q 0+940  
T 940 
 940 
---
Q 215+8  
T 223 
 223 
---
Q 74+202 
T 276 
 276 
---
Q 393+91 
T 484 
 484 
---
Q 876+288
T 1164
 1254
---
Q 309+9  
T 318 
 318 
---
Q 634+35 
T 669 
 669 
---
Q 64+2   
T 66  
 66  
---
Q 234+56 
T 290 
 290 
---

--------------------------------------------------
Iteration 121
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0084 - acc: 0.9978 - val_loss: 0.0036 - val_acc: 0.9992
Q 560+701
T 1261
 1261
---
Q 4+850  
T 854 
 854 
---
Q 983+1  
T 984 
 984 
---
Q 220+0  
T 220 
 220 
---
Q 359+95 
T 454 
 454 
---
Q 79+939 
T 1018
 1018
---
Q 71+384 
T 455 
 455 
---
Q 17+278 
T 295 
 295 
---
Q 928+22 
T 950 
 950 
---
Q 438+525
T 963 
 963 
---

--------------------------------------------------
Iteration 122
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0103 - acc: 0.9973 - val_loss: 0.0182 - val_acc: 0.9941
Q 37+413 
T 450 
 450 
---
Q 374+960
T 1334
 1334
---
Q 836+55 
T 891 
 891 
---
Q 262+760
T 1022
 1022
---
Q 753+634
T 1387
 1387
---
Q 126+235
T 361 
 361 
---
Q 585+6  
T 591 
 591 
---
Q 392+47 
T 439 
 439 
---
Q 902+459
T 1361
 1361
---
Q 938+53 
T 991 
 991 
---

--------------------------------------------------
Iteration 123
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0024 - val_acc: 0.9994
Q 14+202 
T 216 
 216 
---
Q 7+366  
T 373 
 373 
---
Q 3+561  
T 564 
 564 
---
Q 926+960
T 1886
 1886
---
Q 1+368  
T 369 
 369 
---
Q 14+227 
T 241 
 241 
---
Q 532+54 
T 586 
 586 
---
Q 37+573 
T 610 
 610 
---
Q 393+13 
T 406 
 406 
---
Q 543+89 
T 632 
 632 
---

--------------------------------------------------
Iteration 124
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.2915e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9997
Q 655+88 
T 743 
 743 
---
Q 861+626
T 1487
 1487
---
Q 944+25 
T 969 
 969 
---
Q 93+681 
T 774 
 774 
---
Q 111+51 
T 162 
 162 
---
Q 42+46  
T 88  
 88  
---
Q 25+200 
T 225 
 225 
---
Q 947+507
T 1454
 1454
---
Q 1+950  
T 951 
 951 
---
Q 84+213 
T 297 
 297 
---

--------------------------------------------------
Iteration 125
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.1835e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9995
Q 545+422
T 967 
 967 
---
Q 22+94  
T 116 
 116 
---
Q 42+848 
T 890 
 890 
---
Q 986+20 
T 1006
 1006
---
Q 273+324
T 597 
 597 
---
Q 887+359
T 1246
 1246
---
Q 686+5  
T 691 
 691 
---
Q 613+56 
T 669 
 669 
---
Q 409+19 
T 428 
 428 
---
Q 843+43 
T 886 
 886 
---

--------------------------------------------------
Iteration 126
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.5357e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996
Q 14+163 
T 177 
 177 
---
Q 364+88 
T 452 
 452 
---
Q 956+69 
T 1025
 1025
---
Q 31+677 
T 708 
 708 
---
Q 295+239
T 534 
 534 
---
Q 543+133
T 676 
 676 
---
Q 895+746
T 1641
 1641
---
Q 496+789
T 1285
 1285
---
Q 308+710
T 1018
 1018
---
Q 100+341
T 441 
 441 
---

--------------------------------------------------
Iteration 127
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.2913e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9996
Q 13+630 
T 643 
 643 
---
Q 56+85  
T 141 
 141 
---
Q 834+576
T 1410
 1410
---
Q 619+891
T 1510
 1510
---
Q 85+695 
T 780 
 780 
---
Q 68+45  
T 113 
 113 
---
Q 784+792
T 1576
 1576
---
Q 687+67 
T 754 
 754 
---
Q 61+630 
T 691 
 691 
---
Q 46+419 
T 465 
 465 
---

--------------------------------------------------
Iteration 128
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0331 - acc: 0.9919 - val_loss: 0.0032 - val_acc: 0.9994
Q 43+738 
T 781 
 781 
---
Q 473+867
T 1340
 1340
---
Q 75+923 
T 998 
 998 
---
Q 6+885  
T 891 
 891 
---
Q 322+83 
T 405 
 405 
---
Q 582+18 
T 600 
 600 
---
Q 93+681 
T 774 
 774 
---
Q 25+522 
T 547 
 547 
---
Q 56+38  
T 94  
 94  
---
Q 896+86 
T 982 
 982 
---

--------------------------------------------------
Iteration 129
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 9.5373e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 0.9996
Q 142+45 
T 187 
 187 
---
Q 963+37 
T 1000
 1000
---
Q 314+676
T 990 
 990 
---
Q 22+94  
T 116 
 116 
---
Q 72+314 
T 386 
 386 
---
Q 12+195 
T 207 
 207 
---
Q 396+692
T 1088
 1088
---
Q 43+7   
T 50  
 50  
---
Q 3+705  
T 708 
 708 
---
Q 482+316
T 798 
 798 
---

--------------------------------------------------
Iteration 130
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.2846e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996
Q 671+90 
T 761 
 761 
---
Q 961+53 
T 1014
 1014
---
Q 6+935  
T 941 
 941 
---
Q 869+752
T 1621
 1621
---
Q 66+564 
T 630 
 630 
---
Q 926+411
T 1337
 1337
---
Q 543+80 
T 623 
 623 
---
Q 5+875  
T 880 
 880 
---
Q 590+86 
T 676 
 676 
---
Q 907+990
T 1897
 1897
---

--------------------------------------------------
Iteration 131
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.5177e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9997
Q 6+896  
T 902 
 902 
---
Q 74+202 
T 276 
 276 
---
Q 657+9  
T 666 
 666 
---
Q 831+273
T 1104
 1104
---
Q 18+490 
T 508 
 508 
---
Q 604+49 
T 653 
 653 
---
Q 893+978
T 1871
 1871
---
Q 990+322
T 1312
 1312
---
Q 779+10 
T 789 
 789 
---
Q 3+573  
T 576 
 576 
---

--------------------------------------------------
Iteration 132
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.6718e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996
Q 100+14 
T 114 
 114 
---
Q 758+64 
T 822 
 822 
---
Q 340+11 
T 351 
 351 
---
Q 22+426 
T 448 
 448 
---
Q 56+481 
T 537 
 537 
---
Q 76+755 
T 831 
 831 
---
Q 51+89  
T 140 
 140 
---
Q 35+250 
T 285 
 285 
---
Q 100+6  
T 106 
 106 
---
Q 9+312  
T 321 
 321 
---

--------------------------------------------------
Iteration 133
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.1220e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996
Q 160+61 
T 221 
 221 
---
Q 7+826  
T 833 
 833 
---
Q 460+50 
T 510 
 510 
---
Q 20+199 
T 219 
 219 
---
Q 183+99 
T 282 
 282 
---
Q 64+555 
T 619 
 619 
---
Q 565+838
T 1403
 1403
---
Q 154+82 
T 236 
 236 
---
Q 6+249  
T 255 
 255 
---
Q 256+86 
T 342 
 342 
---

--------------------------------------------------
Iteration 134
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.7334e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9996
Q 0+804  
T 804 
 804 
---
Q 83+154 
T 237 
 237 
---
Q 691+290
T 981 
 980 
---
Q 87+322 
T 409 
 409 
---
Q 749+720
T 1469
 1469
---
Q 3+654  
T 657 
 657 
---
Q 697+79 
T 776 
 776 
---
Q 722+22 
T 744 
 744 
---
Q 53+896 
T 949 
 949 
---
Q 3+552  
T 555 
 555 
---

--------------------------------------------------
Iteration 135
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.7229e-04 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9989
Q 685+10 
T 695 
 695 
---
Q 553+803
T 1356
 1356
---
Q 465+875
T 1340
 1340
---
Q 0+343  
T 343 
 343 
---
Q 417+85 
T 502 
 502 
---
Q 483+911
T 1394
 1394
---
Q 812+8  
T 820 
 820 
---
Q 57+199 
T 256 
 256 
---
Q 612+688
T 1300
 1300
---
Q 698+88 
T 786 
 786 
---

--------------------------------------------------
Iteration 136
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0374 - acc: 0.9893 - val_loss: 0.0057 - val_acc: 0.9983
Q 70+868 
T 938 
 938 
---
Q 372+9  
T 381 
 381 
---
Q 425+522
T 947 
 947 
---
Q 809+456
T 1265
 1265
---
Q 0+765  
T 765 
 765 
---
Q 989+5  
T 994 
 994 
---
Q 797+880
T 1677
 1677
---
Q 371+45 
T 416 
 416 
---
Q 28+66  
T 94  
 94  
---
Q 32+529 
T 561 
 561 
---

--------------------------------------------------
Iteration 137
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0017 - acc: 0.9998 - val_loss: 0.0025 - val_acc: 0.9996
Q 798+590
T 1388
 1388
---
Q 801+86 
T 887 
 887 
---
Q 9+210  
T 219 
 219 
---
Q 131+79 
T 210 
 210 
---
Q 0+614  
T 614 
 614 
---
Q 34+101 
T 135 
 135 
---
Q 607+540
T 1147
 1147
---
Q 305+756
T 1061
 1061
---
Q 69+716 
T 785 
 785 
---
Q 822+648
T 1470
 1470
---

--------------------------------------------------
Iteration 138
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.1675e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9996
Q 44+56  
T 100 
 100 
---
Q 386+291
T 677 
 677 
---
Q 206+83 
T 289 
 289 
---
Q 416+328
T 744 
 744 
---
Q 46+10  
T 56  
 56  
---
Q 586+61 
T 647 
 647 
---
Q 7+315  
T 322 
 322 
---
Q 91+297 
T 388 
 388 
---
Q 247+11 
T 258 
 258 
---
Q 352+112
T 464 
 464 
---

--------------------------------------------------
Iteration 139
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.0843e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9997
Q 140+66 
T 206 
 206 
---
Q 61+64  
T 125 
 125 
---
Q 906+341
T 1247
 1247
---
Q 929+20 
T 949 
 949 
---
Q 71+3   
T 74  
 74  
---
Q 15+87  
T 102 
 102 
---
Q 540+489
T 1029
 1029
---
Q 68+309 
T 377 
 377 
---
Q 786+534
T 1320
 1320
---
Q 97+89  
T 186 
 186 
---

--------------------------------------------------
Iteration 140
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.3488e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997
Q 43+303 
T 346 
 346 
---
Q 38+899 
T 937 
 937 
---
Q 695+90 
T 785 
 785 
---
Q 85+692 
T 777 
 777 
---
Q 526+1  
T 527 
 527 
---
Q 419+92 
T 511 
 511 
---
Q 4+968  
T 972 
 972 
---
Q 30+383 
T 413 
 413 
---
Q 32+126 
T 158 
 158 
---
Q 87+621 
T 708 
 708 
---

--------------------------------------------------
Iteration 141
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.9372e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9998
Q 689+717
T 1406
 1406
---
Q 33+834 
T 867 
 867 
---
Q 292+374
T 666 
 666 
---
Q 340+11 
T 351 
 351 
---
Q 879+387
T 1266
 1266
---
Q 531+457
T 988 
 988 
---
Q 177+155
T 332 
 332 
---
Q 47+253 
T 300 
 300 
---
Q 385+668
T 1053
 1053
---
Q 148+2  
T 150 
 150 
---

--------------------------------------------------
Iteration 142
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.2853e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9994
Q 47+150 
T 197 
 197 
---
Q 750+6  
T 756 
 756 
---
Q 122+575
T 697 
 697 
---
Q 723+54 
T 777 
 777 
---
Q 4+885  
T 889 
 889 
---
Q 94+288 
T 382 
 382 
---
Q 2+490  
T 492 
 492 
---
Q 61+219 
T 280 
 280 
---
Q 947+82 
T 1029
 1029
---
Q 443+287
T 730 
 730 
---

--------------------------------------------------
Iteration 143
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0444 - acc: 0.9877 - val_loss: 0.0122 - val_acc: 0.9964
Q 715+864
T 1579
 1579
---
Q 32+252 
T 284 
 284 
---
Q 556+74 
T 630 
 630 
---
Q 39+80  
T 119 
 119 
---
Q 294+17 
T 311 
 311 
---
Q 78+116 
T 194 
 194 
---
Q 58+824 
T 882 
 882 
---
Q 16+390 
T 406 
 406 
---
Q 668+19 
T 687 
 687 
---
Q 557+22 
T 579 
 579 
---

--------------------------------------------------
Iteration 144
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0030 - val_acc: 0.9994
Q 395+232
T 627 
 627 
---
Q 400+139
T 539 
 539 
---
Q 794+271
T 1065
 1065
---
Q 443+287
T 730 
 730 
---
Q 336+10 
T 346 
 346 
---
Q 351+76 
T 427 
 427 
---
Q 75+71  
T 146 
 146 
---
Q 681+267
T 948 
 948 
---
Q 828+387
T 1215
 1215
---
Q 826+340
T 1166
 1166
---

--------------------------------------------------
Iteration 145
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.6714e-04 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 0.9993
Q 821+66 
T 887 
 887 
---
Q 45+663 
T 708 
 708 
---
Q 218+83 
T 301 
 301 
---
Q 64+77  
T 141 
 141 
---
Q 540+692
T 1232
 1232
---
Q 569+7  
T 576 
 576 
---
Q 310+88 
T 398 
 398 
---
Q 787+9  
T 796 
 796 
---
Q 1+718  
T 719 
 719 
---
Q 1+461  
T 462 
 462 
---

--------------------------------------------------
Iteration 146
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.5957e-04 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 0.9995
Q 76+72  
T 148 
 148 
---
Q 5+82   
T 87  
 87  
---
Q 689+241
T 930 
 930 
---
Q 65+139 
T 204 
 204 
---
Q 572+270
T 842 
 842 
---
Q 83+506 
T 589 
 589 
---
Q 308+132
T 440 
 440 
---
Q 56+721 
T 777 
 777 
---
Q 823+4  
T 827 
 827 
---
Q 949+710
T 1659
 1659
---

--------------------------------------------------
Iteration 147
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.7119e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9998
Q 47+29  
T 76  
 76  
---
Q 0+451  
T 451 
 451 
---
Q 74+954 
T 1028
 1028
---
Q 266+77 
T 343 
 343 
---
Q 32+529 
T 561 
 561 
---
Q 570+579
T 1149
 1149
---
Q 62+516 
T 578 
 578 
---
Q 4+543  
T 547 
 547 
---
Q 573+826
T 1399
 1399
---
Q 272+927
T 1199
 1199
---

--------------------------------------------------
Iteration 148
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.0898e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996
Q 3+654  
T 657 
 657 
---
Q 32+334 
T 366 
 366 
---
Q 703+80 
T 783 
 783 
---
Q 205+14 
T 219 
 219 
---
Q 279+935
T 1214
 1214
---
Q 93+810 
T 903 
 903 
---
Q 381+59 
T 440 
 440 
---
Q 64+76  
T 140 
 140 
---
Q 122+575
T 697 
 697 
---
Q 903+188
T 1091
 1091
---

--------------------------------------------------
Iteration 149
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.6289e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9995
Q 79+550 
T 629 
 629 
---
Q 344+18 
T 362 
 362 
---
Q 950+35 
T 985 
 985 
---
Q 83+434 
T 517 
 517 
---
Q 16+982 
T 998 
 998 
---
Q 329+57 
T 386 
 386 
---
Q 16+990 
T 1006
 1006
---
Q 986+20 
T 1006
 1006
---
Q 192+747
T 939 
 939 
---
Q 65+39  
T 104 
 104 
---

--------------------------------------------------
Iteration 150
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.2984e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9996
Q 90+852 
T 942 
 942 
---
Q 3+987  
T 990 
 990 
---
Q 897+23 
T 920 
 920 
---
Q 26+320 
T 346 
 346 
---
Q 92+3   
T 95  
 95  
---
Q 910+47 
T 957 
 957 
---
Q 66+691 
T 757 
 757 
---
Q 356+448
T 804 
 804 
---
Q 452+308
T 760 
 760 
---
Q 463+67 
T 530 
 530 
---

--------------------------------------------------
Iteration 151
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0279 - acc: 0.9920 - val_loss: 0.0163 - val_acc: 0.9952
Q 61+37  
T 98  
 98  
---
Q 63+353 
T 416 
 416 
---
Q 894+98 
T 992 
 992 
---
Q 3+665  
T 668 
 668 
---
Q 238+813
T 1051
 1051
---
Q 98+996 
T 1094
 1094
---
Q 20+7   
T 27  
 27  
---
Q 781+95 
T 876 
 876 
---
Q 853+535
T 1388
 1388
---
Q 352+400
T 752 
 752 
---

--------------------------------------------------
Iteration 152
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0030 - val_acc: 0.9992
Q 51+350 
T 401 
 401 
---
Q 401+2  
T 403 
 403 
---
Q 25+200 
T 225 
 225 
---
Q 546+54 
T 600 
 600 
---
Q 393+91 
T 484 
 484 
---
Q 91+606 
T 697 
 697 
---
Q 376+330
T 706 
 706 
---
Q 81+148 
T 229 
 229 
---
Q 45+155 
T 200 
 200 
---
Q 449+350
T 799 
 799 
---

--------------------------------------------------
Iteration 153
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.3586e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 0.9996
Q 779+4  
T 783 
 783 
---
Q 438+213
T 651 
 651 
---
Q 56+810 
T 866 
 866 
---
Q 308+672
T 980 
 980 
---
Q 952+123
T 1075
 1075
---
Q 216+190
T 406 
 406 
---
Q 995+373
T 1368
 1368
---
Q 20+330 
T 350 
 350 
---
Q 623+9  
T 632 
 632 
---
Q 280+876
T 1156
 1156
---

--------------------------------------------------
Iteration 154
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.7734e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 0.9997
Q 8+700  
T 708 
 708 
---
Q 61+668 
T 729 
 729 
---
Q 277+584
T 861 
 861 
---
Q 507+51 
T 558 
 558 
---
Q 20+689 
T 709 
 709 
---
Q 81+314 
T 395 
 395 
---
Q 95+328 
T 423 
 423 
---
Q 74+829 
T 903 
 903 
---
Q 49+145 
T 194 
 194 
---
Q 52+363 
T 415 
 415 
---

--------------------------------------------------
Iteration 155
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.0083e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996
Q 615+576
T 1191
 1191
---
Q 444+85 
T 529 
 529 
---
Q 259+3  
T 262 
 262 
---
Q 2+306  
T 308 
 308 
---
Q 44+0   
T 44  
 44  
---
Q 586+3  
T 589 
 589 
---
Q 359+95 
T 454 
 454 
---
Q 933+45 
T 978 
 978 
---
Q 19+46  
T 65  
 65  
---
Q 36+21  
T 57  
 57  
---

--------------------------------------------------
Iteration 156
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.5917e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9997
Q 836+91 
T 927 
 927 
---
Q 99+691 
T 790 
 790 
---
Q 422+87 
T 509 
 509 
---
Q 532+909
T 1441
 1441
---
Q 12+115 
T 127 
 127 
---
Q 927+5  
T 932 
 932 
---
Q 68+622 
T 690 
 690 
---
Q 100+341
T 441 
 441 
---
Q 851+10 
T 861 
 861 
---
Q 32+18  
T 50  
 50  
---

--------------------------------------------------
Iteration 157
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0238 - val_acc: 0.9931
Q 93+87  
T 180 
 180 
---
Q 4+525  
T 529 
 529 
---
Q 753+278
T 1031
 1031
---
Q 97+976 
T 1073
 1073
---
Q 94+96  
T 190 
 190 
---
Q 32+126 
T 158 
 158 
---
Q 252+640
T 892 
 892 
---
Q 285+71 
T 356 
 356 
---
Q 156+30 
T 186 
 186 
---
Q 836+997
T 1833
 1833
---

--------------------------------------------------
Iteration 158
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0234 - acc: 0.9928 - val_loss: 0.0030 - val_acc: 0.9993
Q 327+610
T 937 
 937 
---
Q 138+968
T 1106
 1106
---
Q 238+18 
T 256 
 256 
---
Q 697+721
T 1418
 1418
---
Q 712+65 
T 777 
 777 
---
Q 888+9  
T 897 
 897 
---
Q 96+706 
T 802 
 802 
---
Q 19+338 
T 357 
 357 
---
Q 180+285
T 465 
 465 
---
Q 436+46 
T 482 
 482 
---

--------------------------------------------------
Iteration 159
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 7.0986e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996
Q 341+96 
T 437 
 437 
---
Q 67+706 
T 773 
 773 
---
Q 149+561
T 710 
 710 
---
Q 28+22  
T 50  
 50  
---
Q 918+62 
T 980 
 980 
---
Q 41+62  
T 103 
 103 
---
Q 47+541 
T 588 
 588 
---
Q 72+72  
T 144 
 144 
---
Q 60+54  
T 114 
 114 
---
Q 519+76 
T 595 
 595 
---

--------------------------------------------------
Iteration 160
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.6011e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9997
Q 68+335 
T 403 
 403 
---
Q 938+313
T 1251
 1251
---
Q 22+71  
T 93  
 93  
---
Q 681+267
T 948 
 948 
---
Q 84+711 
T 795 
 795 
---
Q 75+923 
T 998 
 998 
---
Q 825+815
T 1640
 1640
---
Q 93+91  
T 184 
 184 
---
Q 123+173
T 296 
 296 
---
Q 705+53 
T 758 
 758 
---

--------------------------------------------------
Iteration 161
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.8461e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997
Q 194+50 
T 244 
 244 
---
Q 25+697 
T 722 
 722 
---
Q 703+8  
T 711 
 711 
---
Q 17+419 
T 436 
 436 
---
Q 420+0  
T 420 
 420 
---
Q 664+767
T 1431
 1431
---
Q 45+120 
T 165 
 165 
---
Q 682+94 
T 776 
 776 
---
Q 785+956
T 1741
 1741
---
Q 88+819 
T 907 
 907 
---

--------------------------------------------------
Iteration 162
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.5019e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997
Q 243+251
T 494 
 494 
---
Q 456+35 
T 491 
 491 
---
Q 94+954 
T 1048
 1048
---
Q 68+335 
T 403 
 403 
---
Q 619+891
T 1510
 1510
---
Q 1+235  
T 236 
 236 
---
Q 334+15 
T 349 
 349 
---
Q 835+1  
T 836 
 836 
---
Q 23+236 
T 259 
 259 
---
Q 78+116 
T 194 
 194 
---

--------------------------------------------------
Iteration 163
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1164 - val_acc: 0.9708
Q 739+956
T 1695
 1795
---
Q 607+540
T 1147
 1147
---
Q 5+643  
T 648 
 648 
---
Q 842+990
T 1832
 1832
---
Q 901+85 
T 986 
 986 
---
Q 74+64  
T 138 
 138 
---
Q 16+974 
T 990 
 990 
---
Q 239+528
T 767 
 767 
---
Q 61+325 
T 386 
 386 
---
Q 240+99 
T 339 
 339 
---

--------------------------------------------------
Iteration 164
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0332 - acc: 0.9904 - val_loss: 0.0040 - val_acc: 0.9987
Q 43+385 
T 428 
 428 
---
Q 64+77  
T 141 
 141 
---
Q 67+813 
T 880 
 880 
---
Q 28+321 
T 349 
 349 
---
Q 46+34  
T 80  
 80  
---
Q 83+817 
T 900 
 900 
---
Q 0+244  
T 244 
 244 
---
Q 725+37 
T 762 
 762 
---
Q 583+770
T 1353
 1353
---
Q 63+162 
T 225 
 225 
---

--------------------------------------------------
Iteration 165
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0028 - val_acc: 0.9992
Q 127+9  
T 136 
 136 
---
Q 964+82 
T 1046
 1046
---
Q 682+94 
T 776 
 776 
---
Q 337+164
T 501 
 501 
---
Q 680+907
T 1587
 1587
---
Q 320+260
T 580 
 580 
---
Q 33+538 
T 571 
 571 
---
Q 16+441 
T 457 
 457 
---
Q 292+576
T 868 
 868 
---
Q 60+471 
T 531 
 531 
---

--------------------------------------------------
Iteration 166
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 5.6554e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 0.9996
Q 79+417 
T 496 
 496 
---
Q 1+527  
T 528 
 528 
---
Q 604+96 
T 700 
 700 
---
Q 768+589
T 1357
 1357
---
Q 660+91 
T 751 
 751 
---
Q 945+93 
T 1038
 1038
---
Q 58+728 
T 786 
 786 
---
Q 294+17 
T 311 
 311 
---
Q 734+972
T 1706
 1706
---
Q 516+732
T 1248
 1248
---

--------------------------------------------------
Iteration 167
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.2561e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997
Q 73+468 
T 541 
 541 
---
Q 92+3   
T 95  
 95  
---
Q 26+743 
T 769 
 769 
---
Q 1+847  
T 848 
 848 
---
Q 50+941 
T 991 
 991 
---
Q 8+313  
T 321 
 321 
---
Q 194+611
T 805 
 805 
---
Q 982+593
T 1575
 1575
---
Q 8+587  
T 595 
 595 
---
Q 916+89 
T 1005
 1005
---

--------------------------------------------------
Iteration 168
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.6044e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9998
Q 84+260 
T 344 
 344 
---
Q 55+547 
T 602 
 602 
---
Q 258+592
T 850 
 850 
---
Q 96+886 
T 982 
 982 
---
Q 304+478
T 782 
 782 
---
Q 808+6  
T 814 
 814 
---
Q 214+893
T 1107
 1107
---
Q 39+71  
T 110 
 110 
---
Q 836+525
T 1361
 1361
---
Q 218+83 
T 301 
 301 
---

--------------------------------------------------
Iteration 169
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.1522e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9998
Q 90+348 
T 438 
 438 
---
Q 901+788
T 1689
 1689
---
Q 275+83 
T 358 
 358 
---
Q 166+896
T 1062
 1062
---
Q 378+512
T 890 
 890 
---
Q 765+855
T 1620
 1620
---
Q 98+1   
T 99  
 99  
---
Q 86+125 
T 211 
 211 
---
Q 69+306 
T 375 
 375 
---
Q 83+506 
T 589 
 589 
---

--------------------------------------------------
Iteration 170
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.8299e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997
Q 390+66 
T 456 
 456 
---
Q 65+139 
T 204 
 204 
---
Q 894+78 
T 972 
 972 
---
Q 849+159
T 1008
 1008
---
Q 51+976 
T 1027
 1027
---
Q 375+4  
T 379 
 379 
---
Q 631+692
T 1323
 1323
---
Q 37+396 
T 433 
 433 
---
Q 1+138  
T 139 
 139 
---
Q 165+140
T 305 
 305 
---

--------------------------------------------------
Iteration 171
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.9395e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997
Q 975+616
T 1591
 1591
---
Q 2+132  
T 134 
 134 
---
Q 56+212 
T 268 
 268 
---
Q 874+497
T 1371
 1371
---
Q 574+7  
T 581 
 581 
---
Q 643+0  
T 643 
 643 
---
Q 76+47  
T 123 
 123 
---
Q 800+941
T 1741
 1741
---
Q 402+28 
T 430 
 430 
---
Q 994+559
T 1553
 1553
---

--------------------------------------------------
Iteration 172
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1125 - val_acc: 0.9663
Q 545+74 
T 619 
 619 
---
Q 1+935  
T 936 
 936 
---
Q 728+38 
T 766 
 766 
---
Q 64+541 
T 605 
 605 
---
Q 695+681
T 1376
 1376
---
Q 68+223 
T 291 
 291 
---
Q 17+6   
T 23  
 23  
---
Q 830+208
T 1038
 1038
---
Q 339+111
T 450 
 450 
---
Q 671+90 
T 761 
 761 
---

--------------------------------------------------
Iteration 173
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0239 - acc: 0.9928 - val_loss: 0.0029 - val_acc: 0.9993
Q 47+122 
T 169 
 169 
---
Q 640+6  
T 646 
 646 
---
Q 748+57 
T 805 
 805 
---
Q 8+630  
T 638 
 638 
---
Q 287+4  
T 291 
 291 
---
Q 348+944
T 1292
 1292
---
Q 68+335 
T 403 
 403 
---
Q 479+346
T 825 
 825 
---
Q 42+22  
T 64  
 64  
---
Q 284+81 
T 365 
 365 
---

--------------------------------------------------
Iteration 174
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.9017e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 0.9996
Q 95+133 
T 228 
 228 
---
Q 22+620 
T 642 
 642 
---
Q 14+255 
T 269 
 269 
---
Q 2+110  
T 112 
 112 
---
Q 127+83 
T 210 
 210 
---
Q 981+20 
T 1001
 1001
---
Q 98+440 
T 538 
 538 
---
Q 150+2  
T 152 
 152 
---
Q 882+989
T 1871
 1871
---
Q 402+654
T 1056
 1056
---

--------------------------------------------------
Iteration 175
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 4.1856e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 0.9996
Q 538+1  
T 539 
 539 
---
Q 330+12 
T 342 
 342 
---
Q 945+7  
T 952 
 952 
---
Q 72+411 
T 483 
 483 
---
Q 80+948 
T 1028
 1028
---
Q 982+30 
T 1012
 1012
---
Q 49+396 
T 445 
 445 
---
Q 258+8  
T 266 
 266 
---
Q 143+61 
T 204 
 204 
---
Q 48+155 
T 203 
 203 
---

--------------------------------------------------
Iteration 176
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.4603e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9997
Q 7+915  
T 922 
 922 
---
Q 828+2  
T 830 
 830 
---
Q 76+143 
T 219 
 219 
---
Q 17+970 
T 987 
 987 
---
Q 28+780 
T 808 
 808 
---
Q 583+770
T 1353
 1353
---
Q 473+43 
T 516 
 516 
---
Q 297+376
T 673 
 673 
---
Q 759+19 
T 778 
 778 
---
Q 4+184  
T 188 
 188 
---

--------------------------------------------------
Iteration 177
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.9866e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9998
Q 47+423 
T 470 
 470 
---
Q 263+531
T 794 
 794 
---
Q 308+710
T 1018
 1018
---
Q 967+92 
T 1059
 1059
---
Q 37+544 
T 581 
 581 
---
Q 623+81 
T 704 
 704 
---
Q 8+733  
T 741 
 741 
---
Q 592+253
T 845 
 845 
---
Q 275+96 
T 371 
 371 
---
Q 159+42 
T 201 
 201 
---

--------------------------------------------------
Iteration 178
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.6255e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9998
Q 79+340 
T 419 
 419 
---
Q 65+695 
T 760 
 760 
---
Q 57+657 
T 714 
 714 
---
Q 79+551 
T 630 
 630 
---
Q 86+125 
T 211 
 211 
---
Q 52+501 
T 553 
 553 
---
Q 761+0  
T 761 
 761 
---
Q 84+213 
T 297 
 297 
---
Q 43+303 
T 346 
 346 
---
Q 492+548
T 1040
 1040
---

--------------------------------------------------
Iteration 179
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.3539e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9997
Q 238+28 
T 266 
 266 
---
Q 409+60 
T 469 
 469 
---
Q 639+593
T 1232
 1232
---
Q 276+59 
T 335 
 335 
---
Q 126+66 
T 192 
 192 
---
Q 874+787
T 1661
 1661
---
Q 305+41 
T 346 
 346 
---
Q 260+33 
T 293 
 293 
---
Q 412+408
T 820 
 820 
---
Q 830+7  
T 837 
 837 
---

--------------------------------------------------
Iteration 180
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.1318e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9998
Q 391+972
T 1363
 1363
---
Q 926+380
T 1306
 1306
---
Q 48+93  
T 141 
 141 
---
Q 19+338 
T 357 
 357 
---
Q 402+28 
T 430 
 430 
---
Q 62+129 
T 191 
 191 
---
Q 36+660 
T 696 
 696 
---
Q 857+82 
T 939 
 939 
---
Q 491+42 
T 533 
 533 
---
Q 196+824
T 1020
 1020
---

--------------------------------------------------
Iteration 181
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.9054e-04 - acc: 1.0000 - val_loss: 9.5128e-04 - val_acc: 0.9998
Q 389+206
T 595 
 595 
---
Q 471+4  
T 475 
 475 
---
Q 96+253 
T 349 
 349 
---
Q 545+63 
T 608 
 608 
---
Q 252+942
T 1194
 1194
---
Q 386+11 
T 397 
 397 
---
Q 137+975
T 1112
 1112
---
Q 279+10 
T 289 
 289 
---
Q 281+631
T 912 
 912 
---
Q 14+120 
T 134 
 134 
---

--------------------------------------------------
Iteration 182
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0367 - acc: 0.9900 - val_loss: 0.0038 - val_acc: 0.9991
Q 691+938
T 1629
 1629
---
Q 33+478 
T 511 
 511 
---
Q 96+114 
T 210 
 210 
---
Q 65+139 
T 204 
 204 
---
Q 84+294 
T 378 
 378 
---
Q 752+465
T 1217
 1217
---
Q 53+195 
T 248 
 248 
---
Q 115+87 
T 202 
 202 
---
Q 950+845
T 1795
 1795
---
Q 16+33  
T 49  
 49  
---

--------------------------------------------------
Iteration 183
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0025 - val_acc: 0.9993
Q 483+75 
T 558 
 558 
---
Q 18+631 
T 649 
 649 
---
Q 954+711
T 1665
 1665
---
Q 653+39 
T 692 
 692 
---
Q 384+171
T 555 
 555 
---
Q 29+96  
T 125 
 125 
---
Q 687+67 
T 754 
 754 
---
Q 470+160
T 630 
 630 
---
Q 645+647
T 1292
 1292
---
Q 4+111  
T 115 
 115 
---

--------------------------------------------------
Iteration 184
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 6.3926e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9997
Q 105+4  
T 109 
 109 
---
Q 737+40 
T 777 
 777 
---
Q 382+3  
T 385 
 385 
---
Q 352+37 
T 389 
 389 
---
Q 876+414
T 1290
 1290
---
Q 76+725 
T 801 
 801 
---
Q 13+1   
T 14  
 14  
---
Q 391+77 
T 468 
 468 
---
Q 8+526  
T 534 
 534 
---
Q 729+73 
T 802 
 802 
---

--------------------------------------------------
Iteration 185
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.8180e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 0.9998
Q 438+757
T 1195
 1195
---
Q 613+471
T 1084
 1084
---
Q 444+85 
T 529 
 529 
---
Q 56+171 
T 227 
 227 
---
Q 15+519 
T 534 
 534 
---
Q 535+540
T 1075
 1075
---
Q 771+0  
T 771 
 771 
---
Q 368+59 
T 427 
 427 
---
Q 756+6  
T 762 
 762 
---
Q 74+470 
T 544 
 544 
---

--------------------------------------------------
Iteration 186
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.1856e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997
Q 20+814 
T 834 
 834 
---
Q 45+64  
T 109 
 109 
---
Q 36+412 
T 448 
 448 
---
Q 931+98 
T 1029
 1029
---
Q 920+66 
T 986 
 986 
---
Q 53+190 
T 243 
 243 
---
Q 556+33 
T 589 
 589 
---
Q 30+736 
T 766 
 766 
---
Q 21+661 
T 682 
 682 
---
Q 439+42 
T 481 
 481 
---

--------------------------------------------------
Iteration 187
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.7468e-04 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 0.9998
Q 91+297 
T 388 
 388 
---
Q 4+217  
T 221 
 221 
---
Q 27+232 
T 259 
 259 
---
Q 365+2  
T 367 
 367 
---
Q 39+80  
T 119 
 119 
---
Q 712+578
T 1290
 1290
---
Q 67+63  
T 130 
 130 
---
Q 295+239
T 534 
 534 
---
Q 216+190
T 406 
 406 
---
Q 64+830 
T 894 
 894 
---

--------------------------------------------------
Iteration 188
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.4213e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 0.9998
Q 60+598 
T 658 
 658 
---
Q 662+247
T 909 
 909 
---
Q 0+867  
T 867 
 867 
---
Q 58+220 
T 278 
 278 
---
Q 70+292 
T 362 
 362 
---
Q 18+171 
T 189 
 189 
---
Q 937+926
T 1863
 1863
---
Q 87+621 
T 708 
 708 
---
Q 814+629
T 1443
 1443
---
Q 1+718  
T 719 
 719 
---

--------------------------------------------------
Iteration 189
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.1795e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 0.9998
Q 384+7  
T 391 
 391 
---
Q 2+749  
T 751 
 751 
---
Q 223+542
T 765 
 765 
---
Q 402+654
T 1056
 1056
---
Q 695+23 
T 718 
 718 
---
Q 47+946 
T 993 
 993 
---
Q 583+424
T 1007
 1007
---
Q 832+8  
T 840 
 840 
---
Q 585+6  
T 591 
 591 
---
Q 38+321 
T 359 
 359 
---

--------------------------------------------------
Iteration 190
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.9668e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9997
Q 452+8  
T 460 
 460 
---
Q 10+283 
T 293 
 293 
---
Q 898+908
T 1806
 1806
---
Q 338+77 
T 415 
 415 
---
Q 649+883
T 1532
 1532
---
Q 549+89 
T 638 
 638 
---
Q 844+55 
T 899 
 899 
---
Q 208+83 
T 291 
 291 
---
Q 275+817
T 1092
 1092
---
Q 381+656
T 1037
 1037
---

--------------------------------------------------
Iteration 191
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.7756e-04 - acc: 1.0000 - val_loss: 8.8384e-04 - val_acc: 0.9998
Q 705+258
T 963 
 963 
---
Q 628+21 
T 649 
 649 
---
Q 625+806
T 1431
 1431
---
Q 9+995  
T 1004
 1004
---
Q 93+87  
T 180 
 180 
---
Q 56+481 
T 537 
 537 
---
Q 139+9  
T 148 
 148 
---
Q 459+163
T 622 
 622 
---
Q 417+2  
T 419 
 419 
---
Q 946+6  
T 952 
 952 
---

--------------------------------------------------
Iteration 192
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.6181e-04 - acc: 1.0000 - val_loss: 9.2125e-04 - val_acc: 0.9997
Q 78+122 
T 200 
 200 
---
Q 95+328 
T 423 
 423 
---
Q 2+749  
T 751 
 751 
---
Q 143+195
T 338 
 338 
---
Q 907+98 
T 1005
 1005
---
Q 639+57 
T 696 
 696 
---
Q 339+10 
T 349 
 349 
---
Q 9+789  
T 798 
 798 
---
Q 35+902 
T 937 
 937 
---
Q 968+3  
T 971 
 971 
---

--------------------------------------------------
Iteration 193
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 1.7900e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 0.9995
Q 9+426  
T 435 
 435 
---
Q 67+788 
T 855 
 855 
---
Q 25+200 
T 225 
 225 
---
Q 509+2  
T 511 
 511 
---
Q 98+440 
T 538 
 538 
---
Q 241+97 
T 338 
 338 
---
Q 104+539
T 643 
 643 
---
Q 182+69 
T 251 
 251 
---
Q 42+842 
T 884 
 884 
---
Q 55+7   
T 62  
 62  
---

--------------------------------------------------
Iteration 194
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0308 - acc: 0.9915 - val_loss: 0.0032 - val_acc: 0.9991
Q 893+631
T 1524
 1524
---
Q 94+447 
T 541 
 541 
---
Q 803+818
T 1621
 1621
---
Q 514+0  
T 514 
 514 
---
Q 1+935  
T 936 
 936 
---
Q 674+15 
T 689 
 689 
---
Q 393+13 
T 406 
 406 
---
Q 35+438 
T 473 
 473 
---
Q 847+84 
T 931 
 931 
---
Q 345+87 
T 432 
 432 
---

--------------------------------------------------
Iteration 195
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0018 - val_acc: 0.9994
Q 874+94 
T 968 
 968 
---
Q 373+176
T 549 
 549 
---
Q 93+308 
T 401 
 401 
---
Q 50+86  
T 136 
 136 
---
Q 97+847 
T 944 
 944 
---
Q 48+517 
T 565 
 565 
---
Q 355+565
T 920 
 920 
---
Q 596+886
T 1482
 1482
---
Q 996+443
T 1439
 1439
---
Q 42+178 
T 220 
 220 
---

--------------------------------------------------
Iteration 196
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 3.9288e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 0.9997
Q 558+461
T 1019
 1019
---
Q 376+643
T 1019
 1019
---
Q 47+896 
T 943 
 943 
---
Q 180+285
T 465 
 465 
---
Q 9+93   
T 102 
 102 
---
Q 78+558 
T 636 
 636 
---
Q 923+400
T 1323
 1323
---
Q 433+172
T 605 
 605 
---
Q 24+839 
T 863 
 863 
---
Q 681+549
T 1230
 1230
---

--------------------------------------------------
Iteration 197
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.9619e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9998
Q 304+1  
T 305 
 305 
---
Q 381+229
T 610 
 610 
---
Q 86+468 
T 554 
 554 
---
Q 713+8  
T 721 
 721 
---
Q 564+60 
T 624 
 624 
---
Q 7+188  
T 195 
 195 
---
Q 235+39 
T 274 
 274 
---
Q 397+0  
T 397 
 397 
---
Q 401+825
T 1226
 1226
---
Q 27+441 
T 468 
 468 
---

--------------------------------------------------
Iteration 198
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.5089e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 0.9998
Q 99+902 
T 1001
 1001
---
Q 43+142 
T 185 
 185 
---
Q 38+17  
T 55  
 55  
---
Q 816+81 
T 897 
 897 
---
Q 166+896
T 1062
 1062
---
Q 861+2  
T 863 
 863 
---
Q 837+945
T 1782
 1782
---
Q 373+3  
T 376 
 376 
---
Q 16+441 
T 457 
 457 
---
Q 42+68  
T 110 
 110 
---

--------------------------------------------------
Iteration 199
Train on 45000 samples, validate on 5000 samples
Epoch 1/1
45000/45000 [==============================] - 8s - loss: 2.2072e-04 - acc: 1.0000 - val_loss: 0.0010 - val_acc: 0.9998
Q 74+954 
T 1028
 1028
---
Q 79+939 
T 1018
 1018
---
Q 3+911  
T 914 
 914 
---
Q 841+375
T 1216
 1216
---
Q 3+479  
T 482 
 482 
---
Q 319+48 
T 367 
 367 
---
Q 758+64 
T 822 
 822 
---
Q 94+63  
T 157 
 157 
---
Q 339+3  
T 342 
 342 
---
Q 90+95  
T 185 
 185 
---
