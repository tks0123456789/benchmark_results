python mnist_mlp.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
60000 train samples
10000 test samples
____________________________________________________________________________________________________
Layer (type)                       Output Shape        Param #     Connected to                     
====================================================================================================
dense_1 (Dense)                    (None, 512)         401920      dense_input_1[0][0]              
____________________________________________________________________________________________________
activation_1 (Activation)          (None, 512)         0           dense_1[0][0]                    
____________________________________________________________________________________________________
dropout_1 (Dropout)                (None, 512)         0           activation_1[0][0]               
____________________________________________________________________________________________________
dense_2 (Dense)                    (None, 512)         262656      dropout_1[0][0]                  
____________________________________________________________________________________________________
activation_2 (Activation)          (None, 512)         0           dense_2[0][0]                    
____________________________________________________________________________________________________
dropout_2 (Dropout)                (None, 512)         0           activation_2[0][0]               
____________________________________________________________________________________________________
dense_3 (Dense)                    (None, 10)          5130        dropout_2[0][0]                  
____________________________________________________________________________________________________
activation_3 (Activation)          (None, 10)          0           dense_3[0][0]                    
====================================================================================================
Total params: 669706
____________________________________________________________________________________________________
Train on 60000 samples, validate on 10000 samples
Epoch 1/20
60000/60000 [==============================] - 2s - loss: 0.2752 - acc: 0.9166 - val_loss: 0.1164 - val_acc: 0.9643
Epoch 2/20
60000/60000 [==============================] - 2s - loss: 0.1136 - acc: 0.9655 - val_loss: 0.0837 - val_acc: 0.9754
Epoch 3/20
60000/60000 [==============================] - 2s - loss: 0.0809 - acc: 0.9747 - val_loss: 0.0699 - val_acc: 0.9779
Epoch 4/20
60000/60000 [==============================] - 2s - loss: 0.0606 - acc: 0.9808 - val_loss: 0.0718 - val_acc: 0.9765
Epoch 5/20
60000/60000 [==============================] - 2s - loss: 0.0503 - acc: 0.9838 - val_loss: 0.0652 - val_acc: 0.9787
Epoch 6/20
60000/60000 [==============================] - 2s - loss: 0.0425 - acc: 0.9866 - val_loss: 0.0535 - val_acc: 0.9835
Epoch 7/20
60000/60000 [==============================] - 2s - loss: 0.0344 - acc: 0.9889 - val_loss: 0.0609 - val_acc: 0.9814
Epoch 8/20
60000/60000 [==============================] - 2s - loss: 0.0293 - acc: 0.9901 - val_loss: 0.0637 - val_acc: 0.9830
Epoch 9/20
60000/60000 [==============================] - 2s - loss: 0.0249 - acc: 0.9918 - val_loss: 0.0584 - val_acc: 0.9845
Epoch 10/20
60000/60000 [==============================] - 2s - loss: 0.0227 - acc: 0.9929 - val_loss: 0.0609 - val_acc: 0.9830
Epoch 11/20
60000/60000 [==============================] - 2s - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0594 - val_acc: 0.9836
Epoch 12/20
60000/60000 [==============================] - 2s - loss: 0.0175 - acc: 0.9942 - val_loss: 0.0634 - val_acc: 0.9847
Epoch 13/20
60000/60000 [==============================] - 2s - loss: 0.0160 - acc: 0.9950 - val_loss: 0.0616 - val_acc: 0.9847
Epoch 14/20
60000/60000 [==============================] - 2s - loss: 0.0141 - acc: 0.9953 - val_loss: 0.0652 - val_acc: 0.9845
Epoch 15/20
60000/60000 [==============================] - 2s - loss: 0.0125 - acc: 0.9961 - val_loss: 0.0670 - val_acc: 0.9844
Epoch 16/20
60000/60000 [==============================] - 2s - loss: 0.0119 - acc: 0.9961 - val_loss: 0.0824 - val_acc: 0.9822
Epoch 17/20
60000/60000 [==============================] - 2s - loss: 0.0107 - acc: 0.9964 - val_loss: 0.0630 - val_acc: 0.9857
Epoch 18/20
60000/60000 [==============================] - 2s - loss: 0.0089 - acc: 0.9971 - val_loss: 0.0671 - val_acc: 0.9849
Epoch 19/20
60000/60000 [==============================] - 2s - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0703 - val_acc: 0.9844
Epoch 20/20
60000/60000 [==============================] - 2s - loss: 0.0087 - acc: 0.9972 - val_loss: 0.0644 - val_acc: 0.9844
Test score: 0.0643513638924
Test accuracy: 0.9844


python mnist_cnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/12
60000/60000 [==============================] - 26s - loss: 0.2572 - acc: 0.9216 - val_loss: 0.0571 - val_acc: 0.9825
Epoch 2/12
60000/60000 [==============================] - 26s - loss: 0.0951 - acc: 0.9711 - val_loss: 0.0399 - val_acc: 0.9864
Epoch 3/12
60000/60000 [==============================] - 26s - loss: 0.0713 - acc: 0.9786 - val_loss: 0.0363 - val_acc: 0.9884
Epoch 4/12
60000/60000 [==============================] - 26s - loss: 0.0578 - acc: 0.9829 - val_loss: 0.0307 - val_acc: 0.9890
Epoch 5/12
60000/60000 [==============================] - 26s - loss: 0.0488 - acc: 0.9848 - val_loss: 0.0296 - val_acc: 0.9901
Epoch 6/12
60000/60000 [==============================] - 26s - loss: 0.0416 - acc: 0.9867 - val_loss: 0.0304 - val_acc: 0.9907
Epoch 7/12
60000/60000 [==============================] - 26s - loss: 0.0381 - acc: 0.9880 - val_loss: 0.0317 - val_acc: 0.9892
Epoch 8/12
60000/60000 [==============================] - 26s - loss: 0.0363 - acc: 0.9883 - val_loss: 0.0284 - val_acc: 0.9917
Epoch 9/12
60000/60000 [==============================] - 26s - loss: 0.0312 - acc: 0.9907 - val_loss: 0.0270 - val_acc: 0.9919
Epoch 10/12
60000/60000 [==============================] - 26s - loss: 0.0296 - acc: 0.9907 - val_loss: 0.0280 - val_acc: 0.9922
Epoch 11/12
60000/60000 [==============================] - 26s - loss: 0.0276 - acc: 0.9909 - val_loss: 0.0277 - val_acc: 0.9917
Epoch 12/12
60000/60000 [==============================] - 26s - loss: 0.0252 - acc: 0.9919 - val_loss: 0.0282 - val_acc: 0.9920
Test score: 0.0282181292013
Test accuracy: 0.992


python mnist_sklearn_wrapper.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.6127 - acc: 0.7937     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.3219 - acc: 0.8992     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2608 - acc: 0.9189     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.5918 - acc: 0.7985     
Epoch 2/3
40000/40000 [==============================] - 10s - loss: 0.3134 - acc: 0.9005    
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2680 - acc: 0.9175     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.5986 - acc: 0.8000     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.3143 - acc: 0.8985     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2551 - acc: 0.9210     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 10s - loss: 0.5079 - acc: 0.8317    
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2924 - acc: 0.9073     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2523 - acc: 0.9194     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2363 - acc: 0.9264     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2175 - acc: 0.9322     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2058 - acc: 0.9362     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.5848 - acc: 0.8031     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.3129 - acc: 0.8999     
Epoch 3/6
40000/40000 [==============================] - 10s - loss: 0.2596 - acc: 0.9197    
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2436 - acc: 0.9256     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2330 - acc: 0.9287     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2298 - acc: 0.9301     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 10s - loss: 0.4908 - acc: 0.8408    
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2745 - acc: 0.9161     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2334 - acc: 0.9295     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2164 - acc: 0.9348     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2091 - acc: 0.9387     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1998 - acc: 0.9403     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3452 - acc: 0.8931     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1583 - acc: 0.9535     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1333 - acc: 0.9614     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3824 - acc: 0.8812     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1816 - acc: 0.9466     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1409 - acc: 0.9586     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3366 - acc: 0.8945     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1656 - acc: 0.9506     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1372 - acc: 0.9590     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3563 - acc: 0.8890     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1720 - acc: 0.9497     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1422 - acc: 0.9585     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1268 - acc: 0.9645     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1187 - acc: 0.9657     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1088 - acc: 0.9683     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3489 - acc: 0.8937     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1736 - acc: 0.9505     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1447 - acc: 0.9577     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1317 - acc: 0.9615     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1204 - acc: 0.9660     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1091 - acc: 0.9692     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3427 - acc: 0.8950     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1659 - acc: 0.9525     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1379 - acc: 0.9602     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1212 - acc: 0.9645     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1158 - acc: 0.9667     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1071 - acc: 0.9694     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.4662 - acc: 0.8535     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.2737 - acc: 0.9175     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2354 - acc: 0.9302     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.4313 - acc: 0.8608     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.2572 - acc: 0.9190     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2317 - acc: 0.9276     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.5119 - acc: 0.8339     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.2912 - acc: 0.9084     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.2502 - acc: 0.9243     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.4504 - acc: 0.8545     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2578 - acc: 0.9206     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2313 - acc: 0.9274     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2150 - acc: 0.9318     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2103 - acc: 0.9337     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2059 - acc: 0.9362     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.4825 - acc: 0.8444     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2730 - acc: 0.9168     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2408 - acc: 0.9288     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2135 - acc: 0.9340     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2065 - acc: 0.9378     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1996 - acc: 0.9395     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.4800 - acc: 0.8467     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.2735 - acc: 0.9144     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.2472 - acc: 0.9216     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.2267 - acc: 0.9299     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.2190 - acc: 0.9324     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.2094 - acc: 0.9362     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3215 - acc: 0.9029     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1662 - acc: 0.9520     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1396 - acc: 0.9601     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3494 - acc: 0.8946     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1709 - acc: 0.9509     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1480 - acc: 0.9578     
20000/20000 [==============================] - 1s     
Epoch 1/3
40000/40000 [==============================] - 9s - loss: 0.3360 - acc: 0.8978     
Epoch 2/3
40000/40000 [==============================] - 9s - loss: 0.1628 - acc: 0.9530     
Epoch 3/3
40000/40000 [==============================] - 9s - loss: 0.1436 - acc: 0.9600     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3252 - acc: 0.9015     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1671 - acc: 0.9515     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1406 - acc: 0.9598     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1290 - acc: 0.9632     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1210 - acc: 0.9653     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1095 - acc: 0.9685     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3284 - acc: 0.9001     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1702 - acc: 0.9526     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1399 - acc: 0.9612     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1287 - acc: 0.9638     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1284 - acc: 0.9650     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1158 - acc: 0.9670     
20000/20000 [==============================] - 1s     
Epoch 1/6
40000/40000 [==============================] - 9s - loss: 0.3295 - acc: 0.9007     
Epoch 2/6
40000/40000 [==============================] - 9s - loss: 0.1705 - acc: 0.9512     
Epoch 3/6
40000/40000 [==============================] - 9s - loss: 0.1480 - acc: 0.9568     
Epoch 4/6
40000/40000 [==============================] - 9s - loss: 0.1321 - acc: 0.9626     
Epoch 5/6
40000/40000 [==============================] - 9s - loss: 0.1219 - acc: 0.9654     
Epoch 6/6
40000/40000 [==============================] - 9s - loss: 0.1185 - acc: 0.9667     
20000/20000 [==============================] - 1s     
Epoch 1/6
60000/60000 [==============================] - 14s - loss: 0.3071 - acc: 0.9065    
Epoch 2/6
60000/60000 [==============================] - 14s - loss: 0.1478 - acc: 0.9567    
Epoch 3/6
60000/60000 [==============================] - 14s - loss: 0.1229 - acc: 0.9650    
Epoch 4/6
60000/60000 [==============================] - 14s - loss: 0.1137 - acc: 0.9675    
Epoch 5/6
60000/60000 [==============================] - 14s - loss: 0.1074 - acc: 0.9697    
Epoch 6/6
60000/60000 [==============================] - 14s - loss: 0.1015 - acc: 0.9708    
The parameters of the best model are: 
{'dense_layer_sizes': [64], 'nb_conv': 3, 'nb_pool': 2, 'nb_epoch': 6, 'nb_filters': 8}
10000/10000 [==============================] - 0s     
loss :  0.0453512147586
acc :  0.986


python mnist_siamese_graph.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Train on 108400 samples, validate on 17820 samples
Epoch 1/20
108400/108400 [==============================] - 4s - loss: 0.1068 - val_loss: 0.0506
Epoch 2/20
108400/108400 [==============================] - 4s - loss: 0.0510 - val_loss: 0.0369
Epoch 3/20
108400/108400 [==============================] - 4s - loss: 0.0369 - val_loss: 0.0310
Epoch 4/20
108400/108400 [==============================] - 4s - loss: 0.0301 - val_loss: 0.0271
Epoch 5/20
108400/108400 [==============================] - 4s - loss: 0.0256 - val_loss: 0.0268
Epoch 6/20
108400/108400 [==============================] - 4s - loss: 0.0230 - val_loss: 0.0257
Epoch 7/20
108400/108400 [==============================] - 4s - loss: 0.0208 - val_loss: 0.0252
Epoch 8/20
108400/108400 [==============================] - 4s - loss: 0.0190 - val_loss: 0.0237
Epoch 9/20
108400/108400 [==============================] - 4s - loss: 0.0175 - val_loss: 0.0240
Epoch 10/20
108400/108400 [==============================] - 4s - loss: 0.0165 - val_loss: 0.0246
Epoch 11/20
108400/108400 [==============================] - 4s - loss: 0.0157 - val_loss: 0.0245
Epoch 12/20
108400/108400 [==============================] - 4s - loss: 0.0147 - val_loss: 0.0240
Epoch 13/20
108400/108400 [==============================] - 4s - loss: 0.0138 - val_loss: 0.0239
Epoch 14/20
108400/108400 [==============================] - 4s - loss: 0.0133 - val_loss: 0.0253
Epoch 15/20
108400/108400 [==============================] - 4s - loss: 0.0124 - val_loss: 0.0246
Epoch 16/20
108400/108400 [==============================] - 4s - loss: 0.0117 - val_loss: 0.0245
Epoch 17/20
108400/108400 [==============================] - 4s - loss: 0.0115 - val_loss: 0.0242
Epoch 18/20
108400/108400 [==============================] - 4s - loss: 0.0111 - val_loss: 0.0247
Epoch 19/20
108400/108400 [==============================] - 4s - loss: 0.0108 - val_loss: 0.0258
Epoch 20/20
108400/108400 [==============================] - 4s - loss: 0.0104 - val_loss: 0.0251
* Accuracy on training set: 99.93%
* Accuracy on test set: 99.40%


python imdb_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
Downloading data from https://s3.amazonaws.com/text-datasets/imdb.pkl
33218560/33213513 [==============================] - 52s    
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 80)
X_test shape: (5000, 80)
Build model...
Train...
(20000, 80)
(20000,)
Train on 20000 samples, validate on 5000 samples
Epoch 1/15
20000/20000 [==============================] - 49s - loss: 0.5870 - acc: 0.6847 - val_loss: 0.4479 - val_acc: 0.7950
Epoch 2/15
20000/20000 [==============================] - 49s - loss: 0.4335 - acc: 0.8075 - val_loss: 0.4030 - val_acc: 0.8196
Epoch 3/15
20000/20000 [==============================] - 49s - loss: 0.3523 - acc: 0.8526 - val_loss: 0.3983 - val_acc: 0.8200
Epoch 4/15
20000/20000 [==============================] - 49s - loss: 0.2849 - acc: 0.8842 - val_loss: 0.3985 - val_acc: 0.8272
Epoch 5/15
20000/20000 [==============================] - 49s - loss: 0.2434 - acc: 0.9039 - val_loss: 0.4642 - val_acc: 0.8206
Epoch 6/15
20000/20000 [==============================] - 49s - loss: 0.2057 - acc: 0.9181 - val_loss: 0.4650 - val_acc: 0.8264
Epoch 7/15
20000/20000 [==============================] - 49s - loss: 0.1764 - acc: 0.9334 - val_loss: 0.4680 - val_acc: 0.8136
Epoch 8/15
20000/20000 [==============================] - 49s - loss: 0.1483 - acc: 0.9427 - val_loss: 0.5340 - val_acc: 0.8202
Epoch 9/15
20000/20000 [==============================] - 49s - loss: 0.1352 - acc: 0.9474 - val_loss: 0.4883 - val_acc: 0.8132
Epoch 10/15
20000/20000 [==============================] - 49s - loss: 0.1139 - acc: 0.9580 - val_loss: 0.5827 - val_acc: 0.8104
Epoch 11/15
20000/20000 [==============================] - 49s - loss: 0.1011 - acc: 0.9632 - val_loss: 0.5834 - val_acc: 0.8118
Epoch 12/15
20000/20000 [==============================] - 49s - loss: 0.0910 - acc: 0.9661 - val_loss: 0.7059 - val_acc: 0.8088
Epoch 13/15
20000/20000 [==============================] - 49s - loss: 0.0857 - acc: 0.9677 - val_loss: 0.6236 - val_acc: 0.8120
Epoch 14/15
20000/20000 [==============================] - 49s - loss: 0.0756 - acc: 0.9724 - val_loss: 0.7265 - val_acc: 0.8100
Epoch 15/15
20000/20000 [==============================] - 49s - loss: 0.0738 - acc: 0.9728 - val_loss: 0.6517 - val_acc: 0.8090
5000/5000 [==============================] - 4s     
Test score: 0.651677638912
Test accuracy: 0.809


python imdb_cnn.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 400)
X_test shape: (5000, 400)
Build model...
Train on 20000 samples, validate on 5000 samples
Epoch 1/2
20000/20000 [==============================] - 15s - loss: 0.4581 - acc: 0.7640 - val_loss: 0.3172 - val_acc: 0.8656
Epoch 2/2
20000/20000 [==============================] - 15s - loss: 0.2944 - acc: 0.8758 - val_loss: 0.2811 - val_acc: 0.8826


python imdb_cnn_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 100)
X_test shape: (5000, 100)
Build model...
Train...
Train on 20000 samples, validate on 5000 samples
Epoch 1/2
20000/20000 [==============================] - 34s - loss: 0.4312 - acc: 0.7894 - val_loss: 0.3465 - val_acc: 0.8448
Epoch 2/2
20000/20000 [==============================] - 34s - loss: 0.2265 - acc: 0.9110 - val_loss: 0.3540 - val_acc: 0.8490
5000/5000 [==============================] - 3s     
Test score: 0.354021408424
Test accuracy: 0.848999991179


python reuters_mlp.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
Downloading data from https://s3.amazonaws.com/text-datasets/reuters.pkl
9216000/9211982 [==============================] - 17s    
8982 train sequences
2246 test sequences
46 classes
Vectorizing sequence data...
X_train shape: (8982, 1000)
X_test shape: (2246, 1000)
Convert class vector to binary class matrix (for use with categorical_crossentropy)
Y_train shape: (8982, 46)
Y_test shape: (2246, 46)
Building model...
Train on 8083 samples, validate on 899 samples
Epoch 1/5
8083/8083 [==============================] - 0s - loss: 1.4164 - acc: 0.6851 - val_loss: 1.0786 - val_acc: 0.7631
Epoch 2/5
8083/8083 [==============================] - 0s - loss: 0.7705 - acc: 0.8185 - val_loss: 0.9107 - val_acc: 0.7987
Epoch 3/5
8083/8083 [==============================] - 0s - loss: 0.5516 - acc: 0.8661 - val_loss: 0.8658 - val_acc: 0.8009
Epoch 4/5
8083/8083 [==============================] - 0s - loss: 0.4095 - acc: 0.8992 - val_loss: 0.8906 - val_acc: 0.8098
Epoch 5/5
8083/8083 [==============================] - 0s - loss: 0.3282 - acc: 0.9164 - val_loss: 0.8824 - val_acc: 0.8131
2246/2246 [==============================] - 0s     
Test score: 0.875797399748
Test accuracy: 0.793410507569


python antirectifier.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
60000 train samples
10000 test samples
Train on 60000 samples, validate on 10000 samples
Epoch 1/40
60000/60000 [==============================] - 2s - loss: 0.8016 - acc: 0.8857 - val_loss: 0.2561 - val_acc: 0.9458
Epoch 2/40
60000/60000 [==============================] - 2s - loss: 0.1942 - acc: 0.9561 - val_loss: 0.1243 - val_acc: 0.9692
Epoch 3/40
60000/60000 [==============================] - 2s - loss: 0.1185 - acc: 0.9715 - val_loss: 0.0957 - val_acc: 0.9734
Epoch 4/40
60000/60000 [==============================] - 2s - loss: 0.0874 - acc: 0.9783 - val_loss: 0.0797 - val_acc: 0.9770
Epoch 5/40
60000/60000 [==============================] - 2s - loss: 0.0704 - acc: 0.9824 - val_loss: 0.0808 - val_acc: 0.9772
Epoch 6/40
60000/60000 [==============================] - 2s - loss: 0.0596 - acc: 0.9852 - val_loss: 0.0671 - val_acc: 0.9806
Epoch 7/40
60000/60000 [==============================] - 2s - loss: 0.0494 - acc: 0.9881 - val_loss: 0.0642 - val_acc: 0.9804
Epoch 8/40
60000/60000 [==============================] - 2s - loss: 0.0431 - acc: 0.9897 - val_loss: 0.0689 - val_acc: 0.9803
Epoch 9/40
60000/60000 [==============================] - 2s - loss: 0.0369 - acc: 0.9912 - val_loss: 0.0617 - val_acc: 0.9818
Epoch 10/40
60000/60000 [==============================] - 2s - loss: 0.0329 - acc: 0.9922 - val_loss: 0.0603 - val_acc: 0.9815
Epoch 11/40
60000/60000 [==============================] - 2s - loss: 0.0283 - acc: 0.9938 - val_loss: 0.0613 - val_acc: 0.9809
Epoch 12/40
60000/60000 [==============================] - 2s - loss: 0.0256 - acc: 0.9944 - val_loss: 0.0598 - val_acc: 0.9822
Epoch 13/40
60000/60000 [==============================] - 2s - loss: 0.0242 - acc: 0.9943 - val_loss: 0.0560 - val_acc: 0.9841
Epoch 14/40
60000/60000 [==============================] - 2s - loss: 0.0205 - acc: 0.9959 - val_loss: 0.0599 - val_acc: 0.9822
Epoch 15/40
60000/60000 [==============================] - 2s - loss: 0.0185 - acc: 0.9964 - val_loss: 0.0575 - val_acc: 0.9824
Epoch 16/40
60000/60000 [==============================] - 2s - loss: 0.0179 - acc: 0.9963 - val_loss: 0.0564 - val_acc: 0.9823
Epoch 17/40
60000/60000 [==============================] - 2s - loss: 0.0161 - acc: 0.9966 - val_loss: 0.0547 - val_acc: 0.9835
Epoch 18/40
60000/60000 [==============================] - 2s - loss: 0.0149 - acc: 0.9973 - val_loss: 0.0596 - val_acc: 0.9823
Epoch 19/40
60000/60000 [==============================] - 2s - loss: 0.0132 - acc: 0.9975 - val_loss: 0.0538 - val_acc: 0.9839
Epoch 20/40
60000/60000 [==============================] - 2s - loss: 0.0128 - acc: 0.9977 - val_loss: 0.0567 - val_acc: 0.9836
Epoch 21/40
60000/60000 [==============================] - 2s - loss: 0.0122 - acc: 0.9976 - val_loss: 0.0551 - val_acc: 0.9837
Epoch 22/40
60000/60000 [==============================] - 2s - loss: 0.0110 - acc: 0.9981 - val_loss: 0.0557 - val_acc: 0.9826
Epoch 23/40
60000/60000 [==============================] - 2s - loss: 0.0101 - acc: 0.9982 - val_loss: 0.0543 - val_acc: 0.9843
Epoch 24/40
60000/60000 [==============================] - 2s - loss: 0.0093 - acc: 0.9985 - val_loss: 0.0570 - val_acc: 0.9833
Epoch 25/40
60000/60000 [==============================] - 2s - loss: 0.0086 - acc: 0.9985 - val_loss: 0.0621 - val_acc: 0.9811
Epoch 26/40
60000/60000 [==============================] - 2s - loss: 0.0086 - acc: 0.9986 - val_loss: 0.0580 - val_acc: 0.9831
Epoch 27/40
60000/60000 [==============================] - 2s - loss: 0.0083 - acc: 0.9986 - val_loss: 0.0589 - val_acc: 0.9831
Epoch 28/40
60000/60000 [==============================] - 2s - loss: 0.0076 - acc: 0.9989 - val_loss: 0.0595 - val_acc: 0.9818
Epoch 29/40
60000/60000 [==============================] - 2s - loss: 0.0071 - acc: 0.9990 - val_loss: 0.0523 - val_acc: 0.9838
Epoch 30/40
60000/60000 [==============================] - 2s - loss: 0.0065 - acc: 0.9991 - val_loss: 0.0563 - val_acc: 0.9839
Epoch 31/40
60000/60000 [==============================] - 2s - loss: 0.0065 - acc: 0.9992 - val_loss: 0.0537 - val_acc: 0.9853
Epoch 32/40
60000/60000 [==============================] - 2s - loss: 0.0057 - acc: 0.9992 - val_loss: 0.0569 - val_acc: 0.9841
Epoch 33/40
60000/60000 [==============================] - 2s - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0564 - val_acc: 0.9835
Epoch 34/40
60000/60000 [==============================] - 2s - loss: 0.0054 - acc: 0.9992 - val_loss: 0.0530 - val_acc: 0.9844
Epoch 35/40
60000/60000 [==============================] - 2s - loss: 0.0057 - acc: 0.9991 - val_loss: 0.0552 - val_acc: 0.9840
Epoch 36/40
60000/60000 [==============================] - 2s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0549 - val_acc: 0.9837
Epoch 37/40
60000/60000 [==============================] - 2s - loss: 0.0047 - acc: 0.9995 - val_loss: 0.0545 - val_acc: 0.9845
Epoch 38/40
60000/60000 [==============================] - 2s - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0538 - val_acc: 0.9846
Epoch 39/40
60000/60000 [==============================] - 2s - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0541 - val_acc: 0.9848
Epoch 40/40
60000/60000 [==============================] - 2s - loss: 0.0045 - acc: 0.9995 - val_loss: 0.0550 - val_acc: 0.9848


python imdb_bidirectional_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Loading data...
20000 train sequences
5000 test sequences
Pad sequences (samples x time)
X_train shape: (20000, 100)
X_test shape: (5000, 100)
Train...
Train on 20000 samples, validate on 5000 samples
Epoch 1/4
20000/20000 [==============================] - 89s - loss: 0.4595 - acc: 0.7763 - val_loss: 0.3695 - val_acc: 0.8282
Epoch 2/4
20000/20000 [==============================] - 90s - loss: 0.2459 - acc: 0.9023 - val_loss: 0.3844 - val_acc: 0.8362
Epoch 3/4
20000/20000 [==============================] - 90s - loss: 0.1291 - acc: 0.9539 - val_loss: 0.4482 - val_acc: 0.8210
Epoch 4/4
20000/20000 [==============================] - 90s - loss: 0.0540 - acc: 0.9825 - val_loss: 0.6642 - val_acc: 0.8314


python cifar10_cnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
X_train shape: (50000, 3, 32, 32)
50000 train samples
10000 test samples
Using real-time data augmentation.
Epoch 1/200
50000/50000 [==============================] - 78s - loss: 1.7040 - acc: 0.3689 - val_loss: 1.2726 - val_acc: 0.5381
Epoch 2/200
50000/50000 [==============================] - 76s - loss: 1.3625 - acc: 0.5064 - val_loss: 1.1567 - val_acc: 0.5847
Epoch 3/200
50000/50000 [==============================] - 76s - loss: 1.2196 - acc: 0.5633 - val_loss: 1.1163 - val_acc: 0.5981
Epoch 4/200
50000/50000 [==============================] - 76s - loss: 1.1302 - acc: 0.5994 - val_loss: 0.8949 - val_acc: 0.6824
Epoch 5/200
50000/50000 [==============================] - 76s - loss: 1.0609 - acc: 0.6241 - val_loss: 0.8628 - val_acc: 0.6985
Epoch 6/200
50000/50000 [==============================] - 76s - loss: 1.0165 - acc: 0.6419 - val_loss: 0.7944 - val_acc: 0.7250
Epoch 7/200
50000/50000 [==============================] - 76s - loss: 0.9857 - acc: 0.6526 - val_loss: 0.8412 - val_acc: 0.7054
Epoch 8/200
50000/50000 [==============================] - 76s - loss: 0.9624 - acc: 0.6623 - val_loss: 0.7865 - val_acc: 0.7244
Epoch 9/200
50000/50000 [==============================] - 76s - loss: 0.9432 - acc: 0.6711 - val_loss: 0.7452 - val_acc: 0.7424
Epoch 10/200
50000/50000 [==============================] - 76s - loss: 0.9267 - acc: 0.6754 - val_loss: 0.7334 - val_acc: 0.7463
Epoch 11/200
50000/50000 [==============================] - 76s - loss: 0.9153 - acc: 0.6809 - val_loss: 0.7626 - val_acc: 0.7352
Epoch 12/200
50000/50000 [==============================] - 76s - loss: 0.9031 - acc: 0.6848 - val_loss: 0.7727 - val_acc: 0.7362
Epoch 13/200
50000/50000 [==============================] - 76s - loss: 0.8954 - acc: 0.6877 - val_loss: 0.7433 - val_acc: 0.7402
Epoch 14/200
50000/50000 [==============================] - 76s - loss: 0.8818 - acc: 0.6941 - val_loss: 0.7151 - val_acc: 0.7534
Epoch 15/200
50000/50000 [==============================] - 76s - loss: 0.8756 - acc: 0.6943 - val_loss: 0.7009 - val_acc: 0.7540
Epoch 16/200
50000/50000 [==============================] - 76s - loss: 0.8755 - acc: 0.6944 - val_loss: 0.7202 - val_acc: 0.7495
Epoch 17/200
50000/50000 [==============================] - 76s - loss: 0.8717 - acc: 0.6968 - val_loss: 0.6794 - val_acc: 0.7654
Epoch 18/200
50000/50000 [==============================] - 76s - loss: 0.8651 - acc: 0.7011 - val_loss: 0.7028 - val_acc: 0.7580
Epoch 19/200
50000/50000 [==============================] - 76s - loss: 0.8603 - acc: 0.7026 - val_loss: 0.7396 - val_acc: 0.7426
Epoch 20/200
50000/50000 [==============================] - 76s - loss: 0.8523 - acc: 0.7047 - val_loss: 0.6953 - val_acc: 0.7598
Epoch 21/200
50000/50000 [==============================] - 76s - loss: 0.8490 - acc: 0.7059 - val_loss: 0.6797 - val_acc: 0.7635
Epoch 22/200
50000/50000 [==============================] - 76s - loss: 0.8448 - acc: 0.7065 - val_loss: 0.6894 - val_acc: 0.7648
Epoch 23/200
50000/50000 [==============================] - 76s - loss: 0.8373 - acc: 0.7124 - val_loss: 0.6752 - val_acc: 0.7647
Epoch 24/200
50000/50000 [==============================] - 76s - loss: 0.8451 - acc: 0.7092 - val_loss: 0.6945 - val_acc: 0.7605
Epoch 25/200
50000/50000 [==============================] - 76s - loss: 0.8335 - acc: 0.7106 - val_loss: 0.7181 - val_acc: 0.7528
Epoch 26/200
50000/50000 [==============================] - 76s - loss: 0.8359 - acc: 0.7131 - val_loss: 0.6745 - val_acc: 0.7624
Epoch 27/200
50000/50000 [==============================] - 76s - loss: 0.8404 - acc: 0.7092 - val_loss: 0.7088 - val_acc: 0.7553
Epoch 28/200
50000/50000 [==============================] - 76s - loss: 0.8318 - acc: 0.7095 - val_loss: 0.6572 - val_acc: 0.7731
Epoch 29/200
50000/50000 [==============================] - 76s - loss: 0.8210 - acc: 0.7189 - val_loss: 0.7459 - val_acc: 0.7423
Epoch 30/200
50000/50000 [==============================] - 76s - loss: 0.8249 - acc: 0.7167 - val_loss: 0.6984 - val_acc: 0.7639
Epoch 31/200
50000/50000 [==============================] - 76s - loss: 0.8311 - acc: 0.7136 - val_loss: 0.6745 - val_acc: 0.7661
Epoch 32/200
50000/50000 [==============================] - 76s - loss: 0.8247 - acc: 0.7146 - val_loss: 0.7449 - val_acc: 0.7486
Epoch 33/200
50000/50000 [==============================] - 76s - loss: 0.8186 - acc: 0.7171 - val_loss: 0.6705 - val_acc: 0.7727
Epoch 34/200
50000/50000 [==============================] - 76s - loss: 0.8217 - acc: 0.7171 - val_loss: 0.7189 - val_acc: 0.7553
Epoch 35/200
50000/50000 [==============================] - 76s - loss: 0.8236 - acc: 0.7178 - val_loss: 0.6611 - val_acc: 0.7778
Epoch 36/200
50000/50000 [==============================] - 76s - loss: 0.8132 - acc: 0.7218 - val_loss: 0.6329 - val_acc: 0.7902
Epoch 37/200
50000/50000 [==============================] - 76s - loss: 0.8106 - acc: 0.7223 - val_loss: 0.7402 - val_acc: 0.7477
Epoch 38/200
50000/50000 [==============================] - 76s - loss: 0.8054 - acc: 0.7251 - val_loss: 0.6639 - val_acc: 0.7755
Epoch 39/200
50000/50000 [==============================] - 76s - loss: 0.8079 - acc: 0.7231 - val_loss: 0.6402 - val_acc: 0.7812
Epoch 40/200
50000/50000 [==============================] - 76s - loss: 0.8063 - acc: 0.7243 - val_loss: 0.6592 - val_acc: 0.7753
Epoch 41/200
50000/50000 [==============================] - 76s - loss: 0.8000 - acc: 0.7258 - val_loss: 0.6294 - val_acc: 0.7849
Epoch 42/200
50000/50000 [==============================] - 76s - loss: 0.7969 - acc: 0.7268 - val_loss: 0.6941 - val_acc: 0.7680
Epoch 43/200
50000/50000 [==============================] - 76s - loss: 0.7951 - acc: 0.7266 - val_loss: 0.6367 - val_acc: 0.7832
Epoch 44/200
50000/50000 [==============================] - 76s - loss: 0.7996 - acc: 0.7284 - val_loss: 0.6169 - val_acc: 0.7920
Epoch 45/200
50000/50000 [==============================] - 76s - loss: 0.7871 - acc: 0.7311 - val_loss: 0.6402 - val_acc: 0.7825
Epoch 46/200
50000/50000 [==============================] - 76s - loss: 0.8032 - acc: 0.7254 - val_loss: 0.6181 - val_acc: 0.7935
Epoch 47/200
50000/50000 [==============================] - 76s - loss: 0.7846 - acc: 0.7322 - val_loss: 0.6305 - val_acc: 0.7874
Epoch 48/200
50000/50000 [==============================] - 76s - loss: 0.7868 - acc: 0.7304 - val_loss: 0.6436 - val_acc: 0.7807
Epoch 49/200
50000/50000 [==============================] - 76s - loss: 0.7888 - acc: 0.7306 - val_loss: 0.6809 - val_acc: 0.7696
Epoch 50/200
50000/50000 [==============================] - 76s - loss: 0.7940 - acc: 0.7280 - val_loss: 0.6533 - val_acc: 0.7773
Epoch 51/200
50000/50000 [==============================] - 76s - loss: 0.7941 - acc: 0.7301 - val_loss: 0.6434 - val_acc: 0.7810
Epoch 52/200
50000/50000 [==============================] - 76s - loss: 0.7901 - acc: 0.7310 - val_loss: 0.6261 - val_acc: 0.7888
Epoch 53/200
50000/50000 [==============================] - 76s - loss: 0.7765 - acc: 0.7390 - val_loss: 0.6634 - val_acc: 0.7734
Epoch 54/200
50000/50000 [==============================] - 76s - loss: 0.7756 - acc: 0.7364 - val_loss: 0.5995 - val_acc: 0.7975
Epoch 55/200
50000/50000 [==============================] - 76s - loss: 0.7827 - acc: 0.7343 - val_loss: 0.6601 - val_acc: 0.7790
Epoch 56/200
50000/50000 [==============================] - 76s - loss: 0.7874 - acc: 0.7304 - val_loss: 0.6625 - val_acc: 0.7778
Epoch 57/200
50000/50000 [==============================] - 76s - loss: 0.7774 - acc: 0.7342 - val_loss: 0.6231 - val_acc: 0.7911
Epoch 58/200
50000/50000 [==============================] - 76s - loss: 0.7860 - acc: 0.7345 - val_loss: 0.6105 - val_acc: 0.7919
Epoch 59/200
50000/50000 [==============================] - 76s - loss: 0.7811 - acc: 0.7351 - val_loss: 0.6368 - val_acc: 0.7878
Epoch 60/200
50000/50000 [==============================] - 76s - loss: 0.7789 - acc: 0.7348 - val_loss: 0.6162 - val_acc: 0.7921
Epoch 61/200
50000/50000 [==============================] - 76s - loss: 0.7691 - acc: 0.7381 - val_loss: 0.6361 - val_acc: 0.7871
Epoch 62/200
50000/50000 [==============================] - 76s - loss: 0.7702 - acc: 0.7387 - val_loss: 0.6054 - val_acc: 0.7973
Epoch 63/200
50000/50000 [==============================] - 76s - loss: 0.7648 - acc: 0.7397 - val_loss: 0.6482 - val_acc: 0.7834
Epoch 64/200
50000/50000 [==============================] - 76s - loss: 0.7740 - acc: 0.7377 - val_loss: 0.6198 - val_acc: 0.7928
Epoch 65/200
50000/50000 [==============================] - 76s - loss: 0.7740 - acc: 0.7365 - val_loss: 0.6422 - val_acc: 0.7905
Epoch 66/200
50000/50000 [==============================] - 76s - loss: 0.7761 - acc: 0.7359 - val_loss: 0.6330 - val_acc: 0.7930
Epoch 67/200
50000/50000 [==============================] - 76s - loss: 0.7794 - acc: 0.7355 - val_loss: 0.6669 - val_acc: 0.7791
Epoch 68/200
50000/50000 [==============================] - 76s - loss: 0.7669 - acc: 0.7397 - val_loss: 0.6447 - val_acc: 0.7833
Epoch 69/200
50000/50000 [==============================] - 76s - loss: 0.7710 - acc: 0.7383 - val_loss: 0.6148 - val_acc: 0.7909
Epoch 70/200
50000/50000 [==============================] - 76s - loss: 0.7747 - acc: 0.7386 - val_loss: 0.5887 - val_acc: 0.8049
Epoch 71/200
50000/50000 [==============================] - 76s - loss: 0.7647 - acc: 0.7419 - val_loss: 0.6251 - val_acc: 0.7881
Epoch 72/200
50000/50000 [==============================] - 76s - loss: 0.7553 - acc: 0.7441 - val_loss: 0.6539 - val_acc: 0.7817
Epoch 73/200
50000/50000 [==============================] - 76s - loss: 0.7621 - acc: 0.7403 - val_loss: 0.5972 - val_acc: 0.8002
Epoch 74/200
50000/50000 [==============================] - 76s - loss: 0.7616 - acc: 0.7431 - val_loss: 0.6404 - val_acc: 0.7866
Epoch 75/200
50000/50000 [==============================] - 76s - loss: 0.7592 - acc: 0.7431 - val_loss: 0.6202 - val_acc: 0.7933
Epoch 76/200
50000/50000 [==============================] - 76s - loss: 0.7681 - acc: 0.7390 - val_loss: 0.6046 - val_acc: 0.7981
Epoch 77/200
50000/50000 [==============================] - 76s - loss: 0.7731 - acc: 0.7384 - val_loss: 0.6021 - val_acc: 0.7999
Epoch 78/200
50000/50000 [==============================] - 76s - loss: 0.7774 - acc: 0.7387 - val_loss: 0.6239 - val_acc: 0.7917
Epoch 79/200
50000/50000 [==============================] - 76s - loss: 0.7631 - acc: 0.7447 - val_loss: 0.6359 - val_acc: 0.7900
Epoch 80/200
50000/50000 [==============================] - 76s - loss: 0.7575 - acc: 0.7453 - val_loss: 0.6017 - val_acc: 0.7990
Epoch 81/200
50000/50000 [==============================] - 76s - loss: 0.7690 - acc: 0.7404 - val_loss: 0.6458 - val_acc: 0.7867
Epoch 82/200
50000/50000 [==============================] - 76s - loss: 0.7695 - acc: 0.7385 - val_loss: 0.6348 - val_acc: 0.7865
Epoch 83/200
50000/50000 [==============================] - 76s - loss: 0.7638 - acc: 0.7407 - val_loss: 0.6066 - val_acc: 0.7944
Epoch 84/200
50000/50000 [==============================] - 76s - loss: 0.7626 - acc: 0.7423 - val_loss: 0.6236 - val_acc: 0.7945
Epoch 85/200
50000/50000 [==============================] - 76s - loss: 0.7546 - acc: 0.7465 - val_loss: 0.6414 - val_acc: 0.7852
Epoch 86/200
50000/50000 [==============================] - 76s - loss: 0.7510 - acc: 0.7487 - val_loss: 0.6109 - val_acc: 0.7995
Epoch 87/200
50000/50000 [==============================] - 76s - loss: 0.7498 - acc: 0.7469 - val_loss: 0.6685 - val_acc: 0.7741
Epoch 88/200
50000/50000 [==============================] - 76s - loss: 0.7585 - acc: 0.7441 - val_loss: 0.6080 - val_acc: 0.7967
Epoch 89/200
50000/50000 [==============================] - 76s - loss: 0.7554 - acc: 0.7463 - val_loss: 0.6430 - val_acc: 0.7870
Epoch 90/200
50000/50000 [==============================] - 76s - loss: 0.7624 - acc: 0.7452 - val_loss: 0.5973 - val_acc: 0.7988
Epoch 91/200
50000/50000 [==============================] - 76s - loss: 0.7602 - acc: 0.7448 - val_loss: 0.6068 - val_acc: 0.7984
Epoch 92/200
50000/50000 [==============================] - 76s - loss: 0.7668 - acc: 0.7421 - val_loss: 0.6461 - val_acc: 0.7817
Epoch 93/200
50000/50000 [==============================] - 76s - loss: 0.7599 - acc: 0.7453 - val_loss: 0.6302 - val_acc: 0.7904
Epoch 94/200
50000/50000 [==============================] - 76s - loss: 0.7564 - acc: 0.7462 - val_loss: 0.6124 - val_acc: 0.7990
Epoch 95/200
50000/50000 [==============================] - 76s - loss: 0.7528 - acc: 0.7464 - val_loss: 0.6377 - val_acc: 0.7873
Epoch 96/200
50000/50000 [==============================] - 76s - loss: 0.7519 - acc: 0.7464 - val_loss: 0.5868 - val_acc: 0.8048
Epoch 97/200
50000/50000 [==============================] - 76s - loss: 0.7520 - acc: 0.7477 - val_loss: 0.6192 - val_acc: 0.7941
Epoch 98/200
50000/50000 [==============================] - 76s - loss: 0.7599 - acc: 0.7443 - val_loss: 0.6191 - val_acc: 0.7915
Epoch 99/200
50000/50000 [==============================] - 76s - loss: 0.7587 - acc: 0.7438 - val_loss: 0.5945 - val_acc: 0.8023
Epoch 100/200
50000/50000 [==============================] - 76s - loss: 0.7470 - acc: 0.7476 - val_loss: 0.6114 - val_acc: 0.7952
Epoch 101/200
50000/50000 [==============================] - 76s - loss: 0.7474 - acc: 0.7470 - val_loss: 0.6055 - val_acc: 0.8006
Epoch 102/200
50000/50000 [==============================] - 76s - loss: 0.7563 - acc: 0.7454 - val_loss: 0.6149 - val_acc: 0.7951
Epoch 103/200
50000/50000 [==============================] - 76s - loss: 0.7413 - acc: 0.7497 - val_loss: 0.6068 - val_acc: 0.7968
Epoch 104/200
50000/50000 [==============================] - 76s - loss: 0.7511 - acc: 0.7476 - val_loss: 0.6027 - val_acc: 0.7974
Epoch 105/200
50000/50000 [==============================] - 76s - loss: 0.7431 - acc: 0.7507 - val_loss: 0.6190 - val_acc: 0.7923
Epoch 106/200
50000/50000 [==============================] - 76s - loss: 0.7384 - acc: 0.7508 - val_loss: 0.6523 - val_acc: 0.7861
Epoch 107/200
50000/50000 [==============================] - 76s - loss: 0.7476 - acc: 0.7481 - val_loss: 0.5939 - val_acc: 0.7994
Epoch 108/200
50000/50000 [==============================] - 76s - loss: 0.7350 - acc: 0.7524 - val_loss: 0.5933 - val_acc: 0.7977
Epoch 109/200
50000/50000 [==============================] - 76s - loss: 0.7392 - acc: 0.7497 - val_loss: 0.6073 - val_acc: 0.7924
Epoch 110/200
50000/50000 [==============================] - 76s - loss: 0.7387 - acc: 0.7527 - val_loss: 0.5676 - val_acc: 0.8094
Epoch 111/200
50000/50000 [==============================] - 76s - loss: 0.7437 - acc: 0.7505 - val_loss: 0.6051 - val_acc: 0.7988
Epoch 112/200
50000/50000 [==============================] - 76s - loss: 0.7405 - acc: 0.7532 - val_loss: 0.5682 - val_acc: 0.8095
Epoch 113/200
50000/50000 [==============================] - 76s - loss: 0.7385 - acc: 0.7524 - val_loss: 0.5759 - val_acc: 0.8035
Epoch 114/200
50000/50000 [==============================] - 76s - loss: 0.7296 - acc: 0.7543 - val_loss: 0.5756 - val_acc: 0.8052
Epoch 115/200
50000/50000 [==============================] - 76s - loss: 0.7369 - acc: 0.7538 - val_loss: 0.5877 - val_acc: 0.8047
Epoch 116/200
50000/50000 [==============================] - 76s - loss: 0.7392 - acc: 0.7508 - val_loss: 0.6160 - val_acc: 0.7924
Epoch 117/200
50000/50000 [==============================] - 76s - loss: 0.7298 - acc: 0.7520 - val_loss: 0.5999 - val_acc: 0.8032
Epoch 118/200
50000/50000 [==============================] - 76s - loss: 0.7387 - acc: 0.7522 - val_loss: 0.5664 - val_acc: 0.8118
Epoch 119/200
50000/50000 [==============================] - 76s - loss: 0.7453 - acc: 0.7509 - val_loss: 0.6278 - val_acc: 0.7931
Epoch 120/200
50000/50000 [==============================] - 76s - loss: 0.7248 - acc: 0.7559 - val_loss: 0.6112 - val_acc: 0.7983
Epoch 121/200
50000/50000 [==============================] - 76s - loss: 0.7312 - acc: 0.7556 - val_loss: 0.5775 - val_acc: 0.8083
Epoch 122/200
50000/50000 [==============================] - 76s - loss: 0.7328 - acc: 0.7554 - val_loss: 0.5893 - val_acc: 0.8053
Epoch 123/200
50000/50000 [==============================] - 76s - loss: 0.7261 - acc: 0.7542 - val_loss: 0.5827 - val_acc: 0.8025
Epoch 124/200
50000/50000 [==============================] - 76s - loss: 0.7279 - acc: 0.7565 - val_loss: 0.6075 - val_acc: 0.7965
Epoch 125/200
50000/50000 [==============================] - 76s - loss: 0.7365 - acc: 0.7528 - val_loss: 0.6252 - val_acc: 0.7951
Epoch 126/200
50000/50000 [==============================] - 76s - loss: 0.7283 - acc: 0.7568 - val_loss: 0.5970 - val_acc: 0.8019
Epoch 127/200
50000/50000 [==============================] - 76s - loss: 0.7363 - acc: 0.7535 - val_loss: 0.5758 - val_acc: 0.8119
Epoch 128/200
50000/50000 [==============================] - 76s - loss: 0.7315 - acc: 0.7549 - val_loss: 0.5887 - val_acc: 0.8061
Epoch 129/200
50000/50000 [==============================] - 76s - loss: 0.7307 - acc: 0.7556 - val_loss: 0.5978 - val_acc: 0.8021
Epoch 130/200
50000/50000 [==============================] - 76s - loss: 0.7293 - acc: 0.7559 - val_loss: 0.6001 - val_acc: 0.8020
Epoch 131/200
50000/50000 [==============================] - 76s - loss: 0.7322 - acc: 0.7529 - val_loss: 0.5939 - val_acc: 0.8029
Epoch 132/200
50000/50000 [==============================] - 76s - loss: 0.7301 - acc: 0.7570 - val_loss: 0.6338 - val_acc: 0.7894
Epoch 133/200
50000/50000 [==============================] - 76s - loss: 0.7263 - acc: 0.7559 - val_loss: 0.5825 - val_acc: 0.8084
Epoch 134/200
50000/50000 [==============================] - 76s - loss: 0.7332 - acc: 0.7528 - val_loss: 0.6118 - val_acc: 0.7957
Epoch 135/200
50000/50000 [==============================] - 76s - loss: 0.7296 - acc: 0.7526 - val_loss: 0.5887 - val_acc: 0.8032
Epoch 136/200
50000/50000 [==============================] - 76s - loss: 0.7275 - acc: 0.7548 - val_loss: 0.5969 - val_acc: 0.8013
Epoch 137/200
50000/50000 [==============================] - 76s - loss: 0.7276 - acc: 0.7571 - val_loss: 0.6161 - val_acc: 0.7978
Epoch 138/200
50000/50000 [==============================] - 76s - loss: 0.7257 - acc: 0.7563 - val_loss: 0.6023 - val_acc: 0.7996
Epoch 139/200
50000/50000 [==============================] - 76s - loss: 0.7164 - acc: 0.7609 - val_loss: 0.5737 - val_acc: 0.8136
Epoch 140/200
50000/50000 [==============================] - 76s - loss: 0.7202 - acc: 0.7594 - val_loss: 0.6093 - val_acc: 0.7986
Epoch 141/200
50000/50000 [==============================] - 76s - loss: 0.7259 - acc: 0.7553 - val_loss: 0.5765 - val_acc: 0.8109
Epoch 142/200
50000/50000 [==============================] - 76s - loss: 0.7169 - acc: 0.7580 - val_loss: 0.6152 - val_acc: 0.7950
Epoch 143/200
50000/50000 [==============================] - 76s - loss: 0.7190 - acc: 0.7579 - val_loss: 0.5963 - val_acc: 0.8045
Epoch 144/200
50000/50000 [==============================] - 76s - loss: 0.7144 - acc: 0.7611 - val_loss: 0.5938 - val_acc: 0.8055
Epoch 145/200
50000/50000 [==============================] - 76s - loss: 0.7295 - acc: 0.7582 - val_loss: 0.5690 - val_acc: 0.8109
Epoch 146/200
50000/50000 [==============================] - 76s - loss: 0.7194 - acc: 0.7596 - val_loss: 0.5589 - val_acc: 0.8170
Epoch 147/200
50000/50000 [==============================] - 76s - loss: 0.7152 - acc: 0.7607 - val_loss: 0.5825 - val_acc: 0.8132
Epoch 148/200
50000/50000 [==============================] - 76s - loss: 0.7184 - acc: 0.7575 - val_loss: 0.5864 - val_acc: 0.8087
Epoch 149/200
50000/50000 [==============================] - 76s - loss: 0.7226 - acc: 0.7589 - val_loss: 0.5720 - val_acc: 0.8105
Epoch 150/200
50000/50000 [==============================] - 76s - loss: 0.7039 - acc: 0.7639 - val_loss: 0.6120 - val_acc: 0.7999
Epoch 151/200
50000/50000 [==============================] - 76s - loss: 0.7093 - acc: 0.7616 - val_loss: 0.5781 - val_acc: 0.8074
Epoch 152/200
50000/50000 [==============================] - 76s - loss: 0.7188 - acc: 0.7580 - val_loss: 0.5809 - val_acc: 0.8072
Epoch 153/200
50000/50000 [==============================] - 76s - loss: 0.7039 - acc: 0.7645 - val_loss: 0.5686 - val_acc: 0.8101
Epoch 154/200
50000/50000 [==============================] - 76s - loss: 0.7031 - acc: 0.7631 - val_loss: 0.5633 - val_acc: 0.8188
Epoch 155/200
50000/50000 [==============================] - 76s - loss: 0.7164 - acc: 0.7616 - val_loss: 0.5946 - val_acc: 0.8037
Epoch 156/200
50000/50000 [==============================] - 76s - loss: 0.7172 - acc: 0.7603 - val_loss: 0.6074 - val_acc: 0.7958
Epoch 157/200
50000/50000 [==============================] - 76s - loss: 0.7156 - acc: 0.7605 - val_loss: 0.5792 - val_acc: 0.8122
Epoch 158/200
50000/50000 [==============================] - 76s - loss: 0.7089 - acc: 0.7625 - val_loss: 0.5674 - val_acc: 0.8121
Epoch 159/200
50000/50000 [==============================] - 76s - loss: 0.7148 - acc: 0.7626 - val_loss: 0.5708 - val_acc: 0.8125
Epoch 160/200
50000/50000 [==============================] - 76s - loss: 0.7158 - acc: 0.7607 - val_loss: 0.5711 - val_acc: 0.8133
Epoch 161/200
50000/50000 [==============================] - 76s - loss: 0.7164 - acc: 0.7597 - val_loss: 0.5829 - val_acc: 0.8084
Epoch 162/200
50000/50000 [==============================] - 76s - loss: 0.7058 - acc: 0.7637 - val_loss: 0.6212 - val_acc: 0.7972
Epoch 163/200
50000/50000 [==============================] - 76s - loss: 0.7068 - acc: 0.7642 - val_loss: 0.5546 - val_acc: 0.8163
Epoch 164/200
50000/50000 [==============================] - 76s - loss: 0.7141 - acc: 0.7611 - val_loss: 0.5739 - val_acc: 0.8075
Epoch 165/200
50000/50000 [==============================] - 76s - loss: 0.7082 - acc: 0.7644 - val_loss: 0.6128 - val_acc: 0.7973
Epoch 166/200
50000/50000 [==============================] - 76s - loss: 0.7053 - acc: 0.7644 - val_loss: 0.5710 - val_acc: 0.8124
Epoch 167/200
50000/50000 [==============================] - 76s - loss: 0.7212 - acc: 0.7582 - val_loss: 0.6079 - val_acc: 0.8005
Epoch 168/200
50000/50000 [==============================] - 76s - loss: 0.7109 - acc: 0.7606 - val_loss: 0.5686 - val_acc: 0.8114
Epoch 169/200
50000/50000 [==============================] - 76s - loss: 0.7084 - acc: 0.7618 - val_loss: 0.5450 - val_acc: 0.8177
Epoch 170/200
50000/50000 [==============================] - 76s - loss: 0.6988 - acc: 0.7673 - val_loss: 0.5380 - val_acc: 0.8234
Epoch 171/200
50000/50000 [==============================] - 76s - loss: 0.7067 - acc: 0.7636 - val_loss: 0.5669 - val_acc: 0.8122
Epoch 172/200
50000/50000 [==============================] - 76s - loss: 0.7114 - acc: 0.7621 - val_loss: 0.5969 - val_acc: 0.8018
Epoch 173/200
50000/50000 [==============================] - 76s - loss: 0.7129 - acc: 0.7612 - val_loss: 0.6048 - val_acc: 0.7977
Epoch 174/200
50000/50000 [==============================] - 76s - loss: 0.7102 - acc: 0.7620 - val_loss: 0.5934 - val_acc: 0.8059
Epoch 175/200
50000/50000 [==============================] - 76s - loss: 0.7037 - acc: 0.7647 - val_loss: 0.5651 - val_acc: 0.8145
Epoch 176/200
50000/50000 [==============================] - 76s - loss: 0.7007 - acc: 0.7675 - val_loss: 0.6244 - val_acc: 0.7921
Epoch 177/200
50000/50000 [==============================] - 76s - loss: 0.6965 - acc: 0.7671 - val_loss: 0.6227 - val_acc: 0.7928
Epoch 178/200
50000/50000 [==============================] - 76s - loss: 0.7074 - acc: 0.7642 - val_loss: 0.5712 - val_acc: 0.8093
Epoch 179/200
50000/50000 [==============================] - 76s - loss: 0.6923 - acc: 0.7697 - val_loss: 0.5644 - val_acc: 0.8142
Epoch 180/200
50000/50000 [==============================] - 76s - loss: 0.7036 - acc: 0.7661 - val_loss: 0.5758 - val_acc: 0.8126
Epoch 181/200
50000/50000 [==============================] - 76s - loss: 0.6989 - acc: 0.7658 - val_loss: 0.5553 - val_acc: 0.8160
Epoch 182/200
50000/50000 [==============================] - 76s - loss: 0.6995 - acc: 0.7659 - val_loss: 0.5605 - val_acc: 0.8146
Epoch 183/200
50000/50000 [==============================] - 76s - loss: 0.7007 - acc: 0.7649 - val_loss: 0.5660 - val_acc: 0.8102
Epoch 184/200
50000/50000 [==============================] - 76s - loss: 0.6972 - acc: 0.7675 - val_loss: 0.6031 - val_acc: 0.7981
Epoch 185/200
50000/50000 [==============================] - 76s - loss: 0.7101 - acc: 0.7612 - val_loss: 0.5707 - val_acc: 0.8050
Epoch 186/200
50000/50000 [==============================] - 76s - loss: 0.6900 - acc: 0.7681 - val_loss: 0.5437 - val_acc: 0.8223
Epoch 187/200
50000/50000 [==============================] - 76s - loss: 0.6989 - acc: 0.7663 - val_loss: 0.5826 - val_acc: 0.8072
Epoch 188/200
50000/50000 [==============================] - 76s - loss: 0.6892 - acc: 0.7699 - val_loss: 0.5498 - val_acc: 0.8202
Epoch 189/200
50000/50000 [==============================] - 76s - loss: 0.7000 - acc: 0.7678 - val_loss: 0.5809 - val_acc: 0.8090
Epoch 190/200
50000/50000 [==============================] - 76s - loss: 0.6834 - acc: 0.7712 - val_loss: 0.5624 - val_acc: 0.8173
Epoch 191/200
50000/50000 [==============================] - 76s - loss: 0.6854 - acc: 0.7706 - val_loss: 0.5764 - val_acc: 0.8124
Epoch 192/200
50000/50000 [==============================] - 76s - loss: 0.6951 - acc: 0.7665 - val_loss: 0.5545 - val_acc: 0.8145
Epoch 193/200
50000/50000 [==============================] - 76s - loss: 0.6849 - acc: 0.7694 - val_loss: 0.5607 - val_acc: 0.8166
Epoch 194/200
50000/50000 [==============================] - 76s - loss: 0.7010 - acc: 0.7661 - val_loss: 0.5554 - val_acc: 0.8209
Epoch 195/200
50000/50000 [==============================] - 76s - loss: 0.6956 - acc: 0.7693 - val_loss: 0.5482 - val_acc: 0.8198
Epoch 196/200
50000/50000 [==============================] - 76s - loss: 0.6918 - acc: 0.7677 - val_loss: 0.5510 - val_acc: 0.8191
Epoch 197/200
50000/50000 [==============================] - 76s - loss: 0.6879 - acc: 0.7691 - val_loss: 0.5459 - val_acc: 0.8196
Epoch 198/200
50000/50000 [==============================] - 76s - loss: 0.6904 - acc: 0.7689 - val_loss: 0.5865 - val_acc: 0.8061
Epoch 199/200
50000/50000 [==============================] - 76s - loss: 0.6916 - acc: 0.7691 - val_loss: 0.5646 - val_acc: 0.8109
Epoch 200/200
50000/50000 [==============================] - 76s - loss: 0.6865 - acc: 0.7694 - val_loss: 0.6151 - val_acc: 0.7979


python stateful_lstm.py
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Generating Data
Input shape: (50000, 1, 1)
Output shape
(50000, 1)
Creating Model
Training
Epoch 0 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 347.6594    
Epoch 1 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 155.6363    
Epoch 2 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 81.5722    
Epoch 3 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 48.3305    
Epoch 4 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 30.9629    
Epoch 5 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 21.0955    
Epoch 6 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 15.2851    
Epoch 7 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 11.8137    
Epoch 8 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 9.7596    
Epoch 9 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 8.6144    
Epoch 10 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 6.8574    
Epoch 11 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 5.4063    
Epoch 12 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.7967    
Epoch 13 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.3603    
Epoch 14 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.9979    
Epoch 15 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.6330    
Epoch 16 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.5952    
Epoch 17 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.3124    
Epoch 18 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.0268    
Epoch 19 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.0712    
Epoch 20 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.7632    
Epoch 21 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.1311    
Epoch 22 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 4.3231    
Epoch 23 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.4092    
Epoch 24 / 25
Epoch 1/1
50000/50000 [==============================] - 12s - loss: 3.0051    
Predicting
Ploting Results


python babi_rnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
RNN / Embed / Sent / Query = <class 'keras.layers.recurrent.LSTM'>, 50, 100, 100
vocab = [u'.', u'?', u'Daniel', u'John', u'Mary', u'Sandra', u'Where', u'apple', u'back', u'bathroom', u'bedroom', u'discarded', u'down', u'dropped', u'football', u'garden', u'got', u'grabbed', u'hallway', u'is', u'journeyed', u'kitchen', u'left', u'milk', u'moved', u'office', u'picked', u'put', u'the', u'there', u'to', u'took', u'travelled', u'up', u'went']
X.shape = (1000, 552)
Xq.shape = (1000, 5)
Y.shape = (1000, 36)
story_maxlen, query_maxlen = 552, 5
Build model...
Training
Train on 950 samples, validate on 50 samples
Epoch 1/40
950/950 [==============================] - 9s - loss: 3.0771 - acc: 0.1895 - val_loss: 2.6338 - val_acc: 0.0600
Epoch 2/40
950/950 [==============================] - 9s - loss: 2.1378 - acc: 0.1884 - val_loss: 1.9316 - val_acc: 0.0600
Epoch 3/40
950/950 [==============================] - 9s - loss: 1.9409 - acc: 0.1916 - val_loss: 1.8471 - val_acc: 0.0600
Epoch 4/40
950/950 [==============================] - 9s - loss: 1.9016 - acc: 0.1947 - val_loss: 1.8591 - val_acc: 0.0600
Epoch 5/40
950/950 [==============================] - 9s - loss: 1.8757 - acc: 0.1937 - val_loss: 1.8523 - val_acc: 0.0600
Epoch 6/40
950/950 [==============================] - 9s - loss: 1.8856 - acc: 0.1958 - val_loss: 1.8721 - val_acc: 0.0600
Epoch 7/40
950/950 [==============================] - 9s - loss: 1.8953 - acc: 0.1705 - val_loss: 1.8137 - val_acc: 0.1400
Epoch 8/40
950/950 [==============================] - 9s - loss: 1.8641 - acc: 0.1874 - val_loss: 1.8301 - val_acc: 0.0600
Epoch 9/40
950/950 [==============================] - 9s - loss: 1.8720 - acc: 0.1811 - val_loss: 1.8262 - val_acc: 0.0600
Epoch 10/40
950/950 [==============================] - 9s - loss: 1.8619 - acc: 0.1895 - val_loss: 1.8139 - val_acc: 0.0600
Epoch 11/40
950/950 [==============================] - 9s - loss: 1.8443 - acc: 0.1916 - val_loss: 1.8612 - val_acc: 0.0600
Epoch 12/40
950/950 [==============================] - 9s - loss: 1.8156 - acc: 0.1937 - val_loss: 1.8204 - val_acc: 0.0600
Epoch 13/40
950/950 [==============================] - 9s - loss: 1.8356 - acc: 0.1863 - val_loss: 1.7687 - val_acc: 0.3000
Epoch 14/40
950/950 [==============================] - 9s - loss: 1.8339 - acc: 0.1768 - val_loss: 1.7887 - val_acc: 0.1400
Epoch 15/40
950/950 [==============================] - 9s - loss: 1.8161 - acc: 0.1979 - val_loss: 1.8206 - val_acc: 0.0600
Epoch 16/40
950/950 [==============================] - 9s - loss: 1.8239 - acc: 0.2232 - val_loss: 1.7962 - val_acc: 0.1600
Epoch 17/40
950/950 [==============================] - 9s - loss: 1.7992 - acc: 0.2200 - val_loss: 1.7704 - val_acc: 0.2400
Epoch 18/40
950/950 [==============================] - 9s - loss: 1.8092 - acc: 0.2105 - val_loss: 1.7604 - val_acc: 0.2600
Epoch 19/40
950/950 [==============================] - 9s - loss: 1.7945 - acc: 0.2326 - val_loss: 1.8006 - val_acc: 0.1600
Epoch 20/40
950/950 [==============================] - 9s - loss: 1.7948 - acc: 0.2284 - val_loss: 1.8224 - val_acc: 0.1600
Epoch 21/40
950/950 [==============================] - 9s - loss: 1.7885 - acc: 0.2295 - val_loss: 1.7620 - val_acc: 0.2400
Epoch 22/40
950/950 [==============================] - 9s - loss: 1.7695 - acc: 0.2474 - val_loss: 1.7608 - val_acc: 0.2000
Epoch 23/40
950/950 [==============================] - 9s - loss: 1.7567 - acc: 0.2526 - val_loss: 1.6990 - val_acc: 0.3200
Epoch 24/40
950/950 [==============================] - 9s - loss: 1.7521 - acc: 0.2621 - val_loss: 1.7765 - val_acc: 0.2200
Epoch 25/40
950/950 [==============================] - 9s - loss: 1.7814 - acc: 0.2516 - val_loss: 1.6995 - val_acc: 0.3400
Epoch 26/40
950/950 [==============================] - 9s - loss: 1.7519 - acc: 0.2495 - val_loss: 1.7735 - val_acc: 0.2000
Epoch 27/40
950/950 [==============================] - 9s - loss: 1.7379 - acc: 0.3000 - val_loss: 1.7080 - val_acc: 0.3600
Epoch 28/40
950/950 [==============================] - 9s - loss: 1.7266 - acc: 0.2832 - val_loss: 1.8205 - val_acc: 0.1800
Epoch 29/40
950/950 [==============================] - 9s - loss: 1.7199 - acc: 0.2937 - val_loss: 1.6843 - val_acc: 0.3600
Epoch 30/40
950/950 [==============================] - 9s - loss: 1.7142 - acc: 0.2947 - val_loss: 1.6985 - val_acc: 0.3400
Epoch 31/40
950/950 [==============================] - 9s - loss: 1.7070 - acc: 0.3147 - val_loss: 1.7812 - val_acc: 0.2000
Epoch 32/40
950/950 [==============================] - 9s - loss: 1.7164 - acc: 0.2947 - val_loss: 1.6878 - val_acc: 0.3600
Epoch 33/40
950/950 [==============================] - 9s - loss: 1.7086 - acc: 0.3063 - val_loss: 1.7184 - val_acc: 0.3000
Epoch 34/40
950/950 [==============================] - 9s - loss: 1.6891 - acc: 0.3253 - val_loss: 1.8076 - val_acc: 0.3000
Epoch 35/40
950/950 [==============================] - 9s - loss: 1.7639 - acc: 0.2947 - val_loss: 1.7174 - val_acc: 0.3400
Epoch 36/40
950/950 [==============================] - 9s - loss: 1.7231 - acc: 0.2937 - val_loss: 1.7030 - val_acc: 0.3400
Epoch 37/40
950/950 [==============================] - 9s - loss: 1.6799 - acc: 0.3337 - val_loss: 1.6776 - val_acc: 0.3000
Epoch 38/40
950/950 [==============================] - 9s - loss: 1.6726 - acc: 0.3368 - val_loss: 1.7101 - val_acc: 0.3000
Epoch 39/40
950/950 [==============================] - 9s - loss: 1.6822 - acc: 0.3211 - val_loss: 1.6596 - val_acc: 0.3400
Epoch 40/40
950/950 [==============================] - 9s - loss: 1.7062 - acc: 0.3253 - val_loss: 1.6936 - val_acc: 0.3000
1000/1000 [==============================] - 4s     
Test loss / test accuracy = 1.7147 / 0.2820


python babi_memnn.py 
Using Theano backend.
Using gpu device 0: GeForce GTX 660 (CNMeM is disabled, cuDNN not available)
Extracting stories for the challenge: single_supporting_fact_10k
-
Vocab size: 22 unique words
Story max length: 68 words
Query max length: 4 words
Number of training stories: 10000
Number of test stories: 1000
-
Here's what a "story" tuple looks like (input, query, answer):
([u'Mary', u'moved', u'to', u'the', u'bathroom', u'.', u'John', u'went', u'to', u'the', u'hallway', u'.'], [u'Where', u'is', u'Mary', u'?'], u'bathroom')
-
Vectorizing the word sequences...
-
inputs: integer tensor of shape (samples, max_length)
inputs_train shape: (10000, 68)
inputs_test shape: (1000, 68)
-
queries: integer tensor of shape (samples, max_length)
queries_train shape: (10000, 4)
queries_test shape: (1000, 4)
-
answers: binary (1 or 0) tensor of shape (samples, vocab_size)
answers_train shape: (10000, 22)
answers_test shape: (1000, 22)
-
Compiling...
Train on 10000 samples, validate on 1000 samples
Epoch 1/120
10000/10000 [==============================] - 2s - loss: 2.0684 - acc: 0.1614 - val_loss: 1.8024 - val_acc: 0.1910
Epoch 2/120
10000/10000 [==============================] - 2s - loss: 1.8320 - acc: 0.1687 - val_loss: 1.7971 - val_acc: 0.1830
Epoch 3/120
10000/10000 [==============================] - 2s - loss: 1.8149 - acc: 0.1700 - val_loss: 1.7831 - val_acc: 0.2340
Epoch 4/120
10000/10000 [==============================] - 2s - loss: 1.7436 - acc: 0.2401 - val_loss: 1.6922 - val_acc: 0.2660
Epoch 5/120
10000/10000 [==============================] - 2s - loss: 1.6658 - acc: 0.3098 - val_loss: 1.6491 - val_acc: 0.3380
Epoch 6/120
10000/10000 [==============================] - 2s - loss: 1.6266 - acc: 0.3495 - val_loss: 1.5923 - val_acc: 0.3820
Epoch 7/120
10000/10000 [==============================] - 2s - loss: 1.5655 - acc: 0.3923 - val_loss: 1.5462 - val_acc: 0.4120
Epoch 8/120
10000/10000 [==============================] - 2s - loss: 1.5236 - acc: 0.4057 - val_loss: 1.5058 - val_acc: 0.4260
Epoch 9/120
10000/10000 [==============================] - 2s - loss: 1.5016 - acc: 0.4228 - val_loss: 1.4919 - val_acc: 0.4410
Epoch 10/120
10000/10000 [==============================] - 2s - loss: 1.4930 - acc: 0.4346 - val_loss: 1.4726 - val_acc: 0.4360
Epoch 11/120
10000/10000 [==============================] - 2s - loss: 1.4723 - acc: 0.4467 - val_loss: 1.4373 - val_acc: 0.4560
Epoch 12/120
10000/10000 [==============================] - 2s - loss: 1.4295 - acc: 0.4667 - val_loss: 1.3905 - val_acc: 0.4710
Epoch 13/120
10000/10000 [==============================] - 2s - loss: 1.4027 - acc: 0.4683 - val_loss: 1.3723 - val_acc: 0.4800
Epoch 14/120
10000/10000 [==============================] - 2s - loss: 1.3901 - acc: 0.4763 - val_loss: 1.3644 - val_acc: 0.4820
Epoch 15/120
10000/10000 [==============================] - 2s - loss: 1.3719 - acc: 0.4819 - val_loss: 1.3797 - val_acc: 0.4820
Epoch 16/120
10000/10000 [==============================] - 2s - loss: 1.3710 - acc: 0.4807 - val_loss: 1.3497 - val_acc: 0.4940
Epoch 17/120
10000/10000 [==============================] - 2s - loss: 1.3716 - acc: 0.4787 - val_loss: 1.3433 - val_acc: 0.5040
Epoch 18/120
10000/10000 [==============================] - 2s - loss: 1.3657 - acc: 0.4836 - val_loss: 1.3385 - val_acc: 0.5080
Epoch 19/120
10000/10000 [==============================] - 2s - loss: 1.3575 - acc: 0.4859 - val_loss: 1.3291 - val_acc: 0.5120
Epoch 20/120
10000/10000 [==============================] - 2s - loss: 1.3514 - acc: 0.4920 - val_loss: 1.3421 - val_acc: 0.5030
Epoch 21/120
10000/10000 [==============================] - 2s - loss: 1.3395 - acc: 0.4992 - val_loss: 1.3391 - val_acc: 0.5010
Epoch 22/120
10000/10000 [==============================] - 2s - loss: 1.3555 - acc: 0.4843 - val_loss: 1.3272 - val_acc: 0.4940
Epoch 23/120
10000/10000 [==============================] - 2s - loss: 1.3452 - acc: 0.4928 - val_loss: 1.3166 - val_acc: 0.5160
Epoch 24/120
10000/10000 [==============================] - 2s - loss: 1.3396 - acc: 0.4939 - val_loss: 1.3166 - val_acc: 0.5240
Epoch 25/120
10000/10000 [==============================] - 2s - loss: 1.3374 - acc: 0.4962 - val_loss: 1.3190 - val_acc: 0.5140
Epoch 26/120
10000/10000 [==============================] - 2s - loss: 1.3275 - acc: 0.5017 - val_loss: 1.3016 - val_acc: 0.5260
Epoch 27/120
10000/10000 [==============================] - 2s - loss: 1.3168 - acc: 0.4994 - val_loss: 1.3031 - val_acc: 0.5230
Epoch 28/120
10000/10000 [==============================] - 2s - loss: 1.3075 - acc: 0.5065 - val_loss: 1.2768 - val_acc: 0.5340
Epoch 29/120
10000/10000 [==============================] - 2s - loss: 1.2929 - acc: 0.5134 - val_loss: 1.2645 - val_acc: 0.5240
Epoch 30/120
10000/10000 [==============================] - 2s - loss: 1.2774 - acc: 0.5111 - val_loss: 1.2328 - val_acc: 0.5340
Epoch 31/120
10000/10000 [==============================] - 2s - loss: 1.2598 - acc: 0.5112 - val_loss: 1.2129 - val_acc: 0.5340
Epoch 32/120
10000/10000 [==============================] - 2s - loss: 1.2564 - acc: 0.5101 - val_loss: 1.2069 - val_acc: 0.5290
Epoch 33/120
10000/10000 [==============================] - 2s - loss: 1.2544 - acc: 0.5163 - val_loss: 1.2129 - val_acc: 0.5240
Epoch 34/120
10000/10000 [==============================] - 2s - loss: 1.2536 - acc: 0.5125 - val_loss: 1.2122 - val_acc: 0.5340
Epoch 35/120
10000/10000 [==============================] - 2s - loss: 1.2309 - acc: 0.5224 - val_loss: 1.2086 - val_acc: 0.5290
Epoch 36/120
10000/10000 [==============================] - 2s - loss: 1.2328 - acc: 0.5244 - val_loss: 1.2028 - val_acc: 0.5250
Epoch 37/120
10000/10000 [==============================] - 2s - loss: 1.2279 - acc: 0.5234 - val_loss: 1.1873 - val_acc: 0.5250
Epoch 38/120
10000/10000 [==============================] - 2s - loss: 1.2292 - acc: 0.5200 - val_loss: 1.1921 - val_acc: 0.5220
Epoch 39/120
10000/10000 [==============================] - 2s - loss: 1.2157 - acc: 0.5239 - val_loss: 1.1803 - val_acc: 0.5310
Epoch 40/120
10000/10000 [==============================] - 2s - loss: 1.2154 - acc: 0.5225 - val_loss: 1.1868 - val_acc: 0.5360
Epoch 41/120
10000/10000 [==============================] - 2s - loss: 1.2029 - acc: 0.5326 - val_loss: 1.1595 - val_acc: 0.5350
Epoch 42/120
10000/10000 [==============================] - 2s - loss: 1.1928 - acc: 0.5325 - val_loss: 1.1399 - val_acc: 0.5420
Epoch 43/120
10000/10000 [==============================] - 2s - loss: 1.1680 - acc: 0.5400 - val_loss: 1.0980 - val_acc: 0.5510
Epoch 44/120
10000/10000 [==============================] - 2s - loss: 1.1261 - acc: 0.5565 - val_loss: 1.0249 - val_acc: 0.5660
Epoch 45/120
10000/10000 [==============================] - 2s - loss: 1.0717 - acc: 0.5863 - val_loss: 0.9660 - val_acc: 0.6150
Epoch 46/120
10000/10000 [==============================] - 2s - loss: 1.0060 - acc: 0.6164 - val_loss: 0.8830 - val_acc: 0.6610
Epoch 47/120
10000/10000 [==============================] - 2s - loss: 0.9485 - acc: 0.6438 - val_loss: 0.8458 - val_acc: 0.6840
Epoch 48/120
10000/10000 [==============================] - 2s - loss: 0.9100 - acc: 0.6621 - val_loss: 0.7885 - val_acc: 0.7060
Epoch 49/120
10000/10000 [==============================] - 2s - loss: 0.8696 - acc: 0.6837 - val_loss: 0.7571 - val_acc: 0.7210
Epoch 50/120
10000/10000 [==============================] - 2s - loss: 0.8328 - acc: 0.6947 - val_loss: 0.7357 - val_acc: 0.7330
Epoch 51/120
10000/10000 [==============================] - 2s - loss: 0.8157 - acc: 0.7094 - val_loss: 0.7151 - val_acc: 0.7400
Epoch 52/120
10000/10000 [==============================] - 2s - loss: 0.7821 - acc: 0.7213 - val_loss: 0.7079 - val_acc: 0.7410
Epoch 53/120
10000/10000 [==============================] - 2s - loss: 0.7701 - acc: 0.7267 - val_loss: 0.6937 - val_acc: 0.7450
Epoch 54/120
10000/10000 [==============================] - 2s - loss: 0.7550 - acc: 0.7294 - val_loss: 0.6726 - val_acc: 0.7480
Epoch 55/120
10000/10000 [==============================] - 2s - loss: 0.7442 - acc: 0.7335 - val_loss: 0.6579 - val_acc: 0.7480
Epoch 56/120
10000/10000 [==============================] - 2s - loss: 0.7177 - acc: 0.7420 - val_loss: 0.6560 - val_acc: 0.7460
Epoch 57/120
10000/10000 [==============================] - 2s - loss: 0.7126 - acc: 0.7411 - val_loss: 0.6373 - val_acc: 0.7480
Epoch 58/120
10000/10000 [==============================] - 2s - loss: 0.7026 - acc: 0.7427 - val_loss: 0.6363 - val_acc: 0.7470
Epoch 59/120
10000/10000 [==============================] - 2s - loss: 0.6832 - acc: 0.7533 - val_loss: 0.6168 - val_acc: 0.7550
Epoch 60/120
10000/10000 [==============================] - 2s - loss: 0.6719 - acc: 0.7514 - val_loss: 0.6142 - val_acc: 0.7530
Epoch 61/120
10000/10000 [==============================] - 2s - loss: 0.6594 - acc: 0.7580 - val_loss: 0.5949 - val_acc: 0.7530
Epoch 62/120
10000/10000 [==============================] - 2s - loss: 0.6415 - acc: 0.7626 - val_loss: 0.5775 - val_acc: 0.7540
Epoch 63/120
10000/10000 [==============================] - 2s - loss: 0.6265 - acc: 0.7668 - val_loss: 0.5656 - val_acc: 0.7610
Epoch 64/120
10000/10000 [==============================] - 2s - loss: 0.6155 - acc: 0.7735 - val_loss: 0.5516 - val_acc: 0.7600
Epoch 65/120
10000/10000 [==============================] - 2s - loss: 0.5980 - acc: 0.7741 - val_loss: 0.5402 - val_acc: 0.7720
Epoch 66/120
10000/10000 [==============================] - 2s - loss: 0.5843 - acc: 0.7814 - val_loss: 0.5325 - val_acc: 0.7640
Epoch 67/120
10000/10000 [==============================] - 2s - loss: 0.5734 - acc: 0.7859 - val_loss: 0.5219 - val_acc: 0.7840
Epoch 68/120
10000/10000 [==============================] - 2s - loss: 0.5581 - acc: 0.7857 - val_loss: 0.5135 - val_acc: 0.7960
Epoch 69/120
10000/10000 [==============================] - 2s - loss: 0.5467 - acc: 0.7934 - val_loss: 0.4978 - val_acc: 0.7930
Epoch 70/120
10000/10000 [==============================] - 2s - loss: 0.5431 - acc: 0.7978 - val_loss: 0.4823 - val_acc: 0.8020
Epoch 71/120
10000/10000 [==============================] - 2s - loss: 0.5323 - acc: 0.7991 - val_loss: 0.4828 - val_acc: 0.8060
Epoch 72/120
10000/10000 [==============================] - 2s - loss: 0.5182 - acc: 0.8043 - val_loss: 0.4611 - val_acc: 0.8170
Epoch 73/120
10000/10000 [==============================] - 2s - loss: 0.5097 - acc: 0.8105 - val_loss: 0.4601 - val_acc: 0.8240
Epoch 74/120
10000/10000 [==============================] - 2s - loss: 0.5000 - acc: 0.8131 - val_loss: 0.4462 - val_acc: 0.8370
Epoch 75/120
10000/10000 [==============================] - 2s - loss: 0.4916 - acc: 0.8149 - val_loss: 0.4338 - val_acc: 0.8360
Epoch 76/120
10000/10000 [==============================] - 2s - loss: 0.4878 - acc: 0.8186 - val_loss: 0.4327 - val_acc: 0.8470
Epoch 77/120
10000/10000 [==============================] - 2s - loss: 0.4680 - acc: 0.8262 - val_loss: 0.4181 - val_acc: 0.8530
Epoch 78/120
10000/10000 [==============================] - 2s - loss: 0.4563 - acc: 0.8259 - val_loss: 0.4050 - val_acc: 0.8660
Epoch 79/120
10000/10000 [==============================] - 2s - loss: 0.4545 - acc: 0.8347 - val_loss: 0.4088 - val_acc: 0.8550
Epoch 80/120
10000/10000 [==============================] - 2s - loss: 0.4546 - acc: 0.8311 - val_loss: 0.4006 - val_acc: 0.8580
Epoch 81/120
10000/10000 [==============================] - 2s - loss: 0.4563 - acc: 0.8314 - val_loss: 0.3986 - val_acc: 0.8640
Epoch 82/120
10000/10000 [==============================] - 2s - loss: 0.4382 - acc: 0.8380 - val_loss: 0.3796 - val_acc: 0.8730
Epoch 83/120
10000/10000 [==============================] - 2s - loss: 0.4473 - acc: 0.8359 - val_loss: 0.3782 - val_acc: 0.8700
Epoch 84/120
10000/10000 [==============================] - 2s - loss: 0.4322 - acc: 0.8430 - val_loss: 0.3769 - val_acc: 0.8720
Epoch 85/120
10000/10000 [==============================] - 2s - loss: 0.4345 - acc: 0.8373 - val_loss: 0.3690 - val_acc: 0.8710
Epoch 86/120
10000/10000 [==============================] - 2s - loss: 0.4175 - acc: 0.8431 - val_loss: 0.3708 - val_acc: 0.8690
Epoch 87/120
10000/10000 [==============================] - 2s - loss: 0.4241 - acc: 0.8450 - val_loss: 0.3625 - val_acc: 0.8770
Epoch 88/120
10000/10000 [==============================] - 2s - loss: 0.4169 - acc: 0.8484 - val_loss: 0.3711 - val_acc: 0.8640
Epoch 89/120
10000/10000 [==============================] - 2s - loss: 0.4106 - acc: 0.8453 - val_loss: 0.3666 - val_acc: 0.8700
Epoch 90/120
10000/10000 [==============================] - 2s - loss: 0.4051 - acc: 0.8528 - val_loss: 0.3593 - val_acc: 0.8680
Epoch 91/120
10000/10000 [==============================] - 2s - loss: 0.4064 - acc: 0.8512 - val_loss: 0.3532 - val_acc: 0.8760
Epoch 92/120
10000/10000 [==============================] - 2s - loss: 0.4062 - acc: 0.8484 - val_loss: 0.3555 - val_acc: 0.8740
Epoch 93/120
10000/10000 [==============================] - 2s - loss: 0.4096 - acc: 0.8480 - val_loss: 0.3467 - val_acc: 0.8770
Epoch 94/120
10000/10000 [==============================] - 2s - loss: 0.4018 - acc: 0.8529 - val_loss: 0.3471 - val_acc: 0.8740
Epoch 95/120
10000/10000 [==============================] - 2s - loss: 0.3854 - acc: 0.8581 - val_loss: 0.3443 - val_acc: 0.8710
Epoch 96/120
10000/10000 [==============================] - 2s - loss: 0.3947 - acc: 0.8558 - val_loss: 0.3462 - val_acc: 0.8820
Epoch 97/120
10000/10000 [==============================] - 2s - loss: 0.3934 - acc: 0.8585 - val_loss: 0.3384 - val_acc: 0.8730
Epoch 98/120
10000/10000 [==============================] - 2s - loss: 0.3914 - acc: 0.8554 - val_loss: 0.3524 - val_acc: 0.8720
Epoch 99/120
10000/10000 [==============================] - 2s - loss: 0.3820 - acc: 0.8577 - val_loss: 0.3432 - val_acc: 0.8760
Epoch 100/120
10000/10000 [==============================] - 2s - loss: 0.3816 - acc: 0.8603 - val_loss: 0.3439 - val_acc: 0.8760
Epoch 101/120
10000/10000 [==============================] - 2s - loss: 0.3921 - acc: 0.8552 - val_loss: 0.3405 - val_acc: 0.8820
Epoch 102/120
10000/10000 [==============================] - 2s - loss: 0.3810 - acc: 0.8591 - val_loss: 0.3298 - val_acc: 0.8800
Epoch 103/120
10000/10000 [==============================] - 2s - loss: 0.3803 - acc: 0.8627 - val_loss: 0.3271 - val_acc: 0.8790
Epoch 104/120
10000/10000 [==============================] - 2s - loss: 0.3797 - acc: 0.8618 - val_loss: 0.3356 - val_acc: 0.8780
Epoch 105/120
10000/10000 [==============================] - 2s - loss: 0.3793 - acc: 0.8601 - val_loss: 0.3326 - val_acc: 0.8770
Epoch 106/120
10000/10000 [==============================] - 2s - loss: 0.3749 - acc: 0.8629 - val_loss: 0.3242 - val_acc: 0.8800
Epoch 107/120
10000/10000 [==============================] - 2s - loss: 0.3840 - acc: 0.8613 - val_loss: 0.3255 - val_acc: 0.8810
Epoch 108/120
10000/10000 [==============================] - 2s - loss: 0.3641 - acc: 0.8634 - val_loss: 0.3209 - val_acc: 0.8790
Epoch 109/120
10000/10000 [==============================] - 2s - loss: 0.3695 - acc: 0.8661 - val_loss: 0.3226 - val_acc: 0.8820
Epoch 110/120
10000/10000 [==============================] - 2s - loss: 0.3648 - acc: 0.8659 - val_loss: 0.3318 - val_acc: 0.8820
Epoch 111/120
10000/10000 [==============================] - 2s - loss: 0.3642 - acc: 0.8695 - val_loss: 0.3146 - val_acc: 0.8850
Epoch 112/120
10000/10000 [==============================] - 2s - loss: 0.3690 - acc: 0.8639 - val_loss: 0.3130 - val_acc: 0.8840
Epoch 113/120
10000/10000 [==============================] - 2s - loss: 0.3627 - acc: 0.8669 - val_loss: 0.3098 - val_acc: 0.8880
Epoch 114/120
10000/10000 [==============================] - 2s - loss: 0.3561 - acc: 0.8702 - val_loss: 0.3033 - val_acc: 0.8850
Epoch 115/120
10000/10000 [==============================] - 2s - loss: 0.3552 - acc: 0.8675 - val_loss: 0.3057 - val_acc: 0.8880
Epoch 116/120
10000/10000 [==============================] - 2s - loss: 0.3456 - acc: 0.8700 - val_loss: 0.2989 - val_acc: 0.8850
Epoch 117/120
10000/10000 [==============================] - 2s - loss: 0.3456 - acc: 0.8743 - val_loss: 0.2920 - val_acc: 0.8890
Epoch 118/120
10000/10000 [==============================] - 2s - loss: 0.3528 - acc: 0.8716 - val_loss: 0.2909 - val_acc: 0.8860
Epoch 119/120
10000/10000 [==============================] - 2s - loss: 0.3388 - acc: 0.8775 - val_loss: 0.2842 - val_acc: 0.8920
Epoch 120/120
10000/10000 [==============================] - 2s - loss: 0.3504 - acc: 0.8742 - val_loss: 0.2837 - val_acc: 0.8900
